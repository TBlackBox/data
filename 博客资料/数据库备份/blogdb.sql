/*
 Navicat Premium Data Transfer

 Source Server         : 152.32.192.200
 Source Server Type    : MySQL
 Source Server Version : 100227
 Source Host           : 152.32.192.200:3306
 Source Schema         : blogdb

 Target Server Type    : MySQL
 Target Server Version : 100227
 File Encoding         : 65001

 Date: 13/08/2020 17:31:58
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for attachments
-- ----------------------------
DROP TABLE IF EXISTS `attachments`;
CREATE TABLE `attachments`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `file_key` varchar(2047) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `height` int(11) NULL DEFAULT 0,
  `media_type` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `path` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `size` bigint(20) NOT NULL,
  `suffix` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `thumb_path` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `type` int(11) NULL DEFAULT 0,
  `width` int(11) NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `attachments_media_type`(`media_type`) USING BTREE,
  INDEX `attachments_create_time`(`create_time`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of attachments
-- ----------------------------
INSERT INTO `attachments` VALUES (1, '2019-09-30 10:24:22', 0, '2019-09-30 10:24:22', 'upload/2019/9/ba79a75b2f389dae444a2993f72093b-eef65da0eb124e83bf5625f550ed2443.jpg', 959, 'image/jpeg', 'ba79a75b2f389dae444a2993f72093b', 'upload/2019/9/ba79a75b2f389dae444a2993f72093b-eef65da0eb124e83bf5625f550ed2443.jpg', 41540, 'jpg', 'upload/2019/9/ba79a75b2f389dae444a2993f72093b-eef65da0eb124e83bf5625f550ed2443-thumbnail.jpg', 0, 959);
INSERT INTO `attachments` VALUES (2, '2019-10-09 14:31:41', 0, '2019-10-09 14:31:41', 'upload/2019\\10\\4-8312b598e9094384a63988da186a0468.jpg', 411, 'image/jpeg', '4', 'upload/2019/10/4-8312b598e9094384a63988da186a0468.jpg', 23879, 'jpg', 'upload/2019\\10\\4-8312b598e9094384a63988da186a0468-thumbnail.jpg', 0, 440);

-- ----------------------------
-- Table structure for categories
-- ----------------------------
DROP TABLE IF EXISTS `categories`;
CREATE TABLE `categories`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `description` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `parent_id` int(11) NULL DEFAULT 0,
  `slug_name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `slug` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `thumbnail` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `categories_name`(`name`) USING BTREE,
  INDEX `categories_parent_id`(`parent_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 9 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of categories
-- ----------------------------
INSERT INTO `categories` VALUES (1, '2019-09-30 10:27:43', 0, '2019-09-30 10:27:43', 'java', 'Java', 0, 'Java', 'Java', NULL);
INSERT INTO `categories` VALUES (2, '2019-09-30 10:27:55', 0, '2019-09-30 17:51:35', 'SpringBoot', 'springboot', 0, 'springboot', 'springboot', NULL);
INSERT INTO `categories` VALUES (3, '2019-09-30 10:28:19', 0, '2019-09-30 10:28:19', '数据库', '数据库', 0, 'database', 'database', NULL);
INSERT INTO `categories` VALUES (4, '2019-09-30 10:29:05', 0, '2019-09-30 10:29:05', '消息', '消息', 0, 'message', 'message', NULL);
INSERT INTO `categories` VALUES (5, '2019-09-30 10:29:20', 0, '2019-09-30 10:29:20', '工具', '工具', 0, 'utils', 'utils', NULL);
INSERT INTO `categories` VALUES (6, '2020-05-12 17:33:23', 0, '2020-05-12 17:33:23', '', 'JDK8', 0, 'jdk8', 'jdk8', NULL);
INSERT INTO `categories` VALUES (7, '2020-06-03 17:06:07', 0, '2020-06-03 17:06:07', '', 'Effective Java', 0, 'effective-java', 'effective-java', NULL);
INSERT INTO `categories` VALUES (8, '2020-06-03 17:15:01', 0, '2020-06-03 17:15:01', '', 'Java开发利器', 0, 'java', 'java', NULL);

-- ----------------------------
-- Table structure for comment_black_list
-- ----------------------------
DROP TABLE IF EXISTS `comment_black_list`;
CREATE TABLE `comment_black_list`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime(0) NULL DEFAULT NULL,
  `update_time` datetime(0) NULL DEFAULT NULL,
  `ban_time` datetime(0) NULL DEFAULT NULL,
  `ip_address` varchar(127) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for comments
-- ----------------------------
DROP TABLE IF EXISTS `comments`;
CREATE TABLE `comments`  (
  `type` int(11) NOT NULL DEFAULT 0,
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `author` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `author_url` varchar(512) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `content` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `email` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `gravatar_md5` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `ip_address` varchar(127) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `is_admin` tinyint(4) NULL DEFAULT 0,
  `parent_id` bigint(20) NULL DEFAULT 0,
  `post_id` int(11) NOT NULL,
  `status` int(11) NULL DEFAULT 1,
  `top_priority` int(11) NULL DEFAULT 0,
  `user_agent` varchar(512) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `allow_notification` bit(1) NULL DEFAULT b'1',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `comments_post_id`(`post_id`) USING BTREE,
  INDEX `comments_type_status`(`type`, `status`) USING BTREE,
  INDEX `comments_parent_id`(`parent_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of comments
-- ----------------------------
INSERT INTO `comments` VALUES (0, 1, '2019-09-27 18:00:48', 0, '2019-09-28 15:53:29', 'Halo Bot', 'https://github.com/halo-dev/halo', '欢迎使用 Halo，这是你的第一条评论。', 'i@ryanc.cc', '7cc7f29278071bd4dce995612d428834', '14.106.226.222', 0, 0, 1, 0, NULL, 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36', b'1');

-- ----------------------------
-- Table structure for flyway_schema_history
-- ----------------------------
DROP TABLE IF EXISTS `flyway_schema_history`;
CREATE TABLE `flyway_schema_history`  (
  `installed_rank` int(11) NOT NULL,
  `version` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `description` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `type` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `script` varchar(1000) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `checksum` int(11) NULL DEFAULT NULL,
  `installed_by` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `installed_on` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `execution_time` int(11) NOT NULL,
  `success` tinyint(1) NOT NULL,
  PRIMARY KEY (`installed_rank`) USING BTREE,
  INDEX `flyway_schema_history_s_idx`(`success`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of flyway_schema_history
-- ----------------------------
INSERT INTO `flyway_schema_history` VALUES (1, '1', '<< Flyway Baseline >>', 'BASELINE', '<< Flyway Baseline >>', NULL, 'blog', '2020-06-11 23:27:35', 0, 1);
INSERT INTO `flyway_schema_history` VALUES (2, '2', 'migrate 1.2.0-beta.1 to 1.2.0-beta.2', 'SQL', 'V2__migrate_1.2.0-beta.1_to_1.2.0-beta.2.sql', 623818472, 'blog', '2020-06-11 23:27:37', 416, 1);
INSERT INTO `flyway_schema_history` VALUES (3, '3', 'migrate 1.3.0-beta.1 to 1.3.0-beta.2', 'SQL', 'V3__migrate_1.3.0-beta.1_to_1.3.0-beta.2.sql', -417975340, 'blog', '2020-06-11 23:32:13', 1392, 1);
INSERT INTO `flyway_schema_history` VALUES (4, '4', 'migrate 1.3.0-beta.2 to 1.3.0-beta.3', 'SQL', 'V4__migrate_1.3.0-beta.2_to_1.3.0-beta.3.sql', 589261839, 'blog', '2020-06-11 23:32:14', 419, 1);

-- ----------------------------
-- Table structure for journals
-- ----------------------------
DROP TABLE IF EXISTS `journals`;
CREATE TABLE `journals`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `likes` bigint(20) NULL DEFAULT 0,
  `type` int(11) NULL DEFAULT 1,
  `source_content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for links
-- ----------------------------
DROP TABLE IF EXISTS `links`;
CREATE TABLE `links`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `logo` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `team` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `url` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `priority` int(11) NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `links_name`(`name`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of links
-- ----------------------------
INSERT INTO `links` VALUES (1, '2019-10-15 20:53:16', 0, '2019-10-15 20:53:16', '开源库', '', 'github', '', 'https://github.com/', 0);

-- ----------------------------
-- Table structure for logs
-- ----------------------------
DROP TABLE IF EXISTS `logs`;
CREATE TABLE `logs`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `content` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `ip_address` varchar(127) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `log_key` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `type` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `logs_create_time`(`create_time`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 38 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of logs
-- ----------------------------
INSERT INTO `logs` VALUES (1, '2019-09-27 17:59:54', 0, '2019-09-27 17:59:54', '1227900499@qq.com', NULL, '', 35);
INSERT INTO `logs` VALUES (2, '2019-09-27 18:00:48', 0, '2019-09-27 18:00:48', '博客已成功初始化', NULL, '', 0);
INSERT INTO `logs` VALUES (3, '2019-09-27 18:01:02', 0, '2019-09-27 18:01:02', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (4, '2019-09-28 15:52:04', 0, '2019-09-28 15:52:04', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (5, '2019-09-30 10:01:00', 0, '2019-09-30 10:01:00', 'Hello Halo', NULL, '', 20);
INSERT INTO `logs` VALUES (6, '2019-09-30 10:19:53', 0, '2019-09-30 10:19:53', 'HashMap源码解析(jdk8版)', NULL, '', 15);
INSERT INTO `logs` VALUES (7, '2019-09-30 10:27:00', 0, '2019-09-30 10:27:00', 'BlackBox', NULL, '', 45);
INSERT INTO `logs` VALUES (8, '2019-09-30 11:27:06', 0, '2019-09-30 11:27:06', 'HashMap源码解析(jdk8版)', NULL, '', 15);
INSERT INTO `logs` VALUES (9, '2019-09-30 17:39:57', 0, '2019-09-30 17:39:57', 'springboot配置redis 缓存', NULL, '', 15);
INSERT INTO `logs` VALUES (10, '2019-09-30 17:40:22', 0, '2019-09-30 17:40:22', 'springboot配置redis 缓存', NULL, '', 15);
INSERT INTO `logs` VALUES (11, '2019-09-30 17:51:01', 0, '2019-09-30 17:51:01', 'springBoot配置异步任务，定时任务和邮件任务', NULL, '', 15);
INSERT INTO `logs` VALUES (12, '2019-10-09 14:30:50', 0, '2019-10-09 14:30:50', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (13, '2019-10-09 15:29:16', 0, '2019-10-09 15:29:16', '12279000499@qq.com', NULL, '', 35);
INSERT INTO `logs` VALUES (14, '2019-10-09 15:29:22', 0, '2019-10-09 15:29:22', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (15, '2019-10-15 20:51:27', 0, '2019-10-15 20:51:27', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (16, '2019-10-24 17:28:28', 0, '2019-10-24 17:28:28', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (17, '2019-10-24 17:29:07', 0, '2019-10-24 17:29:07', 'netty入门案例', NULL, '', 5);
INSERT INTO `logs` VALUES (18, '2019-10-24 17:30:03', 0, '2019-10-24 17:30:03', 'netty入门案例', NULL, '', 15);
INSERT INTO `logs` VALUES (19, '2019-12-27 10:32:11', 0, '2019-12-27 10:32:11', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (20, '2019-12-27 14:24:45', 0, '2019-12-27 14:24:45', 'iftop实时网络流量监测工具的安装和使用', NULL, '', 5);
INSERT INTO `logs` VALUES (21, '2019-12-27 14:26:08', 0, '2019-12-27 14:26:08', 'iftop实时网络流量监测工具的安装和使用', NULL, '', 15);
INSERT INTO `logs` VALUES (22, '2019-12-27 14:26:46', 0, '2019-12-27 14:26:46', 'iftop实时网络流量监测工具的安装和使用', NULL, '', 15);
INSERT INTO `logs` VALUES (23, '2020-05-05 19:09:38', 0, '2020-05-05 19:09:38', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (24, '2020-05-12 17:31:55', 0, '2020-05-12 17:31:55', 'BlackBox', NULL, '', 25);
INSERT INTO `logs` VALUES (25, '2020-05-12 17:34:23', 0, '2020-05-12 17:34:23', 'jdk8 Map新增的方法介绍', NULL, '', 5);
INSERT INTO `logs` VALUES (26, '2020-06-03 17:04:24', 0, '2020-06-03 17:04:24', 'EffectiveJava之静态工厂方法代替构造器', NULL, '', 5);
INSERT INTO `logs` VALUES (27, '2020-06-03 17:05:03', 0, '2020-06-03 17:05:03', 'EffectiveJava之静态工厂方法代替构造器', NULL, '', 15);
INSERT INTO `logs` VALUES (28, '2020-06-03 17:05:14', 0, '2020-06-03 17:05:14', 'EffectiveJava之静态工厂方法代替构造器', NULL, '', 15);
INSERT INTO `logs` VALUES (29, '2020-06-03 17:06:10', 0, '2020-06-03 17:06:10', 'EffectiveJava之静态工厂方法代替构造器', NULL, '', 15);
INSERT INTO `logs` VALUES (30, '2020-06-03 17:06:16', 0, '2020-06-03 17:06:16', 'EffectiveJava之静态工厂方法代替构造器', NULL, '', 15);
INSERT INTO `logs` VALUES (31, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 'EffectiveJava之遇到多个构造器参数时考虑用构建器', NULL, '', 5);
INSERT INTO `logs` VALUES (32, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 'Effectivejava用私有构造器或者枚举类型强化Singleton(单列)', NULL, '', 5);
INSERT INTO `logs` VALUES (33, '2020-06-03 17:15:21', 0, '2020-06-03 17:15:21', 'GSON简单使用', NULL, '', 5);
INSERT INTO `logs` VALUES (34, '2020-06-03 17:16:34', 0, '2020-06-03 17:16:34', 'Gson对枚举的支持', NULL, '', 5);
INSERT INTO `logs` VALUES (35, '2020-06-03 17:18:25', 0, '2020-06-03 17:18:25', 'Gson对枚举的支持', NULL, '', 15);
INSERT INTO `logs` VALUES (36, '2020-06-03 17:18:30', 0, '2020-06-03 17:18:30', 'Gson对枚举的支持', NULL, '', 15);
INSERT INTO `logs` VALUES (37, '2020-06-11 23:18:14', 0, '2020-06-11 23:18:14', 'BlackBox', NULL, '', 25);

-- ----------------------------
-- Table structure for menus
-- ----------------------------
DROP TABLE IF EXISTS `menus`;
CREATE TABLE `menus`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `icon` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `parent_id` int(11) NULL DEFAULT 0,
  `priority` int(11) NULL DEFAULT 0,
  `target` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '_self',
  `url` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `team` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `menus_parent_id`(`parent_id`) USING BTREE,
  INDEX `menus_name`(`name`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of menus
-- ----------------------------
INSERT INTO `menus` VALUES (1, '2019-09-27 18:00:48', 0, '2019-09-27 18:00:48', '', '首页', 0, 1, '_self', '/', '');
INSERT INTO `menus` VALUES (2, '2019-09-27 18:00:48', 0, '2019-09-27 18:00:48', '', '归档', 0, 2, '_self', '/archives', '');

-- ----------------------------
-- Table structure for metas
-- ----------------------------
DROP TABLE IF EXISTS `metas`;
CREATE TABLE `metas`  (
  `type` int(11) NOT NULL DEFAULT 0,
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `meta_key` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `post_id` int(11) NOT NULL,
  `meta_value` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for options
-- ----------------------------
DROP TABLE IF EXISTS `options`;
CREATE TABLE `options`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `option_key` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `option_value` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `type` int(11) NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 39 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of options
-- ----------------------------
INSERT INTO `options` VALUES (1, '2019-09-27 18:00:47', 0, '2019-09-27 18:00:47', 'blog_title', '程序轩', 0);
INSERT INTO `options` VALUES (2, '2019-09-27 18:00:47', 0, '2019-09-27 18:00:47', 'birthday', '1569578446938', 0);
INSERT INTO `options` VALUES (3, '2019-09-27 18:00:47', 0, '2019-09-27 18:00:47', 'blog_locale', 'zh', 0);
INSERT INTO `options` VALUES (4, '2019-09-27 18:00:47', 0, '2019-09-28 15:52:53', 'blog_url', 'https://blog.javafroum.cn', 0);
INSERT INTO `options` VALUES (5, '2019-09-27 18:00:47', 0, '2019-09-27 18:00:47', 'is_installed', 'true', 0);
INSERT INTO `options` VALUES (6, '2019-09-27 18:01:33', 0, '2019-10-08 17:51:26', 'theme', 'ppoffice_icarus', 0);
INSERT INTO `options` VALUES (7, '2019-09-28 15:52:53', 0, '2019-09-28 15:52:53', 'email_ssl_port', '465', 0);
INSERT INTO `options` VALUES (8, '2019-09-28 15:52:53', 0, '2019-09-28 15:52:53', 'oss_qiniu_zone', 'auto', 0);
INSERT INTO `options` VALUES (9, '2019-09-28 15:52:53', 0, '2019-09-28 15:52:53', 'seo_spider_disabled', 'false', 0);
INSERT INTO `options` VALUES (10, '2019-09-28 15:52:53', 0, '2019-09-28 15:52:53', 'comment_new_notice', 'false', 0);
INSERT INTO `options` VALUES (11, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'email_enabled', 'false', 0);
INSERT INTO `options` VALUES (12, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'api_enabled', 'false', 0);
INSERT INTO `options` VALUES (13, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'post_index_page_size', '10', 0);
INSERT INTO `options` VALUES (14, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'email_protocol', 'smtp', 0);
INSERT INTO `options` VALUES (15, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'comment_api_enabled', 'true', 0);
INSERT INTO `options` VALUES (16, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'comment_new_need_check', 'true', 0);
INSERT INTO `options` VALUES (17, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'comment_page_size', '10', 0);
INSERT INTO `options` VALUES (18, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'comment_gravatar_default', 'mm', 0);
INSERT INTO `options` VALUES (19, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'attachment_type', 'LOCAL', 0);
INSERT INTO `options` VALUES (20, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'rss_page_size', '20', 0);
INSERT INTO `options` VALUES (21, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'comment_reply_notice', 'false', 0);
INSERT INTO `options` VALUES (22, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'comment_pass_notice', 'false', 0);
INSERT INTO `options` VALUES (23, '2019-09-28 15:52:54', 0, '2019-09-28 15:52:54', 'post_summary_length', '150', 0);
INSERT INTO `options` VALUES (24, '2019-09-30 11:24:59', 0, '2019-09-30 11:24:59', 'seo_keywords', 'java', 0);
INSERT INTO `options` VALUES (25, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'post_index_sort', 'createTime', 0);
INSERT INTO `options` VALUES (26, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'attachment_upload_max_parallel_uploads', '3', 0);
INSERT INTO `options` VALUES (27, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'attachment_upload_max_files', '50', 0);
INSERT INTO `options` VALUES (28, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'comment_internal_plugin_js', '//cdn.jsdelivr.net/gh/halo-dev/halo-comment@latest/dist/halo-comment.min.js', 0);
INSERT INTO `options` VALUES (29, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'attachment_upload_image_preview_enable', 'true', 0);
INSERT INTO `options` VALUES (30, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'blog_logo', 'https://blog.javafroum.cn/upload/2019/9/ba79a75b2f389dae444a2993f72093b-eef65da0eb124e83bf5625f550ed2443.jpg', 0);
INSERT INTO `options` VALUES (31, '2019-10-15 20:54:19', 0, '2019-10-15 20:54:19', 'blog_favicon', 'https://blog.javafroum.cn/upload/2019/9/ba79a75b2f389dae444a2993f72093b-eef65da0eb124e83bf5625f550ed2443.jpg', 0);
INSERT INTO `options` VALUES (32, '2020-05-05 19:17:42', 0, '2020-05-05 19:22:17', 'blog_footer_info', '', 0);
INSERT INTO `options` VALUES (33, '2020-05-05 19:20:37', 0, '2020-05-05 19:20:37', 'seo_description', '专注技术的分享和交流', 0);
INSERT INTO `options` VALUES (34, '2020-05-05 19:22:17', 0, '2020-05-05 19:22:17', 'oss_upyun_operator', '1227900499@qq.com', 0);
INSERT INTO `options` VALUES (35, '2020-05-05 19:22:17', 0, '2020-05-05 19:22:17', 'oss_upyun_password', 'zy18228145045', 0);
INSERT INTO `options` VALUES (36, '2020-05-05 19:22:17', 0, '2020-05-05 19:22:17', 'email_username', '1227900499@qq.com', 0);
INSERT INTO `options` VALUES (37, '2020-05-05 19:22:17', 0, '2020-05-05 19:22:17', 'email_password', 'zy18228145045', 0);
INSERT INTO `options` VALUES (38, '2020-05-05 19:22:17', 0, '2020-05-05 19:22:17', 'blog_statistics_code', '<script>\nvar _hmt = _hmt || [];\n(function() {\n  var hm = document.createElement(\"script\");\n  hm.src = \"https://hm.baidu.com/hm.js?a54c56adfbe96a204d699e5d4d768bfc\";\n  var s = document.getElementsByTagName(\"script\")[0]; \n  s.parentNode.insertBefore(hm, s);\n})();\n</script>\n', 0);

-- ----------------------------
-- Table structure for photos
-- ----------------------------
DROP TABLE IF EXISTS `photos`;
CREATE TABLE `photos`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `location` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `take_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `team` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `thumbnail` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `url` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `photos_create_time`(`create_time`) USING BTREE,
  INDEX `photos_team`(`team`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for post_categories
-- ----------------------------
DROP TABLE IF EXISTS `post_categories`;
CREATE TABLE `post_categories`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `category_id` int(11) NULL DEFAULT NULL,
  `post_id` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `post_categories_post_id`(`post_id`) USING BTREE,
  INDEX `post_categories_category_id`(`category_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 22 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of post_categories
-- ----------------------------
INSERT INTO `post_categories` VALUES (1, '2019-09-30 11:27:01', 0, '2019-09-30 11:27:01', 2, 2);
INSERT INTO `post_categories` VALUES (2, '2019-09-30 17:39:51', 0, '2019-09-30 17:39:51', 1, 3);
INSERT INTO `post_categories` VALUES (3, '2019-09-30 17:39:51', 0, '2019-09-30 17:39:51', 2, 3);
INSERT INTO `post_categories` VALUES (4, '2019-09-30 17:50:51', 0, '2019-09-30 17:50:51', 1, 4);
INSERT INTO `post_categories` VALUES (5, '2019-09-30 17:50:51', 0, '2019-09-30 17:50:51', 2, 4);
INSERT INTO `post_categories` VALUES (6, '2019-10-24 17:30:03', 0, '2019-10-24 17:30:03', 1, 5);
INSERT INTO `post_categories` VALUES (9, '2019-12-27 14:26:46', 0, '2019-12-27 14:26:46', 5, 6);
INSERT INTO `post_categories` VALUES (10, '2020-05-12 17:34:23', 0, '2020-05-12 17:34:23', 1, 7);
INSERT INTO `post_categories` VALUES (12, '2020-06-03 17:06:16', 0, '2020-06-03 17:06:16', 1, 8);
INSERT INTO `post_categories` VALUES (13, '2020-06-03 17:06:16', 0, '2020-06-03 17:06:16', 7, 8);
INSERT INTO `post_categories` VALUES (14, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 1, 9);
INSERT INTO `post_categories` VALUES (15, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 7, 9);
INSERT INTO `post_categories` VALUES (16, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 1, 10);
INSERT INTO `post_categories` VALUES (17, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 7, 10);
INSERT INTO `post_categories` VALUES (18, '2020-06-03 17:15:21', 0, '2020-06-03 17:15:21', 8, 11);
INSERT INTO `post_categories` VALUES (21, '2020-06-03 17:18:30', 0, '2020-06-03 17:18:30', 8, 12);

-- ----------------------------
-- Table structure for post_tags
-- ----------------------------
DROP TABLE IF EXISTS `post_tags`;
CREATE TABLE `post_tags`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `post_id` int(11) NOT NULL,
  `tag_id` int(11) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `post_tags_post_id`(`post_id`) USING BTREE,
  INDEX `post_tags_tag_id`(`tag_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 33 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of post_tags
-- ----------------------------
INSERT INTO `post_tags` VALUES (1, '2019-09-30 11:27:06', 0, '2019-09-30 11:27:06', 2, 1);
INSERT INTO `post_tags` VALUES (2, '2019-09-30 17:39:57', 0, '2019-09-30 17:39:57', 3, 3);
INSERT INTO `post_tags` VALUES (3, '2019-09-30 17:40:22', 0, '2019-09-30 17:40:22', 3, 4);
INSERT INTO `post_tags` VALUES (4, '2019-09-30 17:51:01', 0, '2019-09-30 17:51:01', 4, 5);
INSERT INTO `post_tags` VALUES (7, '2019-12-27 14:26:46', 0, '2019-12-27 14:26:46', 6, 7);
INSERT INTO `post_tags` VALUES (8, '2020-05-12 17:34:23', 0, '2020-05-12 17:34:23', 7, 8);
INSERT INTO `post_tags` VALUES (9, '2020-05-12 17:34:23', 0, '2020-05-12 17:34:23', 7, 9);
INSERT INTO `post_tags` VALUES (10, '2020-05-12 17:34:23', 0, '2020-05-12 17:34:23', 7, 10);
INSERT INTO `post_tags` VALUES (19, '2020-06-03 17:06:16', 0, '2020-06-03 17:06:16', 8, 11);
INSERT INTO `post_tags` VALUES (20, '2020-06-03 17:06:16', 0, '2020-06-03 17:06:16', 8, 12);
INSERT INTO `post_tags` VALUES (21, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 9, 10);
INSERT INTO `post_tags` VALUES (22, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 9, 11);
INSERT INTO `post_tags` VALUES (23, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 9, 12);
INSERT INTO `post_tags` VALUES (24, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 10, 11);
INSERT INTO `post_tags` VALUES (25, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 10, 12);
INSERT INTO `post_tags` VALUES (26, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 10, 14);
INSERT INTO `post_tags` VALUES (27, '2020-06-03 17:15:21', 0, '2020-06-03 17:15:21', 11, 16);
INSERT INTO `post_tags` VALUES (28, '2020-06-03 17:15:21', 0, '2020-06-03 17:15:21', 11, 15);
INSERT INTO `post_tags` VALUES (31, '2020-06-03 17:18:30', 0, '2020-06-03 17:18:30', 12, 16);
INSERT INTO `post_tags` VALUES (32, '2020-06-03 17:18:30', 0, '2020-06-03 17:18:30', 12, 15);

-- ----------------------------
-- Table structure for posts
-- ----------------------------
DROP TABLE IF EXISTS `posts`;
CREATE TABLE `posts`  (
  `type` int(11) NOT NULL DEFAULT 0,
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `create_from` int(11) NULL DEFAULT 0,
  `disallow_comment` int(11) NULL DEFAULT 0,
  `edit_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `format_content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `likes` bigint(20) NULL DEFAULT 0,
  `original_content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `status` int(11) NULL DEFAULT 1,
  `summary` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL,
  `template` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `thumbnail` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `title` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `top_priority` int(11) NULL DEFAULT 0,
  `url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `visits` bigint(20) NULL DEFAULT 0,
  `editor_type` int(11) NULL DEFAULT 0,
  `meta_description` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `meta_keywords` varchar(511) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `slug` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `posts_type_status`(`type`, `status`) USING BTREE,
  INDEX `posts_create_time`(`create_time`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 13 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of posts
-- ----------------------------
INSERT INTO `posts` VALUES (0, 2, '2019-09-30 10:19:47', 0, '2019-09-30 11:27:12', 0, 0, '2019-09-30 11:27:12', '<h1 id=\"hashmap源码解析jdk8版\">HashMap源码解析(jdk8版)</h1>\n<p>HashMap允许key为null,也允许value为null<br/></p>\n<p>HashMap与HashTable两个类是差不多的,除了HashTable是线程安全且不允许null值这一点外.</p>\n<p>基本概念:HashMap底层是数组+链表(数组的每个值都是一条链表的头结点),1.8后加入了红黑树(当链表长度达到8就自动将该链表替换为红黑树),通过计算key的哈希码,在经过高位参与位运算计算得出键值对(将key和value包装起来的对象)所在的数组的下标,采用头插入法插入该位置的链表(若该位置是空的就直接插入)</p>\n<h2 id=\"hashmap的相关域\">HashMap的相关域:</h2>\n<pre><code>    static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; \n\n    static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\n\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n    static final int TREEIFY_THRESHOLD = 8;\n\n    static final int UNTREEIFY_THRESHOLD = 6;\n\n    static final int MIN_TREEIFY_CAPACITY = 64;\n</code></pre>\n<ul>\n<li>\n<p>DEFAULT_INITIAL_CAPACITY: 默认底层数组的初始大小(2^4),可通过构造参数指定</p>\n</li>\n<li>\n<p>MAXIMUM_CAPACITY: 数组的最大长度(2^31),超过将替换为此值</p>\n</li>\n<li>\n<p>DEFAULT_LOAD_FACTOR: 默认负载因子,为0.75,可通过构造参数指定</p>\n</li>\n<li>\n<p>TREEIFY_THRESHOLD: 链表转换为红黑树的阙值,当链表长度达到8自动转为红黑树进行存储(前提是数组长度大于等于64)</p>\n</li>\n<li>\n<p>UNTREEIFY_THRESHOLD: 红黑树转为链表的阙值,当红黑树结点个数减小到6时,自动转为链表存储</p>\n</li>\n<li>\n<p>MIN_TREEIFY_CAPACITY: 链表进行树化的前提条件,数组长度要达到64或一上,在这之前只能通过数组扩容来减少链表长度</p>\n<pre><code>  transient Node&lt;K,V&gt;[] table;\n\n  transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;\n\n  transient int size;\n\n  transient int modCount;\n\n  int threshold;\n\n  final float loadFactor;\n</code></pre>\n</li>\n<li>\n<p>table: 底层数组,可动态扩容,数组长度为2的整数次方</p>\n</li>\n<li>\n<p>size: 这个map中存放的键值对数目</p>\n</li>\n<li>\n<p>modCount: 记录这个map数据结构发生改变的次数(发送插入删除或者链表与树相互转换的操作),由于fail-fast机制</p>\n</li>\n<li>\n<p>threshold: 数组进行扩容的下个阙值(当前键值对数量达到这个值后进行<code>resize()</code>(扩容)操作)(threshold = capacity * load factor)</p>\n</li>\n<li>\n<p>loadFactor:　实际的负载因子</p>\n</li>\n</ul>\n<h2 id=\"哈希码计算方法hashobject-key\">哈希码计算方法<code>hash(Object key)</code></h2>\n<pre><code>    static final int hash(Object key) {\n        int h;\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);\n    }\n</code></pre>\n<ul>\n<li>局部变量h存放hashCode()放回的初始哈希码,通过h右移16位与h异或(右移后,前16位为0,异或不改变h的前16位值)得到最终的哈希吗.<br/>\n通过高位参与位运算可以减少数组长度较低时的哈希码冲突问题(取模时,高位变低位不变,冲突几率会变高)</li>\n</ul>\n<h2 id=\"链表结点的数据结构nodekv\">链表结点的数据结构<code>Node&lt;K,V&gt;</code></h2>\n<pre><code>    static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {\n        final int hash; // 计算得到的hash码\n        final K key;    // 键对象\n        V value;        // 值对象\n        Node&lt;K,V&gt; next; // 下一个结点\n        方法略...\n    }\n</code></pre>\n<h2 id=\"树节点数据结构vtreenodekv\">树节点数据结构v<code>TreeNode&lt;K,V&gt;</code></h2>\n<pre><code>    static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; {\n        TreeNode&lt;K,V&gt; parent;  // 父亲节点\n        TreeNode&lt;K,V&gt; left;    // 左子树\n        TreeNode&lt;K,V&gt; right;   //右子树\n        TreeNode&lt;K,V&gt; prev;    // needed to unlink next upon deletion\n        boolean red;            // 红色还是黑色\n        TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) {\n            super(hash, key, val, next);\n        方法略...    \n    }\n</code></pre>\n<ul>\n<li>通过继承<code>LinkedHashMap.Entry&lt;K,V&gt;</code>,实际上间接继承了链表的<code>Node&lt;K,V&gt;</code></li>\n</ul>\n<h2 id=\"获取valuegetobject-key\">获取value:get(Object key)</h2>\n<pre><code>    public V get(Object key) {\n        Node&lt;K,V&gt; e;\n        return (e = getNode(hash(key), key)) == null ? null : e.value;      //1\n    }\n\n    final Node&lt;K,V&gt; getNode(int hash, Object key) {\n        Node&lt;K,V&gt;[] tab;\n        Node&lt;K,V&gt; first, e;\n        int n;\n        K k;\n        if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;\n            (first = tab[(n - 1) &amp; hash]) != null) {                        //2\n            if (first.hash == hash &amp;&amp; // always check first node\n                ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) //3\n                return first;\n            if ((e = first.next) != null) {                                 //4\n                if (first instanceof TreeNode)\n                    return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);\n                do {\n                    if (e.hash == hash &amp;&amp;\n                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                        return e;\n                } while ((e = e.next) != null);\n            }\n        }\n        return null;\n    }\n</code></pre>\n<ol>\n<li>计算key的哈希码,传入getNode方法,放回Node对象或者null</li>\n<li>如果table为null,table是空的或者数组( (length-1)&amp;hash )处的值为null,就返回null,否则进入3</li>\n<li>检查第一个结点,若是指定的key,直接返回该结点,否则进入4</li>\n<li>如果这个树/链表不止一个结点,先判断是树还是链表,再进行对应的结点查找,找到就返回,否则返回null.</li>\n</ol>\n<h2 id=\"增加键值对putk-key-v-value\">增加键值对<code>put(K key, V value)</code></h2>\n<pre><code>    public V put(K key, V value) {\n        return putVal(hash(key), key, value, false, true);\n    }\n\n    /**\n    * Implements Map.put and related methods\n    *\n    * @param hash hash for key\n    * @param key the key\n    * @param value the value to put\n    * @param onlyIfAbsent if true, don\'t change existing value\n    * @param evict if false, the table is in creation mode.\n    * @return previous value, or null if none\n    */\n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                boolean evict) {\n        Node&lt;K,V&gt;[] tab;\n        Node&lt;K,V&gt; p;\n        int n, i;\n        if ((tab = table) == null || (n = tab.length) == 0)             //1\n            n = (tab = resize()).length;\n        if ((p = tab[i = (n - 1) &amp; hash]) == null)                      //2\n            tab[i] = newNode(hash, key, value, null);\n        else {\n            Node&lt;K,V&gt; e; K k;\n            if (p.hash == hash &amp;&amp;\n                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //3\n                e = p;\n            else if (p instanceof TreeNode)                             //4\n                e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);\n            else {                                                      //5\n                for (int binCount = 0; ; ++binCount) {\n                    if ((e = p.next) == null) {                         \n                        p.next = newNode(hash, key, value, null);\n                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    if (e.hash == hash &amp;&amp;\n                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n            if (e != null) { // existing mapping for key                //6\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }                                                               //7\n        ++modCount;\n        if (++size &gt; threshold)\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n</code></pre>\n<ol>\n<li>如果数组为null或是空的,则<code>resize()</code>扩充容量</li>\n<li>通过hash计算并位运算取摸获得数组下标,若该位置是空的,新建链表结点直接填坑然后跳到7,否则进入3</li>\n<li>判断头结点的key跟要put进去的key是否同一个,是则将其引用赋给e,进入6,否则进入4</li>\n<li>判断头结点是不是树结点,是则执行<code>putTreeVal</code>,若树中已存在该key,则直接返回该键值对(赋给e),否则新建并插入结点并返回null,然后进入6.如果不是树节点则进入5</li>\n<li>在链表中遍历,如果不存在,就新建一个结点,然后是否达到树化的阙值,是就转化为树结构,之后跳到7.如果存在就把它的引用赋给e跳到6</li>\n<li>在搜索到当前map中存在相同key时候将该键值对赋给e,在这里进行值的覆盖,并返回旧值</li>\n<li>对改动进行计数,判断是否需要进行数组扩容,返回null</li>\n</ol>\n<h2 id=\"移除键值对removeobject-key\">移除键值对<code>remove(Object key)</code></h2>\n<pre><code>    public V remove(Object key) {\n        Node&lt;K,V&gt; e;\n        return (e = removeNode(hash(key), key, null, false, true)) == null ?\n            null : e.value;\n    }\n\n    final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,\n                            boolean matchValue, boolean movable) {\n        Node&lt;K,V&gt;[] tab;\n        Node&lt;K,V&gt; p;\n        int n,index;\n        if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;            //1\n            (p = tab[index = (n - 1) &amp; hash]) != null) {\n            Node&lt;K,V&gt; node = null, e;\n            K k;\n            V v;\n            if (p.hash == hash &amp;&amp;\n                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //2\n                node = p;\n            else if ((e = p.next) != null) {                            //3\n                if (p instanceof TreeNode)\n                    node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);\n                else {\n                    do {\n                        if (e.hash == hash &amp;&amp;\n                            ((k = e.key) == key ||\n                            (key != null &amp;&amp; key.equals(k)))) {\n                            node = e;\n                            break;\n                        }\n                        p = e;\n                    } while ((e = e.next) != null);\n                }\n            }\n            if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||    //4\n                                (value != null &amp;&amp; value.equals(v)))) {\n                if (node instanceof TreeNode)\n                    ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);\n                else if (node == p)\n                    tab[index] = node.next;\n                else\n                    p.next = node.next;\n                ++modCount;\n                --size;\n                afterNodeRemoval(node);\n                return node;\n            }\n        }\n        return null;\n    }\n</code></pre>\n<ol>\n<li>判断底层数组是否为null或者是空的,是就直接返回null,否则2</li>\n<li>判断头结点是否就是要移除的键值对,是就赋给e,进入4,否则进入3</li>\n<li>判断是树还是链表并进行相应遍历,找到符合的键值对,并赋给e,进入4,若查无,返回null</li>\n<li>针对不同的存储结构进行相应的移除操作,并更新相关的计数值</li>\n</ol>\n<h2 id=\"链表的树化操作treeifybinnodekv-tab-int-hash\">链表的树化操作<code>treeifyBin(Node&lt;K,V&gt;[] tab, int hash)</code></h2>\n<pre><code>    /**\n    * Replaces all linked nodes in bin at index for given hash unless\n    * table is too small, in which case resizes instead.\n    */\n    final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) {\n        int n, index; Node&lt;K,V&gt; e;\n        if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY)\n            resize();\n        else if ((e = tab[index = (n - 1) &amp; hash]) != null) {\n            TreeNode&lt;K,V&gt; hd = null, tl = null;\n            do {\n                TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null);\n                if (tl == null)\n                    hd = p;\n                else {\n                    p.prev = tl;\n                    tl.next = p;\n                }\n                tl = p;\n            } while ((e = e.next) != null);\n            if ((tab[index] = hd) != null)\n                hd.treeify(tab);\n        }\n    }\n</code></pre>\n<ul>\n<li>先将链表结点转化成树结点,构造成双向链表,在<code>treeify</code>进行红黑树的构造</li>\n</ul>\n<h2 id=\"扩容操作resize\">扩容操作<code>resize</code></h2>\n<pre><code>    /**\n    * Initializes or doubles table size.  If null, allocates in\n    * accord with initial capacity target held in field threshold.\n    * Otherwise, because we are using power-of-two expansion, the\n    * elements from each bin must either stay at same index, or move\n    * with a power of two offset in the new table.\n    *\n    * @return the table\n    */\n    final Node&lt;K,V&gt;[] resize() {\n        Node&lt;K,V&gt;[] oldTab = table;\n        int oldCap = (oldTab == null) ? 0 : oldTab.length;\n        int oldThr = threshold;\n        int newCap, newThr = 0;\n        if (oldCap &gt; 0) {\n            if (oldCap &gt;= MAXIMUM_CAPACITY) {                           // 1\n                threshold = Integer.MAX_VALUE;\n                return oldTab;\n            }\n            else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;       // 2\n                    oldCap &gt;= DEFAULT_INITIAL_CAPACITY)\n                newThr = oldThr &lt;&lt; 1; // double threshold\n        }\n        else if (oldThr &gt; 0) // initial capacity was placed in threshold    // 3\n            newCap = oldThr;\n        else {               // zero initial threshold signifies using defaults // 4\n            newCap = DEFAULT_INITIAL_CAPACITY;\n            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n        }\n        if (newThr == 0) {                                                      // 5\n            float ft = (float)newCap * loadFactor;\n            newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?\n                    (int)ft : Integer.MAX_VALUE);\n        }\n        threshold = newThr;                                                     // 6\n        @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;})\n            Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];\n        table = newTab;\n        if (oldTab != null) {                                                   // 7\n            for (int j = 0; j &lt; oldCap; ++j) {\n                Node&lt;K,V&gt; e;\n                if ((e = oldTab[j]) != null) {\n                    oldTab[j] = null;\n                    if (e.next == null)                                         // 7-1\n                        newTab[e.hash &amp; (newCap - 1)] = e;\n                    else if (e instanceof TreeNode)                             // 7-2\n                        ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);\n                    else { // preserve order                                    // 7-3\n                        Node&lt;K,V&gt; loHead = null, loTail = null;\n                        Node&lt;K,V&gt; hiHead = null, hiTail = null;\n                        Node&lt;K,V&gt; next;\n                        do {\n                            next = e.next;\n                            if ((e.hash &amp; oldCap) == 0) {\n                                if (loTail == null)\n                                    loHead = e;\n                                else\n                                    loTail.next = e;\n                                loTail = e;\n                            }\n                            else {\n                                if (hiTail == null)\n                                    hiHead = e;\n                                else\n                                    hiTail.next = e;\n                                hiTail = e;\n                            }\n                        } while ((e = next) != null);\n                        if (loTail != null) {\n                            loTail.next = null;\n                            newTab[j] = loHead;\n                        }\n                        if (hiTail != null) {\n                            hiTail.next = null;\n                            newTab[j + oldCap] = hiHead;\n                        }\n                    }\n                }\n            }\n        }\n        return newTab;\n    }\n</code></pre>\n<ol>\n<li>若底层数组长度大于等于允许的最大值,将扩容阙值设为MAX_INT,直接不做任何操作,直接返回原数组</li>\n<li>如果底层数组长度是大于默认初始长度且当前长度*2小于允许的最大值,则将新的数组长度,扩容阙值都设为原来的两倍</li>\n<li>当前数组未初始化,且扩容阙值已经初始化(不为0),将新的数组长度设定为扩容阙值,跳到5</li>\n<li>当前数组与扩容阙值都未初始化,将新的数组长度和扩容阙值设为默认初始值</li>\n<li>根据新的数组长度值计算新的扩容阙值,如果新的数组长度值或者新的阙值大于数组长度的允许最大值,则将其替换为MAX_INT,反之保留</li>\n<li>将经过上述计算得到的新值进行更新(设置threshold为新值, 实例化一个新长度的底层数组)</li>\n<li>遍历数组的每个坑位,将老数组的值搬运到新的数组中\n7-1. 若该坑位只有一个结点,直接搬运到新数组对应坑位,需要重新计算下标,因为新数组的长度已经改变\n7-2. 若该坑位放的是树,则调用对应方法进行换坑\n7-3. 若该坑位是是链表,遍历这条链表,根据其hash&amp;旧数组长度是0还是1分为两组,一组在新数组下标不变,另一组是原来下标+旧数组长度<br/>\n注: 因为每次扩容都是2扩容两倍,位运算时只增加一个高位(右数第oldCap个),按位与时,若键值对的右数第oldCap位是0则下标不会受扩容影响,若不是,则下标是原下标加上oldCap.</li>\n</ol>\n', 0, '# HashMap源码解析(jdk8版)\n\nHashMap允许key为null,也允许value为null<br/>\n\nHashMap与HashTable两个类是差不多的,除了HashTable是线程安全且不允许null值这一点外.\n\n基本概念:HashMap底层是数组+链表(数组的每个值都是一条链表的头结点),1.8后加入了红黑树(当链表长度达到8就自动将该链表替换为红黑树),通过计算key的哈希码,在经过高位参与位运算计算得出键值对(将key和value包装起来的对象)所在的数组的下标,采用头插入法插入该位置的链表(若该位置是空的就直接插入)\n\n## HashMap的相关域:\n\n\n        static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; \n    \n        static final int MAXIMUM_CAPACITY = 1 << 30;\n    \n        static final float DEFAULT_LOAD_FACTOR = 0.75f;\n    \n        static final int TREEIFY_THRESHOLD = 8;\n    \n        static final int UNTREEIFY_THRESHOLD = 6;\n    \n        static final int MIN_TREEIFY_CAPACITY = 64;\n\n+ DEFAULT_INITIAL_CAPACITY: 默认底层数组的初始大小(2^4),可通过构造参数指定\n+ MAXIMUM_CAPACITY: 数组的最大长度(2^31),超过将替换为此值\n+ DEFAULT_LOAD_FACTOR: 默认负载因子,为0.75,可通过构造参数指定\n+ TREEIFY_THRESHOLD: 链表转换为红黑树的阙值,当链表长度达到8自动转为红黑树进行存储(前提是数组长度大于等于64)\n+ UNTREEIFY_THRESHOLD: 红黑树转为链表的阙值,当红黑树结点个数减小到6时,自动转为链表存储\n+ MIN_TREEIFY_CAPACITY: 链表进行树化的前提条件,数组长度要达到64或一上,在这之前只能通过数组扩容来减少链表长度\n\n        transient Node<K,V>[] table;\n    \n        transient Set<Map.Entry<K,V>> entrySet;\n    \n        transient int size;\n    \n        transient int modCount;\n    \n        int threshold;\n    \n        final float loadFactor;\n\n+ table: 底层数组,可动态扩容,数组长度为2的整数次方\n+ size: 这个map中存放的键值对数目\n+ modCount: 记录这个map数据结构发生改变的次数(发送插入删除或者链表与树相互转换的操作),由于fail-fast机制\n+ threshold: 数组进行扩容的下个阙值(当前键值对数量达到这个值后进行`resize()`(扩容)操作)(threshold = capacity * load factor)\n+ loadFactor:　实际的负载因子\n\n\n\n## 哈希码计算方法`hash(Object key)`\n\n        static final int hash(Object key) {\n            int h;\n            return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n        }\n\n+ 局部变量h存放hashCode()放回的初始哈希码,通过h右移16位与h异或(右移后,前16位为0,异或不改变h的前16位值)得到最终的哈希吗.<br/>\n通过高位参与位运算可以减少数组长度较低时的哈希码冲突问题(取模时,高位变低位不变,冲突几率会变高)\n\n\n## 链表结点的数据结构`Node<K,V>`\n\n        static class Node<K,V> implements Map.Entry<K,V> {\n            final int hash; // 计算得到的hash码\n            final K key;    // 键对象\n            V value;        // 值对象\n            Node<K,V> next; // 下一个结点\n            方法略...\n        }\n\n## 树节点数据结构v`TreeNode<K,V>`\n\n        static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {\n            TreeNode<K,V> parent;  // 父亲节点\n            TreeNode<K,V> left;    // 左子树\n            TreeNode<K,V> right;   //右子树\n            TreeNode<K,V> prev;    // needed to unlink next upon deletion\n            boolean red;            // 红色还是黑色\n            TreeNode(int hash, K key, V val, Node<K,V> next) {\n                super(hash, key, val, next);\n            方法略...    \n        }\n\n+ 通过继承`LinkedHashMap.Entry<K,V>`,实际上间接继承了链表的`Node<K,V>`\n\n## 获取value:get(Object key)\n\n        public V get(Object key) {\n            Node<K,V> e;\n            return (e = getNode(hash(key), key)) == null ? null : e.value;      //1\n        }\n    \n        final Node<K,V> getNode(int hash, Object key) {\n            Node<K,V>[] tab;\n            Node<K,V> first, e;\n            int n;\n            K k;\n            if ((tab = table) != null && (n = tab.length) > 0 &&\n                (first = tab[(n - 1) & hash]) != null) {                        //2\n                if (first.hash == hash && // always check first node\n                    ((k = first.key) == key || (key != null && key.equals(k)))) //3\n                    return first;\n                if ((e = first.next) != null) {                                 //4\n                    if (first instanceof TreeNode)\n                        return ((TreeNode<K,V>)first).getTreeNode(hash, key);\n                    do {\n                        if (e.hash == hash &&\n                            ((k = e.key) == key || (key != null && key.equals(k))))\n                            return e;\n                    } while ((e = e.next) != null);\n                }\n            }\n            return null;\n        }\n\n1. 计算key的哈希码,传入getNode方法,放回Node对象或者null\n2. 如果table为null,table是空的或者数组( (length-1)&hash )处的值为null,就返回null,否则进入3\n3. 检查第一个结点,若是指定的key,直接返回该结点,否则进入4\n4. 如果这个树/链表不止一个结点,先判断是树还是链表,再进行对应的结点查找,找到就返回,否则返回null.\n\n## 增加键值对`put(K key, V value)`\n\n        public V put(K key, V value) {\n            return putVal(hash(key), key, value, false, true);\n        }\n    \n        /**\n        * Implements Map.put and related methods\n        *\n        * @param hash hash for key\n        * @param key the key\n        * @param value the value to put\n        * @param onlyIfAbsent if true, don\'t change existing value\n        * @param evict if false, the table is in creation mode.\n        * @return previous value, or null if none\n        */\n        final V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                    boolean evict) {\n            Node<K,V>[] tab;\n            Node<K,V> p;\n            int n, i;\n            if ((tab = table) == null || (n = tab.length) == 0)             //1\n                n = (tab = resize()).length;\n            if ((p = tab[i = (n - 1) & hash]) == null)                      //2\n                tab[i] = newNode(hash, key, value, null);\n            else {\n                Node<K,V> e; K k;\n                if (p.hash == hash &&\n                    ((k = p.key) == key || (key != null && key.equals(k)))) //3\n                    e = p;\n                else if (p instanceof TreeNode)                             //4\n                    e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n                else {                                                      //5\n                    for (int binCount = 0; ; ++binCount) {\n                        if ((e = p.next) == null) {                         \n                            p.next = newNode(hash, key, value, null);\n                            if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                                treeifyBin(tab, hash);\n                            break;\n                        }\n                        if (e.hash == hash &&\n                            ((k = e.key) == key || (key != null && key.equals(k))))\n                            break;\n                        p = e;\n                    }\n                }\n                if (e != null) { // existing mapping for key                //6\n                    V oldValue = e.value;\n                    if (!onlyIfAbsent || oldValue == null)\n                        e.value = value;\n                    afterNodeAccess(e);\n                    return oldValue;\n                }\n            }                                                               //7\n            ++modCount;\n            if (++size > threshold)\n                resize();\n            afterNodeInsertion(evict);\n            return null;\n        }\n\n1. 如果数组为null或是空的,则`resize()`扩充容量\n2. 通过hash计算并位运算取摸获得数组下标,若该位置是空的,新建链表结点直接填坑然后跳到7,否则进入3\n3. 判断头结点的key跟要put进去的key是否同一个,是则将其引用赋给e,进入6,否则进入4\n4. 判断头结点是不是树结点,是则执行`putTreeVal`,若树中已存在该key,则直接返回该键值对(赋给e),否则新建并插入结点并返回null,然后进入6.如果不是树节点则进入5\n5. 在链表中遍历,如果不存在,就新建一个结点,然后是否达到树化的阙值,是就转化为树结构,之后跳到7.如果存在就把它的引用赋给e跳到6\n6. 在搜索到当前map中存在相同key时候将该键值对赋给e,在这里进行值的覆盖,并返回旧值\n7. 对改动进行计数,判断是否需要进行数组扩容,返回null\n\n\n## 移除键值对`remove(Object key)`\n\n        public V remove(Object key) {\n            Node<K,V> e;\n            return (e = removeNode(hash(key), key, null, false, true)) == null ?\n                null : e.value;\n        }\n    \n        final Node<K,V> removeNode(int hash, Object key, Object value,\n                                boolean matchValue, boolean movable) {\n            Node<K,V>[] tab;\n            Node<K,V> p;\n            int n,index;\n            if ((tab = table) != null && (n = tab.length) > 0 &&            //1\n                (p = tab[index = (n - 1) & hash]) != null) {\n                Node<K,V> node = null, e;\n                K k;\n                V v;\n                if (p.hash == hash &&\n                    ((k = p.key) == key || (key != null && key.equals(k)))) //2\n                    node = p;\n                else if ((e = p.next) != null) {                            //3\n                    if (p instanceof TreeNode)\n                        node = ((TreeNode<K,V>)p).getTreeNode(hash, key);\n                    else {\n                        do {\n                            if (e.hash == hash &&\n                                ((k = e.key) == key ||\n                                (key != null && key.equals(k)))) {\n                                node = e;\n                                break;\n                            }\n                            p = e;\n                        } while ((e = e.next) != null);\n                    }\n                }\n                if (node != null && (!matchValue || (v = node.value) == value ||    //4\n                                    (value != null && value.equals(v)))) {\n                    if (node instanceof TreeNode)\n                        ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);\n                    else if (node == p)\n                        tab[index] = node.next;\n                    else\n                        p.next = node.next;\n                    ++modCount;\n                    --size;\n                    afterNodeRemoval(node);\n                    return node;\n                }\n            }\n            return null;\n        }\n\n1. 判断底层数组是否为null或者是空的,是就直接返回null,否则2\n2. 判断头结点是否就是要移除的键值对,是就赋给e,进入4,否则进入3\n3. 判断是树还是链表并进行相应遍历,找到符合的键值对,并赋给e,进入4,若查无,返回null\n4. 针对不同的存储结构进行相应的移除操作,并更新相关的计数值\n\n## 链表的树化操作`treeifyBin(Node<K,V>[] tab, int hash)`\n\n        /**\n        * Replaces all linked nodes in bin at index for given hash unless\n        * table is too small, in which case resizes instead.\n        */\n        final void treeifyBin(Node<K,V>[] tab, int hash) {\n            int n, index; Node<K,V> e;\n            if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)\n                resize();\n            else if ((e = tab[index = (n - 1) & hash]) != null) {\n                TreeNode<K,V> hd = null, tl = null;\n                do {\n                    TreeNode<K,V> p = replacementTreeNode(e, null);\n                    if (tl == null)\n                        hd = p;\n                    else {\n                        p.prev = tl;\n                        tl.next = p;\n                    }\n                    tl = p;\n                } while ((e = e.next) != null);\n                if ((tab[index] = hd) != null)\n                    hd.treeify(tab);\n            }\n        }\n\n+ 先将链表结点转化成树结点,构造成双向链表,在`treeify`进行红黑树的构造\n\n## 扩容操作`resize`\n\n        /**\n        * Initializes or doubles table size.  If null, allocates in\n        * accord with initial capacity target held in field threshold.\n        * Otherwise, because we are using power-of-two expansion, the\n        * elements from each bin must either stay at same index, or move\n        * with a power of two offset in the new table.\n        *\n        * @return the table\n        */\n        final Node<K,V>[] resize() {\n            Node<K,V>[] oldTab = table;\n            int oldCap = (oldTab == null) ? 0 : oldTab.length;\n            int oldThr = threshold;\n            int newCap, newThr = 0;\n            if (oldCap > 0) {\n                if (oldCap >= MAXIMUM_CAPACITY) {                           // 1\n                    threshold = Integer.MAX_VALUE;\n                    return oldTab;\n                }\n                else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&       // 2\n                        oldCap >= DEFAULT_INITIAL_CAPACITY)\n                    newThr = oldThr << 1; // double threshold\n            }\n            else if (oldThr > 0) // initial capacity was placed in threshold    // 3\n                newCap = oldThr;\n            else {               // zero initial threshold signifies using defaults // 4\n                newCap = DEFAULT_INITIAL_CAPACITY;\n                newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n            }\n            if (newThr == 0) {                                                      // 5\n                float ft = (float)newCap * loadFactor;\n                newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                        (int)ft : Integer.MAX_VALUE);\n            }\n            threshold = newThr;                                                     // 6\n            @SuppressWarnings({\"rawtypes\",\"unchecked\"})\n                Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];\n            table = newTab;\n            if (oldTab != null) {                                                   // 7\n                for (int j = 0; j < oldCap; ++j) {\n                    Node<K,V> e;\n                    if ((e = oldTab[j]) != null) {\n                        oldTab[j] = null;\n                        if (e.next == null)                                         // 7-1\n                            newTab[e.hash & (newCap - 1)] = e;\n                        else if (e instanceof TreeNode)                             // 7-2\n                            ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n                        else { // preserve order                                    // 7-3\n                            Node<K,V> loHead = null, loTail = null;\n                            Node<K,V> hiHead = null, hiTail = null;\n                            Node<K,V> next;\n                            do {\n                                next = e.next;\n                                if ((e.hash & oldCap) == 0) {\n                                    if (loTail == null)\n                                        loHead = e;\n                                    else\n                                        loTail.next = e;\n                                    loTail = e;\n                                }\n                                else {\n                                    if (hiTail == null)\n                                        hiHead = e;\n                                    else\n                                        hiTail.next = e;\n                                    hiTail = e;\n                                }\n                            } while ((e = next) != null);\n                            if (loTail != null) {\n                                loTail.next = null;\n                                newTab[j] = loHead;\n                            }\n                            if (hiTail != null) {\n                                hiTail.next = null;\n                                newTab[j + oldCap] = hiHead;\n                            }\n                        }\n                    }\n                }\n            }\n            return newTab;\n        }\n\n1. 若底层数组长度大于等于允许的最大值,将扩容阙值设为MAX_INT,直接不做任何操作,直接返回原数组\n2. 如果底层数组长度是大于默认初始长度且当前长度*2小于允许的最大值,则将新的数组长度,扩容阙值都设为原来的两倍\n3. 当前数组未初始化,且扩容阙值已经初始化(不为0),将新的数组长度设定为扩容阙值,跳到5\n4. 当前数组与扩容阙值都未初始化,将新的数组长度和扩容阙值设为默认初始值\n5. 根据新的数组长度值计算新的扩容阙值,如果新的数组长度值或者新的阙值大于数组长度的允许最大值,则将其替换为MAX_INT,反之保留\n6. 将经过上述计算得到的新值进行更新(设置threshold为新值, 实例化一个新长度的底层数组)\n7. 遍历数组的每个坑位,将老数组的值搬运到新的数组中\n7-1. 若该坑位只有一个结点,直接搬运到新数组对应坑位,需要重新计算下标,因为新数组的长度已经改变\n7-2. 若该坑位放的是树,则调用对应方法进行换坑\n7-3. 若该坑位是是链表,遍历这条链表,根据其hash&旧数组长度是0还是1分为两组,一组在新数组下标不变,另一组是原来下标+旧数组长度<br/>\n注: 因为每次扩容都是2扩容两倍,位运算时只增加一个高位(右数第oldCap个),按位与时,若键值对的右数第oldCap位是0则下标不会受扩容影响,若不是,则下标是原下标加上oldCap.\n', '', 0, 'HashMap底层是数组+链表(数组的每个值都是一条链表的头结点),1.8后加入了红黑树(当链表长度达到8就自动将该链表替换为红黑树),通过计算key的哈希码,在经过高位参与位运算计算得出键值对(将key和value包装起来的对象)所在的数组的下标,采用头插入法插入该位置的链表(若该位置是空的就直接插入)', '', '', 'HashMap源码解析(jdk8版)', 0, 'HashMap源码解析(jdk8版)', 48, 0, NULL, NULL, 'HashMap源码解析(jdk8版)');
INSERT INTO `posts` VALUES (0, 3, '2019-09-30 17:39:36', 0, '2019-09-30 17:58:00', 0, 0, '2019-09-30 17:58:00', '<h1 id=\"简介\">简介</h1>\n<p>springboot提供了许多的缓存类型，redis缓存配置只需要引入starter,修改相应的配置文件即可。</p>\n<h1 id=\"配置\">配置</h1>\n<ol>\n<li>添加starter</li>\n</ol>\n<pre><code class=\"language-java\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n</code></pre>\n<ol start=\"2\">\n<li>修改配置文件</li>\n</ol>\n<pre><code class=\"language-java\">\nspring:\n  redis:\n    host: 192.168.0.110\n\n</code></pre>\n<ol start=\"3\">\n<li>使用方法</li>\n</ol>\n<p>spingboot 默认有2个模板提供使用</p>\n<ul>\n<li>RedisTemplate    可以存对象 ，默认的序列化方式是jdk的序列化方式</li>\n<li>StringRedisTemplate 只能存字符串</li>\n</ul>\n<p>使用时，只需要注入即可,下面只演示了对象的存储，字符串同理</p>\n<pre><code>    @Autowired\n	RedisTemplate redisTemplate;\n\n    @Autowired\n	StringRedisTemplate stringRedisTemplate;\n\n\n	@Test\n	public void contextLoads() {\n		User user = new User();\n		user.setId(1);\n		user.setName(&quot;哈哈&quot;);\n		redisTemplate.opsForValue().set(&quot;user&quot;,user);\n		User user1 = (User) redisTemplate.opsForValue().get(&quot;user&quot;);\n		System.out.println(user1.getName());\n	}\n\n</code></pre>\n<h1 id=\"序列化json存储\">序列化json存储</h1>\n<ol>\n<li>新建JsonRedisTemplate</li>\n</ol>\n<pre><code>public class JsonRedisTemplate extends RedisTemplate {\n}\n</code></pre>\n<ol start=\"2\">\n<li>创建redis配置类</li>\n</ol>\n<pre><code class=\"language-java\">    @Configuration\n    public class RedisConfigtion {\n        @Bean\n        public JsonRedisTemplate cacheManager(RedisConnectionFactory redisConnectionFactory,\n                                            ResourceLoader resourceLoader) {\n            JsonRedisTemplate redisTemplate = new JsonRedisTemplate();\n            redisTemplate.setConnectionFactory(redisConnectionFactory);\n            //设置键的序列化为字符串\n            redisTemplate.setKeySerializer(new StringRedisSerializer());\n            //设置值得序列化为JSON\n            redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class));\n            return redisTemplate;\n        }\n    }\n\n</code></pre>\n<p><strong>注意：如果需要序列化其他类型，改变序列化参数即可</strong></p>\n<ol start=\"3\">\n<li>使用例子</li>\n</ol>\n<pre><code>    @Autowired\n	JsonRedisTemplate jsonRedisTemplate;\n\n	@Test\n	public void testRedis() throws JSONException {\n		User user = new User();user.setId(1);\n		user.setName(&quot;哈哈&quot;);\n		jsonRedisTemplate.opsForValue().set(&quot;user&quot;,user);\n		Object obj = jsonRedisTemplate.opsForValue().get(&quot;user&quot;);\n		LinkedHashMap map = (LinkedHashMap) obj;\n		JSONObject json = new JSONObject(map);\n		System.out.println(json.getString(&quot;name&quot;));\n	}\n</code></pre>\n<h1 id=\"总结\">总结</h1>\n<p>这只是一个简单的配置用法，springboot的详细用法需要参照其他文档使用。</p>\n', 0, '# 简介\nspringboot提供了许多的缓存类型，redis缓存配置只需要引入starter,修改相应的配置文件即可。\n\n# 配置\n1. 添加starter\n\n```java\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n\n```\n\n2. 修改配置文件\n\n```java\n\nspring:\n  redis:\n    host: 192.168.0.110\n\n```\n\n3. 使用方法\n\nspingboot 默认有2个模板提供使用\n+ RedisTemplate    可以存对象 ，默认的序列化方式是jdk的序列化方式\n+ StringRedisTemplate 只能存字符串\n\n\n使用时，只需要注入即可,下面只演示了对象的存储，字符串同理\n```\n    @Autowired\n	RedisTemplate redisTemplate;\n\n    @Autowired\n	StringRedisTemplate stringRedisTemplate;\n\n\n	@Test\n	public void contextLoads() {\n		User user = new User();\n		user.setId(1);\n		user.setName(\"哈哈\");\n		redisTemplate.opsForValue().set(\"user\",user);\n		User user1 = (User) redisTemplate.opsForValue().get(\"user\");\n		System.out.println(user1.getName());\n	}\n\n```\n\n# 序列化json存储\n\n1. 新建JsonRedisTemplate\n```\npublic class JsonRedisTemplate extends RedisTemplate {\n}\n```\n\n2. 创建redis配置类\n```java\n    @Configuration\n    public class RedisConfigtion {\n        @Bean\n        public JsonRedisTemplate cacheManager(RedisConnectionFactory redisConnectionFactory,\n                                            ResourceLoader resourceLoader) {\n            JsonRedisTemplate redisTemplate = new JsonRedisTemplate();\n            redisTemplate.setConnectionFactory(redisConnectionFactory);\n            //设置键的序列化为字符串\n            redisTemplate.setKeySerializer(new StringRedisSerializer());\n            //设置值得序列化为JSON\n            redisTemplate.setValueSerializer(new Jackson2JsonRedisSerializer<Object>(Object.class));\n            return redisTemplate;\n        }\n    }\n\n```\n\n**注意：如果需要序列化其他类型，改变序列化参数即可**\n\n3. 使用例子\n\n```\n    @Autowired\n	JsonRedisTemplate jsonRedisTemplate;\n\n	@Test\n	public void testRedis() throws JSONException {\n		User user = new User();user.setId(1);\n		user.setName(\"哈哈\");\n		jsonRedisTemplate.opsForValue().set(\"user\",user);\n		Object obj = jsonRedisTemplate.opsForValue().get(\"user\");\n		LinkedHashMap map = (LinkedHashMap) obj;\n		JSONObject json = new JSONObject(map);\n		System.out.println(json.getString(\"name\"));\n	}\n```\n\n# 总结\n这只是一个简单的配置用法，springboot的详细用法需要参照其他文档使用。', '', 0, 'springboot提供了许多的缓存类型，redis缓存配置只需要引入starter,修改相应的配置文件即可。', '', '', 'springboot配置redis 缓存', 0, 'springboot配置redis 缓存', 36, 0, NULL, NULL, 'springboot配置redis 缓存');
INSERT INTO `posts` VALUES (0, 4, '2019-09-30 17:49:50', 0, '2019-09-30 17:51:07', 0, 0, '2019-09-30 17:51:07', '<h1 id=\"简介\">简介</h1>\n<p>本文讲解配置springBoot的3种任务，异步任务，定时任务，邮件任务的基本配置。</p>\n<h1 id=\"异步任务\">异步任务</h1>\n<ol>\n<li>在主入口开启异步任务配置</li>\n</ol>\n<pre><code class=\"language-java\">@EnableAsync //开启异步注解\n@SpringBootApplication\npublic class SpringbootApplication {\n	public static void main(String[] args) {\n		SpringApplication.run(SpringbootApplication.class, args);\n	}\n}\n</code></pre>\n<ol start=\"2\">\n<li>通过<code>@Async</code>声明一个异步任务</li>\n</ol>\n<pre><code class=\"language-java\">@Service\npublic class TeskService {\n\n    @Async\n    public void asyncService(){\n        System.out.println(&quot;异步任务处理数据&quot;);\n    }\n}\n</code></pre>\n<h1 id=\"定时任务\">定时任务</h1>\n<ol>\n<li>程序主入口开启定时任务</li>\n</ol>\n<pre><code class=\"language-java\">@EnableScheduling  //开启基于注解的定时任务\n@SpringBootApplication\npublic class SpringbootApplication {\n	public static void main(String[] args) {\n		SpringApplication.run(SpringbootApplication.class, args);\n	}\n}\n</code></pre>\n<ol start=\"2\">\n<li>配置定时任务</li>\n</ol>\n<pre><code class=\"language-java\">\n@Service\npublic class TeskService {\n    @Scheduled(cron=&quot;0/4 * * * * *&quot;)\n    public void timeService(){\n        System.out.println(&quot;每4秒执行一次，执行定时器了！&quot;);\n    }\n\n}\n</code></pre>\n<ol start=\"3\">\n<li>cron的表达式说明</li>\n</ol>\n<ul>\n<li>corn表达是由6位组成，*表示所有。\n6尾数分别表示这几个时间\nsecond(秒), minute（分）, hour（时）, day of month（日）, month（月）, day of week（周几）</li>\n</ul>\n<ol>\n<li>\n<p>corn表达是各个字段的允许值\n|字段|允许值|允许的特殊符号|\n|:----|:------|-------|\n|秒 |0-59 |, - * /|\n|分 |0-59 |, - * /|\n|小时 |0-23| , - * /|\n|日期 |1-31 |, - * ? / L W C|\n|月份 |1-12| , - * /|\n|星期| 0-7或SUN-SAT 0,7是SUN |, - * ? / L C #|</p>\n</li>\n<li>\n<p>特殊符号代表的含义\n|符号|含义|\n|----|----|\n|, |枚举\n|- |区间\n|* |任意\n|/ |步长\n|? |日/星期冲突匹配\n|L |最后\n|W |工作日\n|C |和calendar联系后计算过的值\n|# |星期，4#2，第2个星期四</p>\n</li>\n</ol>\n<ul>\n<li>一些例子用于解释</li>\n</ul>\n<pre><code class=\"language-java\">【0 0/5 14,18 * * ?】 每天14点整，和18点整，每隔5分钟执行一次\n【0 15 10 ? * 1-6】 每个月的周一至周六10:15分执行一次\n【0 0 2 ? * 6L】每个月的最后一个周六凌晨2点执行一次\n【0 0 2 LW * ?】每个月的最后一个工作日凌晨2点执行一次\n【0 0 2-4 ? * 1#1】每个月的第一个周一凌晨2点到4点期间，每个整点都执行一次；\n【0 * * * * MON-SAT】星期一到星期6  每到整秒都执行\n【0,1,2,3,4 * * * * MON-SAT】星期一到星期6  每到整0，1，2，3，4秒都执行0-4 这个同理\n</code></pre>\n<h1 id=\"邮件任务\">邮件任务</h1>\n<ol>\n<li>在pom.xml里面引入邮件启动器</li>\n</ol>\n<pre><code class=\"language-java\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<ol start=\"2\">\n<li>在配置文件里面配置相应信息</li>\n</ol>\n<pre><code>spring:\n  mail:\n    #用户名\n    username: 1227900499@qq.com\n    #这个密码不是邮箱的登录密码，需要在邮箱服务器里面去生成的授权吗，qq邮箱在qq 里面的 设置--&gt;账户里面\n    password: xxxxxxx\n    #qq服务器是下面这个，其他的服务器需要到相应的地方去找，qq qq在QQ邮箱----&gt;设置---账户里面去找\n    host: smtp.qq.com\n\n</code></pre>\n<ol start=\"3\">\n<li>事例代码</li>\n</ol>\n<pre><code>@Autowired\nJavaMailSenderImpl mailSender;\n\n//简单邮件测试\n@Test\npublic void sendMailTest() {\n    SimpleMailMessage message = new SimpleMailMessage();\n    //设置邮件的基本信息\n    message.setSubject(&quot;简单邮件发送测试&quot;);\n    message.setText(&quot;我是测试内容&quot;);\n\n    message.setTo(&quot;325811402@qq.com&quot;);\n    message.setFrom(&quot;1227900499@qq.com&quot;);\n\n    mailSender.send(message);\n}\n\n//带文件的邮件发送测试\n@Test\npublic void sendMailTest2() throws  Exception{\n    //1、创建一个复杂的消息邮件\n    MimeMessage mimeMessage = mailSender.createMimeMessage();\n    MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, true);\n\n    //邮件设置\n    helper.setSubject(&quot;邮件测试&quot;);\n    //可以加html 标签，单第二个参数要为true ,把html 标签功能开启\n    helper.setText(&quot;&lt;b style=\'color:red\'&gt;邮件测试类容，可以加标签哦&lt;/b&gt;，哈哈&quot;,true);\n\n    helper.setTo(&quot;325811402@qq.com&quot;);\n    helper.setFrom(&quot;1227900499@qq.com&quot;);\n\n    //上传文件\n    helper.addAttachment(&quot;1.jpg&quot;,new File(&quot;C:\\\\Users\\\\Administrator.BF-20180801KGCC\\\\Desktop\\\\头像\\\\1.jpg&quot;));\n    helper.addAttachment(&quot;2.jpg&quot;,new File(&quot;C:\\\\Users\\\\Administrator.BF-20180801KGCC\\\\Desktop\\\\头像\\\\2.jpg&quot;));\n\n    mailSender.send(mimeMessage);\n}\n</code></pre>\n', 0, '# 简介\n本文讲解配置springBoot的3种任务，异步任务，定时任务，邮件任务的基本配置。\n\n# 异步任务\n1. 在主入口开启异步任务配置\n```java\n@EnableAsync //开启异步注解\n@SpringBootApplication\npublic class SpringbootApplication {\n	public static void main(String[] args) {\n		SpringApplication.run(SpringbootApplication.class, args);\n	}\n}\n```\n\n2. 通过`@Async`声明一个异步任务\n```java\n@Service\npublic class TeskService {\n\n    @Async\n    public void asyncService(){\n        System.out.println(\"异步任务处理数据\");\n    }\n}\n```\n\n# 定时任务\n1. 程序主入口开启定时任务\n```java\n@EnableScheduling  //开启基于注解的定时任务\n@SpringBootApplication\npublic class SpringbootApplication {\n	public static void main(String[] args) {\n		SpringApplication.run(SpringbootApplication.class, args);\n	}\n}\n```\n\n2. 配置定时任务\n```java\n\n@Service\npublic class TeskService {\n    @Scheduled(cron=\"0/4 * * * * *\")\n    public void timeService(){\n        System.out.println(\"每4秒执行一次，执行定时器了！\");\n    }\n\n}\n```\n3. cron的表达式说明\n* corn表达是由6位组成，*表示所有。\n6尾数分别表示这几个时间\nsecond(秒), minute（分）, hour（时）, day of month（日）, month（月）, day of week（周几）\n\n1. corn表达是各个字段的允许值\n|字段|允许值|允许的特殊符号|\n|:----|:------|-------|\n|秒 |0-59 |, - * /|\n|分 |0-59 |, - * /|\n|小时 |0-23| , - * /|\n|日期 |1-31 |, - * ? / L W C|\n|月份 |1-12| , - * /|\n|星期| 0-7或SUN-SAT 0,7是SUN |, - * ? / L C #|\n\n2. 特殊符号代表的含义\n|符号|含义|\n|----|----|\n|, |枚举\n|- |区间\n|* |任意\n|/ |步长\n|? |日/星期冲突匹配\n|L |最后\n|W |工作日\n|C |和calendar联系后计算过的值\n|# |星期，4#2，第2个星期四\n\n* 一些例子用于解释\n```java\n【0 0/5 14,18 * * ?】 每天14点整，和18点整，每隔5分钟执行一次\n【0 15 10 ? * 1-6】 每个月的周一至周六10:15分执行一次\n【0 0 2 ? * 6L】每个月的最后一个周六凌晨2点执行一次\n【0 0 2 LW * ?】每个月的最后一个工作日凌晨2点执行一次\n【0 0 2-4 ? * 1#1】每个月的第一个周一凌晨2点到4点期间，每个整点都执行一次；\n【0 * * * * MON-SAT】星期一到星期6  每到整秒都执行\n【0,1,2,3,4 * * * * MON-SAT】星期一到星期6  每到整0，1，2，3，4秒都执行0-4 这个同理\n```\n\n# 邮件任务\n1. 在pom.xml里面引入邮件启动器\n```java\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-mail</artifactId>\n</dependency>\n```\n\n2. 在配置文件里面配置相应信息\n```\nspring:\n  mail:\n    #用户名\n    username: 1227900499@qq.com\n    #这个密码不是邮箱的登录密码，需要在邮箱服务器里面去生成的授权吗，qq邮箱在qq 里面的 设置-->账户里面\n    password: xxxxxxx\n    #qq服务器是下面这个，其他的服务器需要到相应的地方去找，qq qq在QQ邮箱---->设置---账户里面去找\n    host: smtp.qq.com\n\n```\n\n3. 事例代码\n```\n@Autowired\nJavaMailSenderImpl mailSender;\n\n//简单邮件测试\n@Test\npublic void sendMailTest() {\n    SimpleMailMessage message = new SimpleMailMessage();\n    //设置邮件的基本信息\n    message.setSubject(\"简单邮件发送测试\");\n    message.setText(\"我是测试内容\");\n\n    message.setTo(\"325811402@qq.com\");\n    message.setFrom(\"1227900499@qq.com\");\n\n    mailSender.send(message);\n}\n\n//带文件的邮件发送测试\n@Test\npublic void sendMailTest2() throws  Exception{\n    //1、创建一个复杂的消息邮件\n    MimeMessage mimeMessage = mailSender.createMimeMessage();\n    MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, true);\n\n    //邮件设置\n    helper.setSubject(\"邮件测试\");\n    //可以加html 标签，单第二个参数要为true ,把html 标签功能开启\n    helper.setText(\"<b style=\'color:red\'>邮件测试类容，可以加标签哦</b>，哈哈\",true);\n\n    helper.setTo(\"325811402@qq.com\");\n    helper.setFrom(\"1227900499@qq.com\");\n\n    //上传文件\n    helper.addAttachment(\"1.jpg\",new File(\"C:\\\\Users\\\\Administrator.BF-20180801KGCC\\\\Desktop\\\\头像\\\\1.jpg\"));\n    helper.addAttachment(\"2.jpg\",new File(\"C:\\\\Users\\\\Administrator.BF-20180801KGCC\\\\Desktop\\\\头像\\\\2.jpg\"));\n\n    mailSender.send(mimeMessage);\n}\n```', '', 0, '本文讲解配置springBoot的3种任务，异步任务，定时任务，邮件任务的基本配置。', '', '', 'springBoot配置异步任务，定时任务和邮件任务', 0, 'pringBoot', 51, 0, NULL, NULL, 'pringBoot');
INSERT INTO `posts` VALUES (0, 5, '2019-10-24 17:29:07', 0, '2019-10-24 17:30:03', 0, 0, '2019-10-24 17:30:03', '<h1 id=\"简介\">简介</h1>\n<p>本文档主要用于初学者创建netty案列学习和测试使用。本案例用到的maven版本是4.1.38，上面的很多注释解释了netty的使用方法，线程模型登，是netty入门的不二之选。</p>\n<h1 id=\"添加项目依赖\">添加项目依赖</h1>\n<p>新建maven工程，并在破灭。xml里面添加项目依赖。</p>\n<pre><code>&lt;properties&gt;\n    &lt;netty-all.version&gt;4.1.38.Final&lt;/netty-all.version&gt;\n&lt;/properties&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.netty&lt;/groupId&gt;\n        &lt;artifactId&gt;netty-all&lt;/artifactId&gt;\n        &lt;version&gt;${netty-all.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>\n<h1 id=\"常见服务端的环境\">常见服务端的环境</h1>\n<p>这里都都不详解的介绍包的结构了，安需安排就可以了。</p>\n<h2 id=\"常见socketserver用于初始化socket配置和启动\">常见SocketServer,用于初始化socket配置和启动</h2>\n<pre><code>/**\n * 1. 双线程组\n * 2. Bootstrap配置启动信息\n * 3. 注册业务处理Handler\n * 4. 绑定服务监听端口并启动服务\n */\npackage cn.javafroum.netty.server;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelHandler;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.ChannelOption;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\n\n/**\n * @author BlackBox\n */\npublic class SocketServer {\n	// 监听线程组，监听客户端请求\n	private EventLoopGroup acceptorGroup = null;\n	// 处理客户端相关操作线程组，负责处理与客户端的数据通讯\n	private EventLoopGroup clientGroup = null;\n	// 服务启动相关配置信息\n	private ServerBootstrap bootstrap = null;\n	public SocketServer(){\n		init();\n	}\n	private void init(){\n		//这里将一下线程模型的配置\n		//netty里面有3种线程模型 1.单线程模型 2.多线程模型  3.主从多线程模型\n		//1. 单线程模型，即是接受线程组和处理线程组都为同一个并且只有一个线程，只需要更改如下配置\n		//acceptorGroup = new NioEventLoopGroup();\n		//bootstrap.group(acceptorGroup, acceptorGroup);\n\n		//2.多线程模型，即是接受线程只有一个，处理线程有多个\n		//acceptorGroup = new NioEventLoopGroup(1);\n		//clientGroup = new NioEventLoopGroup();\n		//bootstrap.group(acceptorGroup, clientGroup);\n\n		//3.主从多线程模型,即是下面这种配置，接受线程多个，处理线程也是多个\n		// 初始化线程组,构建线程组的时候，如果不传递参数，则默认构建的线程组线程数是CPU核心数量。\n		acceptorGroup = new NioEventLoopGroup();\n		clientGroup = new NioEventLoopGroup();\n		// 初始化服务的配置\n		bootstrap = new ServerBootstrap();\n		// 绑定线程组\n		bootstrap.group(acceptorGroup, clientGroup);\n		// 设定通讯模式为NIO， 同步非阻塞\n		bootstrap.channel(NioServerSocketChannel.class);\n		// 设定缓冲区大小， 缓存区的单位是字节。\n		bootstrap.option(ChannelOption.SO_BACKLOG, 1024);\n		// SO_SNDBUF发送缓冲区\n		// SO_RCVBUF接收缓冲区\n		// SO_KEEPALIVE开启心跳监测（保证连接有效）\n		bootstrap.option(ChannelOption.SO_SNDBUF, 16*1024)\n			.option(ChannelOption.SO_RCVBUF, 16*1024)\n			.option(ChannelOption.SO_KEEPALIVE, true);\n	}\n\n	/**\n	 * 监听处理逻辑。\n	 * @param port 监听端口。\n	 * @param acceptorHandlers 处理器， 如何处理客户端请求。\n	 * @return\n	 * @throws InterruptedException\n	 */\n	public ChannelFuture doAccept(int port, final ChannelHandler... acceptorHandlers) throws InterruptedException{\n		\n		/*\n		 * childHandler是服务的Bootstrap独有的方法。是用于提供处理对象的。\n		 * 可以一次性增加若干个处理逻辑。是类似责任链模式的处理方式。\n		 * 增加A，B两个处理逻辑，在处理客户端请求数据的时候，根据A-》B顺序依次处理。\n		 * \n		 * ChannelInitializer - 用于提供处理器的一个模型对象。\n		 *  其中定义了一个方法，initChannel方法。\n		 *   方法是用于初始化处理逻辑责任链条的。\n		 *   可以保证服务端的Bootstrap只初始化一次处理器，尽量提供处理逻辑的重用。\n		 *   避免反复的创建处理器对象。节约资源开销。\n		 */\n		bootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {\n\n			@Override\n			protected void initChannel(SocketChannel ch) throws Exception {\n				ch.pipeline().addLast(acceptorHandlers);\n			}\n		});\n		// bind方法 - 绑定监听端口的。ServerBootstrap可以绑定多个监听端口。 多次调用bind方法即可\n		// sync - 开始监听逻辑。 返回一个ChannelFuture。 返回结果代表的是监听成功后的一个对应的未来结果\n		// 可以使用ChannelFuture实现后续的服务器和客户端的交互。\n		ChannelFuture future = bootstrap.bind(port).sync();\n		return future;\n	}\n	\n	/**\n	 * shutdownGracefully - 方法是一个安全关闭的方法。可以保证不放弃任何一个已接收的客户端请求。\n	 */\n	public void release(){\n		this.acceptorGroup.shutdownGracefully();\n		this.clientGroup.shutdownGracefully();\n	}\n}\n\n</code></pre>\n<h2 id=\"参见测试handler方便我们处理客服端传来的消息\">参见测试handler,方便我们处理客服端传来的消息</h2>\n<pre><code>package cn.javafroum.netty.server.handler;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandler;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\n\nimport java.io.UnsupportedEncodingException;\n\n\n//Sharable 注解的说明：\n//作用:多个客服端可以共用这个实例，但要注意的是，不能再里面声明变量，这样不安全，声明了变量的话，\n//多个客服端用这边变量会导致不安全\n@ChannelHandler.Sharable\npublic class DiscardServerHandler extends ChannelInboundHandlerAdapter { // (1)\n\n    /**\n     * 业务处理逻辑\n     * 用于处理读取数据请求的逻辑。\n     * msg - 读取到的数据。 默认类型是ByteBuf，是Netty自定义的。是对ByteBuffer的封装。 不需要考虑复位问题。\n     */\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws UnsupportedEncodingException { // (2)\n\n        //ctx - 上下文对象。其中包含于客户端建立连接的所有资源。 如： 对应的Channel\n        System.out.println(&quot;通道id:&quot; + ctx.channel().id().asLongText());\n\n\n        // 获取读取的数据， 是一个缓冲。\n        ByteBuf readBuffer = (ByteBuf) msg;\n        // 创建一个字节数组，用于保存缓存中的数据。\n        byte[] tempDatas = new byte[readBuffer.readableBytes()];\n        // 将缓存中的数据读取到字节数组中。\n        readBuffer.readBytes(tempDatas);\n        String message = new String(tempDatas, &quot;UTF-8&quot;);\n        System.out.println(&quot;收到客服端的消息 : &quot; + message);\n        if(&quot;exit&quot;.equals(message)){\n            ctx.close();\n            return;\n        }\n        String line = &quot;服务端接收到了客服端的消息 : &quot; + message + &quot;  这是返回确认&quot;;\n        // 写操作自动释放缓存，避免内存溢出问题。\n        ctx.writeAndFlush(Unpooled.copiedBuffer(line.getBytes(&quot;UTF-8&quot;)));\n        // 注意，如果调用的是write方法。不会刷新缓存，缓存中的数据不会发送到客户端，必须再次调用flush方法才行。\n        // ctx.write(Unpooled.copiedBuffer(line.getBytes(&quot;UTF-8&quot;)));\n        // ctx.flush();\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { // (4)\n        // Close the connection when an exception is raised.\n        System.out.println(&quot;server exceptionCaught method run...&quot;);\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n</code></pre>\n<h2 id=\"创建启动类\">创建启动类</h2>\n<pre><code>package cn.javafroum.netty.server;\n\nimport cn.javafroum.netty.server.handler.DiscardServerHandler;\nimport io.netty.channel.ChannelFuture;\n\npublic class StartupServer {\n    public static void main(String[] args){\n        ChannelFuture future = null;\n        SocketServer server = null;\n        try{\n            server = new SocketServer();\n            future = server.doAccept(9090,new DiscardServerHandler());\n            System.out.println(&quot;socket 服务端开始运行！&quot;);\n            // 关闭连接的。\n            future.channel().closeFuture().sync();\n        }catch(InterruptedException e){\n            e.printStackTrace();\n        }finally{\n            if(null != future){\n                try {\n                    future.channel().closeFuture().sync();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(null != server){\n                server.release();\n            }\n        }\n    }\n}\n\n</code></pre>\n<h1 id=\"客服端结构创建\">客服端结构创建</h1>\n<h2 id=\"创建客服端配置和初始化类\">创建客服端配置和初始化类</h2>\n<pre><code>/**\n * 1. 单线程组\n * 2. Bootstrap配置启动信息\n * 3. 注册业务处理Handler\n * 4. connect连接服务，并发起请求\n */\npackage cn.javafroum.netty.client;\n\nimport java.util.Scanner;\nimport java.util.concurrent.TimeUnit;\n\nimport io.netty.bootstrap.Bootstrap;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelFutureListener;\nimport io.netty.channel.ChannelHandler;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioSocketChannel;\n\n/**\n * 因为客户端是请求的发起者，不需要监听。\n * 只需要定义唯一的一个线程组即可。\n */\npublic class SocketClient {\n	\n	// 处理请求和处理服务端响应的线程组\n	private EventLoopGroup group = null;\n	// 客户端启动相关配置信息\n	private Bootstrap bootstrap = null;\n	\n	public SocketClient(){\n		init();\n	}\n	\n	private void init(){\n		group = new NioEventLoopGroup();\n		bootstrap = new Bootstrap();\n		// 绑定线程组\n		bootstrap.group(group);\n		// 设定通讯模式为NIO\n		bootstrap.channel(NioSocketChannel.class);\n	}\n	\n	public ChannelFuture doRequest(String host, int port, final ChannelHandler... handlers) throws InterruptedException{\n		/*\n		 * 客户端的Bootstrap没有childHandler方法。只有handler方法。\n		 * 方法含义等同ServerBootstrap中的childHandler\n		 * 在客户端必须绑定处理器，也就是必须调用handler方法。\n		 * 服务器必须绑定处理器，必须调用childHandler方法。\n		 */\n		this.bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() {\n			@Override\n			protected void initChannel(SocketChannel ch) throws Exception {\n				ch.pipeline().addLast(handlers);\n			}\n		});\n		// 建立连接。\n		ChannelFuture future = this.bootstrap.connect(host, port).sync();\n		return future;\n	}\n	\n	public void release(){\n		this.group.shutdownGracefully();\n	}\n}\n\n</code></pre>\n<h2 id=\"创建客服端的handler用于处理接收到服务端的返回消息\">创建客服端的handler，用于处理接收到服务端的返回消息</h2>\n<pre><code>package cn.javafroum.netty.client.handler;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerAdapter;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.util.ReferenceCountUtil;\n\npublic class ClientHandler extends ChannelInboundHandlerAdapter {\n\n	@Override\n	public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n		try{\n			ByteBuf readBuffer = (ByteBuf) msg;\n			byte[] tempDatas = new byte[readBuffer.readableBytes()];\n			readBuffer.readBytes(tempDatas);\n			System.out.println(&quot;from server : &quot; + new String(tempDatas, &quot;UTF-8&quot;));\n		}finally{\n			// 用于释放缓存。避免内存溢出\n			ReferenceCountUtil.release(msg);\n		}\n	}\n\n	@Override\n	public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n		System.out.println(&quot;client exceptionCaught method run...&quot;);\n		// cause.printStackTrace();\n		ctx.close();\n	}\n\n	/*@Override // 断开连接时执行\n	public void channelInactive(ChannelHandlerContext ctx) throws Exception {\n		System.out.println(&quot;channelInactive method run...&quot;);\n	}\n\n	@Override // 连接通道建立成功时执行\n	public void channelActive(ChannelHandlerContext ctx) throws Exception {\n		System.out.println(&quot;channelActive method run...&quot;);\n	}\n\n	@Override // 每次读取完成时执行\n	public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\n		System.out.println(&quot;channelReadComplete method run...&quot;);\n	}*/\n\n}\n\n</code></pre>\n<h2 id=\"创建客服端的启动类\">创建客服端的启动类</h2>\n<pre><code>package cn.javafroum.netty.client;\n\nimport cn.javafroum.netty.client.handler.ClientHandler;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelFutureListener;\n\nimport java.util.Scanner;\nimport java.util.concurrent.TimeUnit;\n\npublic class StartupClient {\n    public static void main(String[] args) {\n        SocketClient client = null;\n        ChannelFuture future = null;\n        try{\n            client = new SocketClient();\n            future = client.doRequest(&quot;localhost&quot;, 9090, new ClientHandler());\n\n            Scanner s = null;\n            while(true){\n                s = new Scanner(System.in);\n                System.out.print(&quot;enter message send to server (enter \'exit\' for close client) &gt; &quot;);\n                String line = s.nextLine();\n                if(&quot;exit&quot;.equals(line)){\n                    // addListener - 增加监听，当某条件满足的时候，触发监听器。\n                    // ChannelFutureListener.CLOSE - 关闭监听器，代表ChannelFuture执行返回后，关闭连接。\n                    future.channel().writeAndFlush(Unpooled.copiedBuffer(line.getBytes(&quot;UTF-8&quot;)))\n                            .addListener(ChannelFutureListener.CLOSE);\n                    break;\n                }\n                future.channel().writeAndFlush(Unpooled.copiedBuffer(line.getBytes(&quot;UTF-8&quot;)));\n                TimeUnit.SECONDS.sleep(1);\n            }\n        }catch(Exception e){\n            e.printStackTrace();\n        }finally{\n            if(null != future){\n                try {\n                    future.channel().closeFuture().sync();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(null != client){\n                client.release();\n            }\n        }\n    }\n}\n\n</code></pre>\n<h1 id=\"总结\">总结</h1>\n<p>按照上面的配置创建好相应的客服端和服务端，只需要运行启动类就可以了，代码里面有比较详细的注释，文档上面也都不说明了，源码可以参照<br />\n<a href=\"https://github.com/TBlackBox/study-example\">github学习案列</a></p>\n', 0, '# 简介\n本文档主要用于初学者创建netty案列学习和测试使用。本案例用到的maven版本是4.1.38，上面的很多注释解释了netty的使用方法，线程模型登，是netty入门的不二之选。\n\n# 添加项目依赖\n新建maven工程，并在破灭。xml里面添加项目依赖。\n```\n<properties>\n    <netty-all.version>4.1.38.Final</netty-all.version>\n</properties>\n\n<dependencies>\n    <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-all</artifactId>\n        <version>${netty-all.version}</version>\n    </dependency>\n</dependencies>\n```\n\n# 常见服务端的环境\n这里都都不详解的介绍包的结构了，安需安排就可以了。\n\n## 常见SocketServer,用于初始化socket配置和启动\n```\n/**\n * 1. 双线程组\n * 2. Bootstrap配置启动信息\n * 3. 注册业务处理Handler\n * 4. 绑定服务监听端口并启动服务\n */\npackage cn.javafroum.netty.server;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelHandler;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.ChannelOption;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\n\n/**\n * @author BlackBox\n */\npublic class SocketServer {\n	// 监听线程组，监听客户端请求\n	private EventLoopGroup acceptorGroup = null;\n	// 处理客户端相关操作线程组，负责处理与客户端的数据通讯\n	private EventLoopGroup clientGroup = null;\n	// 服务启动相关配置信息\n	private ServerBootstrap bootstrap = null;\n	public SocketServer(){\n		init();\n	}\n	private void init(){\n		//这里将一下线程模型的配置\n		//netty里面有3种线程模型 1.单线程模型 2.多线程模型  3.主从多线程模型\n		//1. 单线程模型，即是接受线程组和处理线程组都为同一个并且只有一个线程，只需要更改如下配置\n		//acceptorGroup = new NioEventLoopGroup();\n		//bootstrap.group(acceptorGroup, acceptorGroup);\n\n		//2.多线程模型，即是接受线程只有一个，处理线程有多个\n		//acceptorGroup = new NioEventLoopGroup(1);\n		//clientGroup = new NioEventLoopGroup();\n		//bootstrap.group(acceptorGroup, clientGroup);\n\n		//3.主从多线程模型,即是下面这种配置，接受线程多个，处理线程也是多个\n		// 初始化线程组,构建线程组的时候，如果不传递参数，则默认构建的线程组线程数是CPU核心数量。\n		acceptorGroup = new NioEventLoopGroup();\n		clientGroup = new NioEventLoopGroup();\n		// 初始化服务的配置\n		bootstrap = new ServerBootstrap();\n		// 绑定线程组\n		bootstrap.group(acceptorGroup, clientGroup);\n		// 设定通讯模式为NIO， 同步非阻塞\n		bootstrap.channel(NioServerSocketChannel.class);\n		// 设定缓冲区大小， 缓存区的单位是字节。\n		bootstrap.option(ChannelOption.SO_BACKLOG, 1024);\n		// SO_SNDBUF发送缓冲区\n		// SO_RCVBUF接收缓冲区\n		// SO_KEEPALIVE开启心跳监测（保证连接有效）\n		bootstrap.option(ChannelOption.SO_SNDBUF, 16*1024)\n			.option(ChannelOption.SO_RCVBUF, 16*1024)\n			.option(ChannelOption.SO_KEEPALIVE, true);\n	}\n\n	/**\n	 * 监听处理逻辑。\n	 * @param port 监听端口。\n	 * @param acceptorHandlers 处理器， 如何处理客户端请求。\n	 * @return\n	 * @throws InterruptedException\n	 */\n	public ChannelFuture doAccept(int port, final ChannelHandler... acceptorHandlers) throws InterruptedException{\n		\n		/*\n		 * childHandler是服务的Bootstrap独有的方法。是用于提供处理对象的。\n		 * 可以一次性增加若干个处理逻辑。是类似责任链模式的处理方式。\n		 * 增加A，B两个处理逻辑，在处理客户端请求数据的时候，根据A-》B顺序依次处理。\n		 * \n		 * ChannelInitializer - 用于提供处理器的一个模型对象。\n		 *  其中定义了一个方法，initChannel方法。\n		 *   方法是用于初始化处理逻辑责任链条的。\n		 *   可以保证服务端的Bootstrap只初始化一次处理器，尽量提供处理逻辑的重用。\n		 *   避免反复的创建处理器对象。节约资源开销。\n		 */\n		bootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\n\n			@Override\n			protected void initChannel(SocketChannel ch) throws Exception {\n				ch.pipeline().addLast(acceptorHandlers);\n			}\n		});\n		// bind方法 - 绑定监听端口的。ServerBootstrap可以绑定多个监听端口。 多次调用bind方法即可\n		// sync - 开始监听逻辑。 返回一个ChannelFuture。 返回结果代表的是监听成功后的一个对应的未来结果\n		// 可以使用ChannelFuture实现后续的服务器和客户端的交互。\n		ChannelFuture future = bootstrap.bind(port).sync();\n		return future;\n	}\n	\n	/**\n	 * shutdownGracefully - 方法是一个安全关闭的方法。可以保证不放弃任何一个已接收的客户端请求。\n	 */\n	public void release(){\n		this.acceptorGroup.shutdownGracefully();\n		this.clientGroup.shutdownGracefully();\n	}\n}\n\n```\n\n## 参见测试handler,方便我们处理客服端传来的消息\n```\npackage cn.javafroum.netty.server.handler;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandler;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\n\nimport java.io.UnsupportedEncodingException;\n\n\n//Sharable 注解的说明：\n//作用:多个客服端可以共用这个实例，但要注意的是，不能再里面声明变量，这样不安全，声明了变量的话，\n//多个客服端用这边变量会导致不安全\n@ChannelHandler.Sharable\npublic class DiscardServerHandler extends ChannelInboundHandlerAdapter { // (1)\n\n    /**\n     * 业务处理逻辑\n     * 用于处理读取数据请求的逻辑。\n     * msg - 读取到的数据。 默认类型是ByteBuf，是Netty自定义的。是对ByteBuffer的封装。 不需要考虑复位问题。\n     */\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws UnsupportedEncodingException { // (2)\n\n        //ctx - 上下文对象。其中包含于客户端建立连接的所有资源。 如： 对应的Channel\n        System.out.println(\"通道id:\" + ctx.channel().id().asLongText());\n\n\n        // 获取读取的数据， 是一个缓冲。\n        ByteBuf readBuffer = (ByteBuf) msg;\n        // 创建一个字节数组，用于保存缓存中的数据。\n        byte[] tempDatas = new byte[readBuffer.readableBytes()];\n        // 将缓存中的数据读取到字节数组中。\n        readBuffer.readBytes(tempDatas);\n        String message = new String(tempDatas, \"UTF-8\");\n        System.out.println(\"收到客服端的消息 : \" + message);\n        if(\"exit\".equals(message)){\n            ctx.close();\n            return;\n        }\n        String line = \"服务端接收到了客服端的消息 : \" + message + \"  这是返回确认\";\n        // 写操作自动释放缓存，避免内存溢出问题。\n        ctx.writeAndFlush(Unpooled.copiedBuffer(line.getBytes(\"UTF-8\")));\n        // 注意，如果调用的是write方法。不会刷新缓存，缓存中的数据不会发送到客户端，必须再次调用flush方法才行。\n        // ctx.write(Unpooled.copiedBuffer(line.getBytes(\"UTF-8\")));\n        // ctx.flush();\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { // (4)\n        // Close the connection when an exception is raised.\n        System.out.println(\"server exceptionCaught method run...\");\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n\n## 创建启动类\n```\npackage cn.javafroum.netty.server;\n\nimport cn.javafroum.netty.server.handler.DiscardServerHandler;\nimport io.netty.channel.ChannelFuture;\n\npublic class StartupServer {\n    public static void main(String[] args){\n        ChannelFuture future = null;\n        SocketServer server = null;\n        try{\n            server = new SocketServer();\n            future = server.doAccept(9090,new DiscardServerHandler());\n            System.out.println(\"socket 服务端开始运行！\");\n            // 关闭连接的。\n            future.channel().closeFuture().sync();\n        }catch(InterruptedException e){\n            e.printStackTrace();\n        }finally{\n            if(null != future){\n                try {\n                    future.channel().closeFuture().sync();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(null != server){\n                server.release();\n            }\n        }\n    }\n}\n\n```\n\n\n# 客服端结构创建\n\n## 创建客服端配置和初始化类\n```\n/**\n * 1. 单线程组\n * 2. Bootstrap配置启动信息\n * 3. 注册业务处理Handler\n * 4. connect连接服务，并发起请求\n */\npackage cn.javafroum.netty.client;\n\nimport java.util.Scanner;\nimport java.util.concurrent.TimeUnit;\n\nimport io.netty.bootstrap.Bootstrap;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelFutureListener;\nimport io.netty.channel.ChannelHandler;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioSocketChannel;\n\n/**\n * 因为客户端是请求的发起者，不需要监听。\n * 只需要定义唯一的一个线程组即可。\n */\npublic class SocketClient {\n	\n	// 处理请求和处理服务端响应的线程组\n	private EventLoopGroup group = null;\n	// 客户端启动相关配置信息\n	private Bootstrap bootstrap = null;\n	\n	public SocketClient(){\n		init();\n	}\n	\n	private void init(){\n		group = new NioEventLoopGroup();\n		bootstrap = new Bootstrap();\n		// 绑定线程组\n		bootstrap.group(group);\n		// 设定通讯模式为NIO\n		bootstrap.channel(NioSocketChannel.class);\n	}\n	\n	public ChannelFuture doRequest(String host, int port, final ChannelHandler... handlers) throws InterruptedException{\n		/*\n		 * 客户端的Bootstrap没有childHandler方法。只有handler方法。\n		 * 方法含义等同ServerBootstrap中的childHandler\n		 * 在客户端必须绑定处理器，也就是必须调用handler方法。\n		 * 服务器必须绑定处理器，必须调用childHandler方法。\n		 */\n		this.bootstrap.handler(new ChannelInitializer<SocketChannel>() {\n			@Override\n			protected void initChannel(SocketChannel ch) throws Exception {\n				ch.pipeline().addLast(handlers);\n			}\n		});\n		// 建立连接。\n		ChannelFuture future = this.bootstrap.connect(host, port).sync();\n		return future;\n	}\n	\n	public void release(){\n		this.group.shutdownGracefully();\n	}\n}\n\n```\n\n## 创建客服端的handler，用于处理接收到服务端的返回消息\n```\npackage cn.javafroum.netty.client.handler;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerAdapter;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.util.ReferenceCountUtil;\n\npublic class ClientHandler extends ChannelInboundHandlerAdapter {\n\n	@Override\n	public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n		try{\n			ByteBuf readBuffer = (ByteBuf) msg;\n			byte[] tempDatas = new byte[readBuffer.readableBytes()];\n			readBuffer.readBytes(tempDatas);\n			System.out.println(\"from server : \" + new String(tempDatas, \"UTF-8\"));\n		}finally{\n			// 用于释放缓存。避免内存溢出\n			ReferenceCountUtil.release(msg);\n		}\n	}\n\n	@Override\n	public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n		System.out.println(\"client exceptionCaught method run...\");\n		// cause.printStackTrace();\n		ctx.close();\n	}\n\n	/*@Override // 断开连接时执行\n	public void channelInactive(ChannelHandlerContext ctx) throws Exception {\n		System.out.println(\"channelInactive method run...\");\n	}\n\n	@Override // 连接通道建立成功时执行\n	public void channelActive(ChannelHandlerContext ctx) throws Exception {\n		System.out.println(\"channelActive method run...\");\n	}\n\n	@Override // 每次读取完成时执行\n	public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\n		System.out.println(\"channelReadComplete method run...\");\n	}*/\n\n}\n\n```\n\n## 创建客服端的启动类\n```\npackage cn.javafroum.netty.client;\n\nimport cn.javafroum.netty.client.handler.ClientHandler;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelFutureListener;\n\nimport java.util.Scanner;\nimport java.util.concurrent.TimeUnit;\n\npublic class StartupClient {\n    public static void main(String[] args) {\n        SocketClient client = null;\n        ChannelFuture future = null;\n        try{\n            client = new SocketClient();\n            future = client.doRequest(\"localhost\", 9090, new ClientHandler());\n\n            Scanner s = null;\n            while(true){\n                s = new Scanner(System.in);\n                System.out.print(\"enter message send to server (enter \'exit\' for close client) > \");\n                String line = s.nextLine();\n                if(\"exit\".equals(line)){\n                    // addListener - 增加监听，当某条件满足的时候，触发监听器。\n                    // ChannelFutureListener.CLOSE - 关闭监听器，代表ChannelFuture执行返回后，关闭连接。\n                    future.channel().writeAndFlush(Unpooled.copiedBuffer(line.getBytes(\"UTF-8\")))\n                            .addListener(ChannelFutureListener.CLOSE);\n                    break;\n                }\n                future.channel().writeAndFlush(Unpooled.copiedBuffer(line.getBytes(\"UTF-8\")));\n                TimeUnit.SECONDS.sleep(1);\n            }\n        }catch(Exception e){\n            e.printStackTrace();\n        }finally{\n            if(null != future){\n                try {\n                    future.channel().closeFuture().sync();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(null != client){\n                client.release();\n            }\n        }\n    }\n}\n\n```\n\n\n# 总结\n按照上面的配置创建好相应的客服端和服务端，只需要运行启动类就可以了，代码里面有比较详细的注释，文档上面也都不说明了，源码可以参照   \n[github学习案列](https://github.com/TBlackBox/study-example) \n', '', 0, '本文档主要用于初学者创建netty案列学习和测试使用。本案例用到的maven版本是4.1.38，上面的很多注释解释了netty的使用方法，线程模型登，是netty入门的不二之选。', '', '', 'netty入门案例', 0, 'netty入门案例', 28, 0, NULL, NULL, 'netty入门案例');
INSERT INTO `posts` VALUES (0, 6, '2019-12-27 14:24:45', 0, '2019-12-27 14:26:45', 0, 0, '2019-12-27 14:26:45', '<h1 id=\"简介\">简介</h1>\n<p>iftop是类似于top的实时流量监控工具。iftop可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等，详细的将会在后面的使用参数中说明。<br />\n<a href=\"http://www.ex-parrot.com/~pdw/iftop/\">官方地址</a></p>\n<h1 id=\"安装\">安装</h1>\n<ol>\n<li>通过编译安装</li>\n</ol>\n<ul>\n<li>安装必须要的包\n安装前需要已经安装好基本的编译所需的环境，比如make、gcc、autoconf等。安装iftop还需要安装libpcap和libcurses。</li>\n</ul>\n<p>CentOS上安装所需依赖包：</p>\n<pre><code>yum install flex byacc  libpcap ncurses ncurses-devel libpcap-devel\n</code></pre>\n<p>Debian上安装所需依赖包：</p>\n<pre><code>apt-get install flex byacc  libpcap0.8 libncurses5\n</code></pre>\n<ul>\n<li>下载源码并安装</li>\n</ul>\n<pre><code>wget http://www.ex-parrot.com/pdw/iftop/download/iftop-0.17.tar.gz\n\ntar zxvf iftop-0.17.tar.gz\n\ncd iftop-0.17\n\n./configure\n\nmake &amp;&amp; make install\n</code></pre>\n<h1 id=\"运行\">运行</h1>\n<p>直接运行下面命令</p>\n<pre><code>iftop\n</code></pre>\n<h1 id=\"iftop界面相关说明\">iftop界面相关说明</h1>\n<p>从界面上看可以分为3部分</p>\n<ul>\n<li>第一部分：也就是第一行  可以看成是刻度，为显示流量图形的长条作标尺用的。</li>\n<li>第二部分：第二部分为左中右，左列和中列记录了哪些IP或主机正在本机的网络进行连接。中间的&lt;= =&gt;这两个左右箭头，表示的是流量的方向。最右列又分为三个小列，这些实时参数分别表示外部IP连接到本机2s 10s和40s的平均流量。另外这个部分还有一个流量图形条，流量图形条是对流量大小的动态展示，以第一部分中的流量刻度为基准。通过这个流量图形条可以很方便的看出那个IP的流量最大，今儿迅速定位网络中可能出现的流量问题；</li>\n<li>第三部分：也就是下面的参数说明了，一看就明白，这里都不多说了。</li>\n</ul>\n<table>\n<thead>\n<tr><th>参数</th><th>说明</th></tr>\n</thead>\n<tbody>\n<tr><td>TX</td><td>发送流量</td></tr>\n<tr><td>RX</td><td>接收流量</td></tr>\n<tr><td>TOTAL</td><td>总流量</td></tr>\n<tr><td>Cumm</td><td>运行iftop到目前时间的总流量</td></tr>\n<tr><td>peak</td><td>流量峰值</td></tr>\n<tr><td>rates</td><td>分别表示过去 2s 10s 40s 的平均流量</td></tr>\n</tbody>\n</table>\n<h1 id=\"iftop相关参数\">iftop相关参数</h1>\n<h2 id=\"常用参数\">常用参数</h2>\n<table>\n<thead>\n<tr><th>参数</th><th>说明</th><th>例子</th></tr>\n</thead>\n<tbody>\n<tr><td>-i</td><td>设定监测的网卡</td><td>iftop -i eth0</td></tr>\n<tr><td>-B</td><td>以bytes为单位显示流量(默认是bits)</td><td>iftop -B</td></tr>\n<tr><td>-n</td><td>使host信息默认直接都显示IP</td><td>iftop -n</td></tr>\n<tr><td>-N</td><td>使端口信息默认直接都显示端口号</td><td>iftop -N</td></tr>\n<tr><td>-F</td><td>显示特定网段的进出流量</td><td>iftop -F 10.10.1.0/24或iftop -F 10.10.1.0/255.255.255.0</td></tr>\n<tr><td>-h</td><td>（display this message），帮助，显示参数信息</td><td></td></tr>\n<tr><td>-p</td><td>使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息</td><td></td></tr>\n<tr><td>-b</td><td>使流量图形条默认就显示</td><td></td></tr>\n<tr><td>-f</td><td>这个暂时还不太会用，过滤计算包用的</td><td></td></tr>\n<tr><td>-P</td><td>使host信息及端口信息默认就都显示</td><td></td></tr>\n<tr><td>-m</td><td>设置界面最上边的刻度的最大值，刻度分五个大段显示</td><td># iftop -m 100M</td></tr>\n</tbody>\n</table>\n<h2 id=\"进入iftop画面后的一些操作命令\">进入iftop画面后的一些操作命令</h2>\n<table>\n<thead>\n<tr><th>命令（注意大小写）</th><th>说明</th></tr>\n</thead>\n<tbody>\n<tr><td>h</td><td>切换是否显示帮助</td></tr>\n<tr><td>n</td><td>切换显示本机的IP或主机名</td></tr>\n<tr><td>s</td><td>切换是否显示本机的host信息</td></tr>\n<tr><td>d</td><td>切换是否显示远端目标主机的host信息</td></tr>\n<tr><td>t</td><td>切换显示格式为2行/1行/只显示发送流量/只显示接收流量</td></tr>\n<tr><td>N</td><td>切换显示端口号或端口服务名称</td></tr>\n<tr><td>S</td><td>切换是否显示本机的端口信息</td></tr>\n<tr><td>D</td><td>切换是否显示远端目标主机的端口信息</td></tr>\n<tr><td>p</td><td>切换是否显示端口信息</td></tr>\n<tr><td>P</td><td>切换暂停/继续显示</td></tr>\n<tr><td>b</td><td>切换是否显示平均流量图形条</td></tr>\n<tr><td>B</td><td>切换计算2秒或10秒或40秒内的平均流量</td></tr>\n<tr><td>T</td><td>切换是否显示每个连接的总流量</td></tr>\n<tr><td>l</td><td>打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息</td></tr>\n<tr><td>L</td><td>切换显示画面上边的刻度;刻度不同，流量图形条会有变化</td></tr>\n<tr><td>j或k</td><td>可以向上或向下滚动屏幕显示的连接记录</td></tr>\n<tr><td>1或2或3</td><td>可以根据右侧显示的三列流量数据进行排序</td></tr>\n<tr><td>&lt;</td><td>根据左边的本机名或IP排序</td></tr>\n<tr><td>&gt;</td><td>根据远端目标主机的主机名或IP排序</td></tr>\n<tr><td>o</td><td>切换是否固定只显示当前的连接</td></tr>\n<tr><td>q</td><td>退出监控</td></tr>\n</tbody>\n</table>\n<h1 id=\"总结\">总结</h1>\n<p>这里只列出了一些常用的，更深入的使用需看官方问题和其他更全的资料。</p>\n', 0, '# 简介\niftop是类似于top的实时流量监控工具。iftop可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等，详细的将会在后面的使用参数中说明。  \n[官方地址](http://www.ex-parrot.com/~pdw/iftop/)\n\n# 安装\n1. 通过编译安装\n+ 安装必须要的包\n安装前需要已经安装好基本的编译所需的环境，比如make、gcc、autoconf等。安装iftop还需要安装libpcap和libcurses。\n\nCentOS上安装所需依赖包：\n```\nyum install flex byacc  libpcap ncurses ncurses-devel libpcap-devel\n```\n\nDebian上安装所需依赖包：\n```\napt-get install flex byacc  libpcap0.8 libncurses5\n```\n\n+ 下载源码并安装\n```\nwget http://www.ex-parrot.com/pdw/iftop/download/iftop-0.17.tar.gz\n\ntar zxvf iftop-0.17.tar.gz\n\ncd iftop-0.17\n\n./configure\n\nmake && make install\n```\n\n# 运行\n直接运行下面命令\n```\niftop\n```\n\n# iftop界面相关说明\n从界面上看可以分为3部分\n+ 第一部分：也就是第一行  可以看成是刻度，为显示流量图形的长条作标尺用的。\n+ 第二部分：第二部分为左中右，左列和中列记录了哪些IP或主机正在本机的网络进行连接。中间的<= =>这两个左右箭头，表示的是流量的方向。最右列又分为三个小列，这些实时参数分别表示外部IP连接到本机2s 10s和40s的平均流量。另外这个部分还有一个流量图形条，流量图形条是对流量大小的动态展示，以第一部分中的流量刻度为基准。通过这个流量图形条可以很方便的看出那个IP的流量最大，今儿迅速定位网络中可能出现的流量问题；\n+ 第三部分：也就是下面的参数说明了，一看就明白，这里都不多说了。\n\n\n|参数|说明|\n|-----|------|\n|TX|发送流量|\n|RX|接收流量|\n|TOTAL|总流量|\n|Cumm|运行iftop到目前时间的总流量|\n|peak|流量峰值|\n|rates|分别表示过去 2s 10s 40s 的平均流量|\n\n\n# iftop相关参数\n## 常用参数\n|参数|说明|例子| \n|-------|-------|----|\n|-i|设定监测的网卡 |iftop -i eth0| \n|-B |以bytes为单位显示流量(默认是bits) |iftop -B |\n|-n|使host信息默认直接都显示IP|iftop -n|\n|-N|使端口信息默认直接都显示端口号|iftop -N|\n|-F|显示特定网段的进出流量|iftop -F 10.10.1.0/24或iftop -F 10.10.1.0/255.255.255.0|\n|-h|（display this message），帮助，显示参数信息|\n|-p|使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息|\n|-b|使流量图形条默认就显示|\n|-f|这个暂时还不太会用，过滤计算包用的|\n|-P|使host信息及端口信息默认就都显示|\n|-m|设置界面最上边的刻度的最大值，刻度分五个大段显示|# iftop -m 100M|\n\n\n## 进入iftop画面后的一些操作命令\n\n|命令（注意大小写）|说明| \n|-------|-------|\n|h|切换是否显示帮助|\n|n|切换显示本机的IP或主机名|\n|s|切换是否显示本机的host信息|\n|d|切换是否显示远端目标主机的host信息|\n|t|切换显示格式为2行/1行/只显示发送流量/只显示接收流量|\n|N|切换显示端口号或端口服务名称|\n|S|切换是否显示本机的端口信息|\n|D|切换是否显示远端目标主机的端口信息|\n|p|切换是否显示端口信息|\n|P|切换暂停/继续显示|\n|b|切换是否显示平均流量图形条|\n|B|切换计算2秒或10秒或40秒内的平均流量|\n|T|切换是否显示每个连接的总流量|\n|l|打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息|\n|L|切换显示画面上边的刻度;刻度不同，流量图形条会有变化|\n|j或k|可以向上或向下滚动屏幕显示的连接记录|\n|1或2或3|可以根据右侧显示的三列流量数据进行排序|\n|<|根据左边的本机名或IP排序|\n|>|根据远端目标主机的主机名或IP排序|\n|o|切换是否固定只显示当前的连接|\n|q|退出监控|\n\n\n# 总结\n这里只列出了一些常用的，更深入的使用需看官方问题和其他更全的资料。', '', 0, 'iftop是类似于top的实时流量监控工具。iftop可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等，详细的将会在后面的使用参数中说明。  ', '', '', 'iftop实时网络流量监测工具的安装和使用', 1, 'iftop实时网络流量监测工具的安装和使用', 34, 0, NULL, NULL, 'iftop实时网络流量监测工具的安装和使用');
INSERT INTO `posts` VALUES (0, 7, '2020-05-12 17:34:23', 0, '2020-05-12 17:34:23', 0, 0, '2020-05-12 17:34:23', '<h1 id=\"简介\">简介</h1>\n<p>jdk8对Map新增了一些方法，方便在不同的业务逻辑中使用</p>\n<h1 id=\"方法\">方法</h1>\n<h2 id=\"putifabsent\">putIfAbsent</h2>\n<p>当key对应的value没有时才放入新的值，可以防止旧值被覆盖</p>\n<pre><code>default V putIfAbsent(K key, V value) {}\n</code></pre>\n<h2 id=\"computeifabsent\">computeIfAbsent</h2>\n<p>映射当key不存在或value为null时的value值，包括创建对应key，返回value,如果key存在，则不做处理</p>\n<pre><code>default V computeIfAbsent(K key,\n            Function&lt;? super K, ? extends V&gt; mappingFunction) {}\n</code></pre>\n<h2 id=\"computeifpresent\">computeIfPresent</h2>\n<p>与上述的computeIfAbsent 相反，当key存在时计算替换相应的value，并返回。当key不存在时返回null</p>\n<pre><code>default V computeIfPresent(K key,\n            BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) {}\n</code></pre>\n<h2 id=\"compute\">compute</h2>\n<p>计算key的value，如果key不存在，则创建key并赋值value，如果value为null，则报NPE</p>\n<pre><code>default V compute(K key,\n            BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) {}\n</code></pre>\n<h2 id=\"merge\">merge</h2>\n<ul>\n<li>value 为null 报NPE</li>\n<li>如果key存在，且value 不为null，新，老value根据计算得出结果，赋值给key。</li>\n<li>如果key不存在，且value 不为null，value赋值给key。</li>\n</ul>\n<pre><code>default V merge(K key, V value,\n            BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) {}\n</code></pre>\n<h2 id=\"getordefault\">getOrDefault</h2>\n<p>如果key为空，就返回默认值，否则返回value</p>\n<pre><code>default V getOrDefault(Object key, V defaultValue) {}\n</code></pre>\n<h2 id=\"replace\">replace</h2>\n<ol>\n<li>可以判断oldValue是否正确</li>\n</ol>\n<pre><code> default boolean replace(K key, V oldValue, V newValue) {}\n</code></pre>\n<ol start=\"2\">\n<li>用map的put(相同的key)也能做到newValue替换oldValue，但是replace走的是get获取的流程，获取不到就直接返回false。 -- replace 所在场景一般是key存在的</li>\n</ol>\n<pre><code>default V replace(K key, V value) {}\n</code></pre>\n<h2 id=\"remove\">remove</h2>\n<ol>\n<li>根据key和value移除,值不匹配将移除不成功</li>\n</ol>\n<pre><code>default boolean remove(Object key, Object value) {}\n</code></pre>\n<h2 id=\"foreach\">forEach</h2>\n<p>遍历map</p>\n<pre><code> default void forEach(BiConsumer&lt;? super K, ? super V&gt; action) {}\n</code></pre>\n<h1 id=\"使用例子\">使用例子</h1>\n<pre><code>Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();\n//初始化一些值\nmap.put(&quot;a&quot;, 1);\nmap.put(&quot;b&quot;,null);\nmap.put(&quot;c&quot;,3);\n\n//当key对应的value没有时才放入新的值，可以防止旧值被覆盖\nmap.putIfAbsent(&quot;a&quot;, 2);\n\n//映射当key不存在或value为null时的value值，包括创建对应key，返回value,如果key存在，则不做处理\nmap.computeIfAbsent(&quot;d&quot;, (v) -&gt; 36);\n\n//与上述的computeIfAbsent 相反，当key存在时计算替换相应的value，并返回。当key不存在时返回null\nInteger s = map.computeIfPresent(&quot;f&quot;, (k,v) -&gt; v * 2);\n\n//计算key的value，如果key不存在，则创建key并赋值value，如果value为null，则报NPE\nmap.compute(&quot;f&quot;, (k,v) -&gt; 52);\n\n//value 为null 报NPE\n//如果key存在，且value 不为null，新，老value根据计算得出结果，赋值给key。\n//如果key不存在，且value 不为null，value赋值给key。\nmap.merge(&quot;h&quot;, 2, (v1,v2) -&gt; v1 + v2);\n\n//如果key为空，就返回默认值，否则返回value\nInteger retV = map.getOrDefault(&quot;f&quot;, 12);\nSystem.out.println(retV);\n\n//替换  可以判断oldValue是否正确\nmap.replace(&quot;a&quot;, 2, 23);\n//用map的put(相同的key)也能做到newValue替换oldValue，但是replace走的是get获取的流程，获取不到就直接返回false。\n//-- replace 所在场景一般是key存在的\nmap.replace(&quot;b&quot;, 12);\n\n//根据键值移除  如果值不匹配 将移除不成功\nmap.remove(&quot;b&quot;,121);\n\n//遍历map\nmap.forEach((k,v) -&gt; {\nSystem.out.println(&quot;键：&quot;+k+ &quot;  值：&quot;+v);\n});\n</code></pre>\n<h1 id=\"总结\">总结</h1>\n<p>这里只是简单的列了一下，还需要自己去体会和使用</p>\n', 0, '\n# 简介\njdk8对Map新增了一些方法，方便在不同的业务逻辑中使用\n\n# 方法\n## putIfAbsent\n当key对应的value没有时才放入新的值，可以防止旧值被覆盖\n```\ndefault V putIfAbsent(K key, V value) {}\n```\n\n## computeIfAbsent\n映射当key不存在或value为null时的value值，包括创建对应key，返回value,如果key存在，则不做处理\n```\ndefault V computeIfAbsent(K key,\n            Function<? super K, ? extends V> mappingFunction) {}\n```\n## computeIfPresent\n与上述的computeIfAbsent 相反，当key存在时计算替换相应的value，并返回。当key不存在时返回null\n```\ndefault V computeIfPresent(K key,\n            BiFunction<? super K, ? super V, ? extends V> remappingFunction) {}\n```\n\n## compute\n计算key的value，如果key不存在，则创建key并赋值value，如果value为null，则报NPE\n```\ndefault V compute(K key,\n            BiFunction<? super K, ? super V, ? extends V> remappingFunction) {}\n```\n\n## merge\n- value 为null 报NPE\n- 如果key存在，且value 不为null，新，老value根据计算得出结果，赋值给key。\n- 如果key不存在，且value 不为null，value赋值给key。\n```\ndefault V merge(K key, V value,\n            BiFunction<? super V, ? super V, ? extends V> remappingFunction) {}\n```\n\n## getOrDefault\n如果key为空，就返回默认值，否则返回value\n```\ndefault V getOrDefault(Object key, V defaultValue) {}\n```\n## replace\n1. 可以判断oldValue是否正确\n```\n default boolean replace(K key, V oldValue, V newValue) {}\n```\n2. 用map的put(相同的key)也能做到newValue替换oldValue，但是replace走的是get获取的流程，获取不到就直接返回false。 -- replace 所在场景一般是key存在的\n```\ndefault V replace(K key, V value) {}\n```\n\n## remove\n1. 根据key和value移除,值不匹配将移除不成功\n```\ndefault boolean remove(Object key, Object value) {}\n```\n\n## forEach\n遍历map\n```\n default void forEach(BiConsumer<? super K, ? super V> action) {}\n```\n\n# 使用例子\n```\nMap<String, Integer> map = new HashMap<String, Integer>();\n//初始化一些值\nmap.put(\"a\", 1);\nmap.put(\"b\",null);\nmap.put(\"c\",3);\n\n//当key对应的value没有时才放入新的值，可以防止旧值被覆盖\nmap.putIfAbsent(\"a\", 2);\n\n//映射当key不存在或value为null时的value值，包括创建对应key，返回value,如果key存在，则不做处理\nmap.computeIfAbsent(\"d\", (v) -> 36);\n\n//与上述的computeIfAbsent 相反，当key存在时计算替换相应的value，并返回。当key不存在时返回null\nInteger s = map.computeIfPresent(\"f\", (k,v) -> v * 2);\n\n//计算key的value，如果key不存在，则创建key并赋值value，如果value为null，则报NPE\nmap.compute(\"f\", (k,v) -> 52);\n\n//value 为null 报NPE\n//如果key存在，且value 不为null，新，老value根据计算得出结果，赋值给key。\n//如果key不存在，且value 不为null，value赋值给key。\nmap.merge(\"h\", 2, (v1,v2) -> v1 + v2);\n\n//如果key为空，就返回默认值，否则返回value\nInteger retV = map.getOrDefault(\"f\", 12);\nSystem.out.println(retV);\n\n//替换  可以判断oldValue是否正确\nmap.replace(\"a\", 2, 23);\n//用map的put(相同的key)也能做到newValue替换oldValue，但是replace走的是get获取的流程，获取不到就直接返回false。\n//-- replace 所在场景一般是key存在的\nmap.replace(\"b\", 12);\n\n//根据键值移除  如果值不匹配 将移除不成功\nmap.remove(\"b\",121);\n\n//遍历map\nmap.forEach((k,v) -> {\nSystem.out.println(\"键：\"+k+ \"  值：\"+v);\n});\n```\n\n# 总结\n这里只是简单的列了一下，还需要自己去体会和使用', '', 0, 'jdk8对Map新增了一些方法，方便在不同的业务逻辑中使用', '', '', 'jdk8 Map新增的方法介绍', 0, 'jdk8 Map新增的方法介绍', 9, 0, NULL, NULL, 'jdk8 Map新增的方法介绍');
INSERT INTO `posts` VALUES (0, 8, '2020-06-03 17:04:24', 0, '2020-06-03 17:06:16', 0, 0, '2020-06-03 17:06:16', '<h1 id=\"例子\">例子</h1>\n<p>声明一个静态工厂方法</p>\n<pre><code>public static Boolean valueOf(boolean b) {\n	return (b ? TRUE : FALSE);\n}\n</code></pre>\n<h1 id=\"优点\">优点</h1>\n<ol>\n<li>有名称，使用的时候根据清晰。</li>\n<li>不用每次调用的时候都创建一个新的对象。</li>\n<li>可以返回原返回类型的任何之类型的对象。</li>\n<li>创建参数化实例的时候，使代码变得更佳的简洁。</li>\n</ol>\n<pre><code>Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;String, List&lt;String&gt;&gt;();\n</code></pre>\n<p>上面的声明太长了，可以改一哈</p>\n<pre><code>public static &lt;K,V&gt; HashMap&lt;K,V&gt; newInstance(){\n	return new HashMap&lt;K,V&gt;();\n}\n</code></pre>\n<p>调用</p>\n<pre><code>Map&lt;String, List&lt;String&gt;&gt; map1 = HashMap.newInstance();\n</code></pre>\n<p>编译器可以找到类型参数，称作<code>类型推导</code>,但是，java没有实现（等以后在看吧）。</p>\n<h1 id=\"缺点\">缺点</h1>\n<ol>\n<li>类如果不含公有或者受保护的构造器，就不能被之类化。</li>\n<li>与其他静态方法实际上没有却别。</li>\n</ol>\n<h1 id=\"静态工厂方法的一些惯用名称\">静态工厂方法的一些惯用名称</h1>\n<ul>\n<li>valueOf\n该方法返回的实列与他的参数具有相同的值，这样的静态工厂方法实际上是类型转换方法。</li>\n<li>of\nValueOf的简洁替代，现在比较流行了。</li>\n<li>getInstance\n返回的实例是通过方法参数来描述的，不能说与参数具有相同的值。对于<code>Singleton</code>来说，该方法没有参数，并返回唯一实列。</li>\n<li>newinstance\n和getInstance一样，能够确保返回的没改实例与其他实例不同。</li>\n<li>getType\n像getInstance,在工厂方法处于不同的类中的时候用，Type表示工厂方法返回的对象类型。</li>\n<li>newType\n像newInstance一样，在工厂方法处于不同的类中的时候用，Type表示工厂方法返回的对象类型。</li>\n</ul>\n<h1 id=\"总结\">总结</h1>\n<p>静态工厂方法和公有构造器都各有用处，需要理解各自的长处，静态工厂通常更加的合适，第一考虑应该是静态工厂方法，在是共有的构造器。</p>\n', 0, '# 例子\n声明一个静态工厂方法\n```\npublic static Boolean valueOf(boolean b) {\n	return (b ? TRUE : FALSE);\n}\n```\n\n# 优点\n1. 有名称，使用的时候根据清晰。\n2. 不用每次调用的时候都创建一个新的对象。\n3. 可以返回原返回类型的任何之类型的对象。\n4. 创建参数化实例的时候，使代码变得更佳的简洁。\n```\nMap<String, List<String>> map = new HashMap<String, List<String>>();\n```\n上面的声明太长了，可以改一哈\n```\npublic static <K,V> HashMap<K,V> newInstance(){\n	return new HashMap<K,V>();\n}\n```\n调用\n```\nMap<String, List<String>> map1 = HashMap.newInstance();\n```\n编译器可以找到类型参数，称作`类型推导`,但是，java没有实现（等以后在看吧）。\n\n# 缺点\n1. 类如果不含公有或者受保护的构造器，就不能被之类化。\n2. 与其他静态方法实际上没有却别。\n\n\n# 静态工厂方法的一些惯用名称\n- valueOf \n该方法返回的实列与他的参数具有相同的值，这样的静态工厂方法实际上是类型转换方法。\n- of\nValueOf的简洁替代，现在比较流行了。\n- getInstance\n返回的实例是通过方法参数来描述的，不能说与参数具有相同的值。对于`Singleton`来说，该方法没有参数，并返回唯一实列。\n- newinstance\n和getInstance一样，能够确保返回的没改实例与其他实例不同。\n- getType\n像getInstance,在工厂方法处于不同的类中的时候用，Type表示工厂方法返回的对象类型。\n- newType\n像newInstance一样，在工厂方法处于不同的类中的时候用，Type表示工厂方法返回的对象类型。\n\n# 总结\n静态工厂方法和公有构造器都各有用处，需要理解各自的长处，静态工厂通常更加的合适，第一考虑应该是静态工厂方法，在是共有的构造器。', '', 0, '', '', '', 'EffectiveJava之静态工厂方法代替构造器', 0, 'EffectiveJava之静态工厂方法代替构造器', 7, 0, NULL, NULL, 'EffectiveJava之静态工厂方法代替构造器');
INSERT INTO `posts` VALUES (0, 9, '2020-06-03 17:08:31', 0, '2020-06-03 17:08:31', 0, 0, '2020-06-03 17:08:31', '<h1 id=\"问题\">问题</h1>\n<p>如果要构建一个类，有2给必须的参数，4个可选参数，或者更多的参数。怎么来构建它？</p>\n<h1 id=\"通过多个重叠的构造器\">通过多个重叠的构造器</h1>\n<p>步骤一： 一般的方法都是提供一个必须的构造器\n步骤二： 在提供一个必须参数的构造器加一个喊一个可选参数的构造器\n步骤三： 依次内推</p>\n<p>缺点：\n参数多的时候需要构建很多给构造器，并且代码很难编写，难以阅读。</p>\n<h1 id=\"通过javabean的模式\">通过JavaBean的模式</h1>\n<p>步骤一：建一个JavaBean,将参数封装进去，然后协商<code>get</code>，<code>set</code>方法。\n步骤二：使用的时候，创建一个JavaBean实列，在设置对应的参数。</p>\n<p>缺点：</p>\n<ol>\n<li>构造过程被分到几个调用中，可能处于不一致状态。</li>\n<li>阻止了把类做成了不可变的可能，可能无法确保他的线程安全。</li>\n</ol>\n<h1 id=\"使用builder模式\">使用Builder模式</h1>\n<p>步骤一：让所有必要的参数调用构造器，得到一个builder对象。\n步骤二：通过builder对象调用类似于set的方法，来设置可选参数。\n步骤三：调用build来生成不可变的对象</p>\n<h2 id=\"案列\">案列</h2>\n<pre><code>public class User {\n\n	//必须参数\n	private String name;\n	private Integer age;\n	\n	//可选参数\n	private Integer heigth;\n	private String address;\n	private Integer weight;\n	private Boolean marry; //是否结婚\n	\n	public static class Builder{\n		//必须的参数\n		private final String name;\n		private final Integer age;\n		\n		//可选参数 初始化默认值\n		private Integer heigth = 188;\n		private String address = &quot;中国重庆&quot;;\n		private Integer weight = 55;\n		private Boolean marry = false; //是否结婚\n		\n		public Builder(String name,Integer age) {\n			this.name = name;\n			this.age = age;\n		}\n		\n		public Builder height(Integer height) {\n			this.heigth = height;\n			return this;\n		}\n		public Builder address(String address) {\n			this.address = address;\n			return this;\n		}\n		public Builder weight(Integer weight) {\n			this.weight = weight;\n			return this;\n		}\n		public Builder marry(Boolean marry) {\n			this.marry = marry;\n			return this;\n		}\n		public User build() {\n			return new User(this);\n		}\n	}\n	\n	private User(Builder builder) {\n		this.name = builder.name;\n		this.age = builder.age;\n		this.address = builder.address;\n		this.marry = builder.marry;\n		this.weight = builder.weight;\n	}\n}\n</code></pre>\n<p>调用方法</p>\n<pre><code>User user = new User.Builder(&quot;张三&quot;, 25)\n				 			 .weight(55)\n				 			 .height(188)\n				 			 .address(&quot;中国四川省&quot;)\n				 			 .marry(true)\n				 			 .build();\n</code></pre>\n<h2 id=\"优点\">优点</h2>\n<ol>\n<li>代码容易编写，易于阅读。</li>\n<li>可以对参数强加约束，build方法可以检验这些约束条件，不正确可以抛异常。</li>\n<li>是否灵活，可以利用带单个<code>Builder</code>构建多个对象。</li>\n<li>可以自动填充某些域，例如每次创建对象时自动增加的序号列。</li>\n</ol>\n<h1 id=\"缺点\">缺点</h1>\n<ol>\n<li>为了创建对象，必须先创建它的构造器。（对性能特别注重的地方，都成问题了）。</li>\n<li>代码比重叠构造器更加的冗长。</li>\n</ol>\n<h1 id=\"总结\">总结</h1>\n<p>多个参数时，Builder是个不错的选择，特别是大多数参数是可选的时候，还有就是   比javaBean更加的安全。</p>\n', 0, '# 问题\n如果要构建一个类，有2给必须的参数，4个可选参数，或者更多的参数。怎么来构建它？\n\n# 通过多个重叠的构造器\n步骤一： 一般的方法都是提供一个必须的构造器\n步骤二： 在提供一个必须参数的构造器加一个喊一个可选参数的构造器\n步骤三： 依次内推\n\n缺点：\n参数多的时候需要构建很多给构造器，并且代码很难编写，难以阅读。\n\n\n\n\n# 通过JavaBean的模式\n步骤一：建一个JavaBean,将参数封装进去，然后协商`get`，`set`方法。\n步骤二：使用的时候，创建一个JavaBean实列，在设置对应的参数。\n\n缺点：\n1. 构造过程被分到几个调用中，可能处于不一致状态。\n2. 阻止了把类做成了不可变的可能，可能无法确保他的线程安全。\n\n\n# 使用Builder模式\n步骤一：让所有必要的参数调用构造器，得到一个builder对象。\n步骤二：通过builder对象调用类似于set的方法，来设置可选参数。\n步骤三：调用build来生成不可变的对象\n\n## 案列\n```\npublic class User {\n\n	//必须参数\n	private String name;\n	private Integer age;\n	\n	//可选参数\n	private Integer heigth;\n	private String address;\n	private Integer weight;\n	private Boolean marry; //是否结婚\n	\n	public static class Builder{\n		//必须的参数\n		private final String name;\n		private final Integer age;\n		\n		//可选参数 初始化默认值\n		private Integer heigth = 188;\n		private String address = \"中国重庆\";\n		private Integer weight = 55;\n		private Boolean marry = false; //是否结婚\n		\n		public Builder(String name,Integer age) {\n			this.name = name;\n			this.age = age;\n		}\n		\n		public Builder height(Integer height) {\n			this.heigth = height;\n			return this;\n		}\n		public Builder address(String address) {\n			this.address = address;\n			return this;\n		}\n		public Builder weight(Integer weight) {\n			this.weight = weight;\n			return this;\n		}\n		public Builder marry(Boolean marry) {\n			this.marry = marry;\n			return this;\n		}\n		public User build() {\n			return new User(this);\n		}\n	}\n	\n	private User(Builder builder) {\n		this.name = builder.name;\n		this.age = builder.age;\n		this.address = builder.address;\n		this.marry = builder.marry;\n		this.weight = builder.weight;\n	}\n}\n```\n调用方法\n```\nUser user = new User.Builder(\"张三\", 25)\n				 			 .weight(55)\n				 			 .height(188)\n				 			 .address(\"中国四川省\")\n				 			 .marry(true)\n				 			 .build();\n```\n## 优点\n1. 代码容易编写，易于阅读。\n2. 可以对参数强加约束，build方法可以检验这些约束条件，不正确可以抛异常。\n3. 是否灵活，可以利用带单个`Builder	`构建多个对象。\n4. 可以自动填充某些域，例如每次创建对象时自动增加的序号列。\n\n\n# 缺点\n1. 为了创建对象，必须先创建它的构造器。（对性能特别注重的地方，都成问题了）。\n2. 代码比重叠构造器更加的冗长。\n\n# 总结\n多个参数时，Builder是个不错的选择，特别是大多数参数是可选的时候，还有就是   比javaBean更加的安全。', '', 0, '', '', '', 'EffectiveJava之遇到多个构造器参数时考虑用构建器', 0, 'EffectiveJava之遇到多个构造器参数时考虑用构建器', 6, 0, NULL, NULL, 'EffectiveJava之遇到多个构造器参数时考虑用构建器');
INSERT INTO `posts` VALUES (0, 10, '2020-06-03 17:10:00', 0, '2020-06-03 17:10:00', 0, 0, '2020-06-03 17:10:00', '<h1 id=\"简介\">简介</h1>\n<p>Singleton可以理解为单列，就是一个对象在整个进程中只有一个实例。可以通过下面几种方法来声明。</p>\n<h1 id=\"饿汉式\">饿汉式</h1>\n<pre><code>public class ImageLoader{ \n     private static ImageLoader instance = new ImageLoader; \n     private ImageLoader(){} \n     public static ImageLoader getInstance(){  \n          return instance;  \n      } \n}\n</code></pre>\n<p>把构造方法私有了，把实列直接创建好，要用的时候返回就可以了\n优点：</p>\n<ul>\n<li>线程安全</li>\n<li>调用效率高</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>不能延时加载（容易造成资源浪费）</li>\n<li>可以通过<code>AccessibleObject.setAccessible</code>方法，通过反射调用私有构造器，如果要抵御这种攻击，可以修改构造器，让他被要求创建第二个实列的时候抛出异常。</li>\n</ul>\n<h1 id=\"懒汉式\">懒汉式</h1>\n<pre><code>public class SingletonDemo2 {\n     \n    //类初始化时，不初始化这个对象(延时加载，真正用的时候再创建)\n    private static SingletonDemo2 instance;\n     \n    //构造器私有化\n    private SingletonDemo2(){}\n     \n    //方法同步，调用效率低\n    public static synchronized SingletonDemo2 getInstance(){\n        if(instance==null){\n            instance=new SingletonDemo2();\n        }\n        return instance;\n    }\n}\n</code></pre>\n<p>优点：</p>\n<ul>\n<li>线程安全</li>\n<li>能延时加载</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>调用效率不高</li>\n</ul>\n<h1 id=\"double-checklock实现单例\">Double CheckLock实现单例</h1>\n<p>DCL也就是双重锁判断机制（由于JVM底层模型原因，偶尔会出问题，不建议使用）</p>\n<pre><code>public class SingletonDemo5 {\n        private volatile static SingletonDemo5 SingletonDemo5;\n\n        private SingletonDemo5() {\n        }\n\n        public static SingletonDemo5 newInstance() {\n            if (SingletonDemo5 == null) {\n                synchronized (SingletonDemo5.class) {\n                    if (SingletonDemo5 == null) {\n                        SingletonDemo5 = new SingletonDemo5();\n                    }\n                }\n            }\n            return SingletonDemo5;\n        }\n    }\n</code></pre>\n<h1 id=\"静态内部类实现\">静态内部类实现</h1>\n<p>线程安全，调用效率高，可以延时加载</p>\n<pre><code>public class SingletonDemo3 {\n\n    private static class SingletonClassInstance{\n        private static final SingletonDemo3 instance=new SingletonDemo3();\n    }\n\n    private SingletonDemo3(){}\n\n    public static SingletonDemo3 getInstance(){\n        return SingletonClassInstance.instance;\n    }\n\n}\n</code></pre>\n<h1 id=\"枚举类实现\">枚举类实现</h1>\n<p>线程安全，调用效率高，不能延时加载，可以天然的防止反射和反序列化调用</p>\n<pre><code>public enum SingletonDemo4 {\n\n    //枚举元素本身就是单例\n    INSTANCE;\n\n    //添加自己需要的操作\n    public void singletonOperation(){\n    }\n}\n</code></pre>\n<h1 id=\"总结\">总结</h1>\n<p>单元素的枚举类型已经成为实现Singleton的最佳方法。上面介绍的几种方式主要是通过私有化构造方法来限制一次实列化。</p>\n<p>比较：\n占用资源少，不需要延时加载，枚举 好于 饿汉\n占用资源多，需要延时加载，静态内部类 好于 懒汉式</p>\n', 0, '# 简介\nSingleton可以理解为单列，就是一个对象在整个进程中只有一个实例。可以通过下面几种方法来声明。\n\n# 饿汉式\n```\npublic class ImageLoader{ \n     private static ImageLoader instance = new ImageLoader; \n     private ImageLoader(){} \n     public static ImageLoader getInstance(){  \n          return instance;  \n      } \n}\n```\n把构造方法私有了，把实列直接创建好，要用的时候返回就可以了\n优点：\n- 线程安全\n- 调用效率高\n\n缺点：\n- 不能延时加载（容易造成资源浪费）\n- 可以通过`AccessibleObject.setAccessible`方法，通过反射调用私有构造器，如果要抵御这种攻击，可以修改构造器，让他被要求创建第二个实列的时候抛出异常。\n\n   \n# 懒汉式\n```\npublic class SingletonDemo2 {\n     \n    //类初始化时，不初始化这个对象(延时加载，真正用的时候再创建)\n    private static SingletonDemo2 instance;\n     \n    //构造器私有化\n    private SingletonDemo2(){}\n     \n    //方法同步，调用效率低\n    public static synchronized SingletonDemo2 getInstance(){\n        if(instance==null){\n            instance=new SingletonDemo2();\n        }\n        return instance;\n    }\n}\n```\n优点：\n- 线程安全\n- 能延时加载\n\n缺点：\n- 调用效率不高\n\n# Double CheckLock实现单例\nDCL也就是双重锁判断机制（由于JVM底层模型原因，偶尔会出问题，不建议使用）\n```\npublic class SingletonDemo5 {\n        private volatile static SingletonDemo5 SingletonDemo5;\n\n        private SingletonDemo5() {\n        }\n\n        public static SingletonDemo5 newInstance() {\n            if (SingletonDemo5 == null) {\n                synchronized (SingletonDemo5.class) {\n                    if (SingletonDemo5 == null) {\n                        SingletonDemo5 = new SingletonDemo5();\n                    }\n                }\n            }\n            return SingletonDemo5;\n        }\n    }\n```\n\n# 静态内部类实现\n线程安全，调用效率高，可以延时加载\n```\npublic class SingletonDemo3 {\n\n    private static class SingletonClassInstance{\n        private static final SingletonDemo3 instance=new SingletonDemo3();\n    }\n\n    private SingletonDemo3(){}\n\n    public static SingletonDemo3 getInstance(){\n        return SingletonClassInstance.instance;\n    }\n\n}\n```\n\n# 枚举类实现\n线程安全，调用效率高，不能延时加载，可以天然的防止反射和反序列化调用\n```\npublic enum SingletonDemo4 {\n\n    //枚举元素本身就是单例\n    INSTANCE;\n\n    //添加自己需要的操作\n    public void singletonOperation(){\n    }\n}\n```\n\n\n# 总结\n单元素的枚举类型已经成为实现Singleton的最佳方法。上面介绍的几种方式主要是通过私有化构造方法来限制一次实列化。\n\n比较：\n占用资源少，不需要延时加载，枚举 好于 饿汉\n占用资源多，需要延时加载，静态内部类 好于 懒汉式', '', 0, '', '', '', 'Effectivejava用私有构造器或者枚举类型强化Singleton(单列)', 0, 'Effectivejava用私有构造器或者枚举类型强化Singleton(单列)', 9, 0, NULL, NULL, 'Effectivejava用私有构造器或者枚举类型强化Singleton(单列)');
INSERT INTO `posts` VALUES (0, 11, '2020-06-03 17:15:21', 0, '2020-06-03 17:15:21', 0, 0, '2020-06-03 17:15:21', '<h1 id=\"简介\">简介</h1>\n<h2 id=\"gson-特点\">Gson 特点</h2>\n<ul>\n<li>Gson是目前功能最全的Json解析神器，Gson当初是为因应Google公司内部需求而由Google自行研发而来，但自从在2008年五月公开发布第一版后已被许多公司或用户应用。</li>\n<li>Gson的应用主要为toJson与fromJson两个转换函数，无依赖，不需要例外额外的jar，能够直接跑在JDK上。</li>\n<li>而在使用这种对象转换之前需先创建好对象的类型以及其成员才能成功的将JSON字符串成功转换成相对应的对象。</li>\n<li>类里面只要有get和set方法，Gson完全可以将复杂类型的json到bean或bean到json的转换，是JSON解析的神器。</li>\n<li>Gson在功能上面无可挑剔，但是性能上面比FastJson有所差距。</li>\n</ul>\n<h2 id=\"fastjson的特点\">Fastjson的特点</h2>\n<ul>\n<li>Fastjson是一个Java语言编写的高性能的JSON处理器,由阿里巴巴公司开发。</li>\n<li>无依赖，不需要例外额外的jar，能够直接跑在JDK上。</li>\n<li>FastJson在复杂类型的Bean转换Json上会出现一些问题，可能会出现引用的类型，导致Json转换出错，需要制定引用。</li>\n<li>FastJson采用独创的算法，将parse的速度提升到极致，超过所有json库。</li>\n</ul>\n<p>在项目选型的时候可以使用Google的Gson和阿里巴巴的FastJson两种并行使用，\n如果只是功能要求，没有性能要求，可以使用google的Gson，\n如果有性能上面的要求可以使用Gson将bean转换json确保数据的正确，使用FastJson将Json转换Bean</p>\n<h1 id=\"gson的资料地址\">Gson的资料地址</h1>\n<p><a href=\"https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/module-summary.html\">api文档</a>\n<a href=\"https://github.com/google/gson\">github地址</a>\n<a href=\"https://github.com/google/gson/blob/master/UserGuide.md\">用法指导</a></p>\n<h1 id=\"gson的几个核心库\">Gson的几个核心库</h1>\n<p>Gson类：解析json的最基础的工具类\nGsonBuilder类：解析json的最基础的工具类</p>\n<p>JsonParser类：解析器来解析JSON字符串到JsonElements的解析树</p>\n<p>JsonElement类：一个类代表的JSON元素抽象类，下面4个类都继承了他</p>\n<ul>\n<li>JsonObject类：JSON对象类型</li>\n<li>JsonArray类：JsonObject数组</li>\n<li>JsonNull类： null值</li>\n<li>JsonPrimitive类：可以理解为基础类型</li>\n</ul>\n<p>TypeToken类：用于创建type，比如泛型List&lt;?&gt;</p>\n<h1 id=\"maven引入\">maven引入</h1>\n<pre><code>&lt;dependencies&gt;\n    &lt;!--  Gson: Java to Json conversion --&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;\n      &lt;artifactId&gt;gson&lt;/artifactId&gt;\n      &lt;version&gt;2.8.6&lt;/version&gt;\n      &lt;scope&gt;compile&lt;/scope&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>\n<h1 id=\"基本类型序列换和反序列化\">基本类型序列换和反序列化</h1>\n<pre><code>//基本类型序列化\nGson gson = new Gson();\ngson.toJson(1); // 1       \ngson.toJson(&quot;abcd&quot;); //&quot;abcd&quot;      \ngson.toJson(new Long(10));// 10\ngson.toJson(new int[]{1,2,3,4});  //[1,2,3,4]\ngson.toJson(new String[] {&quot;aa&quot;,&quot;bb&quot;,&quot;cc&quot;}); //[&quot;aa&quot;,&quot;bb&quot;,&quot;cc&quot;]\n\n// 基本类型反序列化\nint one = gson.fromJson(&quot;1&quot;, int.class);  //1\nInteger one1 = gson.fromJson(&quot;1&quot;, Integer.class); //1\nLong one2 = gson.fromJson(&quot;1&quot;, Long.class); //1\nBoolean b = gson.fromJson(&quot;false&quot;, Boolean.class); //false\nString str = gson.fromJson(&quot;\\&quot;abc\\&quot;&quot;, String.class); // abc\nString[] anotherStr = gson.fromJson(&quot;[\\&quot;abc\\&quot;]&quot;, String[].class); //[&quot;abc&quot;]\n</code></pre>\n<h1 id=\"对象的序列化和反序列化\">对象的序列化和反序列化</h1>\n<pre><code>public class User{\n    private String name;\n    private Integer age;\n    private Boolean isBoy;\n    public User(String name,Integer age,Boolean isBoy) {\n        this.age = age;\n        this.name = name;\n        this.isBoy = isBoy;\n    }\n}\n</code></pre>\n<h2 id=\"序列化和反序列化\">序列化和反序列化</h2>\n<pre><code>User user = new User(&quot;张三&quot;, 25, true);\n//序列化对象\nGson gson = new Gson();\nString userStr = gson.toJson(user);\n//{&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:25,&quot;isBoy&quot;:true}\nSystem.out.println(userStr);\n\n//反序列化\nUser user2 = gson.fromJson(userStr, User.class);\n</code></pre>\n<p>** 说明 **</p>\n<ul>\n<li>\n<p>对象推荐使用私有的。</p>\n</li>\n<li>\n<p>不需要任何注解来修饰需要序列化和反序列化的字段，默认全部进行序列化和反序列化，当然包含超类。</p>\n</li>\n<li>\n<p>如果字段被标记被暂时的，则会被忽略。</p>\n</li>\n<li>\n<p>序列化时，一个null字段将会被忽略。</p>\n</li>\n<li>\n<p>反序列化时，json缺少的条目将被赋予默认值：</p>\n<ul>\n<li>对象  赋值为null</li>\n<li>数字  赋值为0</li>\n<li>布尔  赋值为false</li>\n</ul>\n</li>\n<li>\n<p>如果字段是组合类型，将不会被序列化和反序列化。</p>\n</li>\n<li>\n<p>与内部类，匿名类和局部类中的外部类相对应的字段将被忽略，并且不包含在序列化或反序列化中。</p>\n</li>\n<li>\n<p>Gson还可以反序列化静态嵌套类。但是，Gson无法自动反序列化纯内部类，因为它们的无参构造函数还需要引用包含对象，而该对象在反序列化时不可用。您可以通过使内部类静态化或为其提供自定义InstanceCreator来解决此问题。这是一个例子：</p>\n</li>\n</ul>\n<pre><code>public class A { \n  public String a; \n\n  class B { \n\n    public String b; \n\n    public B() {\n      // No args constructor for B\n    }\n  } \n}\n</code></pre>\n<p>** 注意 **\n上述B类（默认情况下）无法使用Gson进行序列化。\n由于类B是内部类，因此Gson不能将{“ b”：“ abc”}反序列化为B的实例。如果将其定义为静态B类，则Gson将能够反序列化该字符串。另一种解决方案是为B编写自定义实例创建者。</p>\n<pre><code>public class InstanceCreatorForB implements InstanceCreator&lt;A.B&gt; {\n  private final A a;\n  public InstanceCreatorForB(A a)  {\n    this.a = a;\n  }\n  public A.B createInstance(Type type) {\n    return a.new B();\n  }\n}\n</code></pre>\n<p>这只是一种做法，但不推荐。</p>\n<h1 id=\"集合的序列化和反序列化\">集合的序列化和反序列化</h1>\n<pre><code>Gson gson = new Gson();\nCollection&lt;Integer&gt; ints = new ArrayList();\nints.add(1);\nints.add(2);\nints.add(3);\nints.add(4);\nints.add(5);\n\n//序列换\nString json = gson.toJson(ints);  // [1,2,3,4,5]\n\n// 反序列化\nType collectionType = new TypeToken&lt;Collection&lt;Integer&gt;&gt;(){}.getType();\nCollection&lt;Integer&gt; ints2 = gson.fromJson(json, collectionType);\n</code></pre>\n<p>** 注意 **\n通过<code>TypeToken</code>传递泛型</p>\n<pre><code>Type type = new TypeToken&lt;T&gt;(){}.getType();\n</code></pre>\n<p>定义的泛型Y,就是JSON序列化和反序列化的Java类型，当然，里面可以是复杂的集合类型。</p>\n<ul>\n<li>Gson可以序列化任意集合，但是不能进行反序列化他们，因为用户无法指示生成的对象类型。</li>\n<li>反序列化时，集合必须是特定的通用类型。</li>\n</ul>\n<h1 id=\"泛型\">泛型</h1>\n<p>当您调用toJson（obj）时，Gson会调用obj.getClass（）以获取有关要序列化的字段的信息。同样，通常可以在fromJson（json，MyClass.class）方法中传递MyClass.class对象。如果对象是非泛型类型，则可以正常工作。但是，如果对象属于泛型，则由于Java Type Erasure，泛型信息会丢失。这是说明要点的示例：</p>\n<pre><code>class Foo&lt;T&gt; {\n  T value;\n}\nGson gson = new Gson();\nFoo&lt;Bar&gt; foo = new Foo&lt;Bar&gt;();\ngson.toJson(foo); // 可能会失败  \n\ngson.fromJson(json, foo.getClass()); // 失败反序列化 foo.value 作为 Bar\n</code></pre>\n<p>** 分析 **\n上面的代码无法将值解释为Bar类型，因为Gson调用foo.getClass（）来获取其类信息，但是此方法返回的是原始类Foo.class。这意味着Gson无法知道这是Foo <Bar>类型的对象，而不仅仅是纯Foo。\n可以通过为泛型类型指定正确的参数化类型来解决此问题。您可以通过使用TypeToken类来实现。</p>\n<pre><code>Type fooType = new TypeToken&lt;Foo&lt;Bar&gt;&gt;() {}.getType();\ngson.toJson(foo, fooType);\n\ngson.fromJson(json, fooType);\n</code></pre>\n<p>用于获取fooType的习惯用法实际上定义了一个匿名的本地内部类，其中包含一个方法getType（），该方法返回完全参数化的类型。</p>\n<h1 id=\"序列化和反序列化带有任意对象的集合\">序列化和反序列化带有任意对象的集合</h1>\n<p>如果要序列化和反序列化<code>[&quot;hello&quot;,5,{&quot;name&quot;:&quot;GREETINGS&quot;,&quot;source&quot;:&quot;guest&quot;}]</code>,\n您可以使用Gson序列化集合，而无需执行任何特定操作：toJson（collection）将写出所需的输出。但是，由于Gson无法知道如何将输入映射到类型，因此fromJson（json，Collection.class）的反序列化将不起作用。Gson要求您在fromJson（）中提供集合类型的通用版本。\n可以有下面的3种方法</p>\n<ol>\n<li>为Collection.class注册一个类型适配器，该适配器查看每个数组成员并将它们映射到适当的对象。这种方法的缺点是它将破坏Gson中其他收集类型的反序列化。</li>\n<li><code>为MyCollectionMemberType</code>注册类型适配器，并将<code>fromJson（）</code>与<code>Collection &lt;MyCollectionMemberType&gt;</code>一起使用。</li>\n</ol>\n<pre><code>仅当数组显示为顶级元素或可以将保存集合的字段类型更改为Collection 	&lt;MyCollectionMemberType&gt;类型时，此方法才实用。\n</code></pre>\n<ol start=\"3\">\n<li>使用Gson的解析器API（低级流解析器或DOM解析器JsonParser）解析数组元素，然后对每个数组元素使用Gson.fromJson（），这是首选方法。下面是案列。</li>\n</ol>\n<pre><code>public class RawCollectionsExample {\n  static class Event {\n    private String name;\n    private String source;\n    private Event(String name, String source) {\n      this.name = name;\n      this.source = source;\n    }\n    @Override\n    public String toString() {\n      return String.format(&quot;(name=%s, source=%s)&quot;, name, source);\n    }\n  }\n\n  @SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; })\n  public static void main(String[] args) {\n    Gson gson = new Gson();\n    Collection collection = new ArrayList();\n    collection.add(&quot;hello&quot;);\n    collection.add(5);\n    collection.add(new Event(&quot;GREETINGS&quot;, &quot;guest&quot;));\n    String json = gson.toJson(collection);\n    \n    System.out.println(&quot;序列化后的字符串: &quot; + json);\n    \n    JsonParser parser = new JsonParser();\n    JsonArray array = parser.parse(json).getAsJsonArray();\n    \n    String message = gson.fromJson(array.get(0), String.class);\n    int number = gson.fromJson(array.get(1), int.class);\n    Event event = gson.fromJson(array.get(2), Event.class);\n    System.out.printf(&quot;反序列化后得到的信息: %s, %d, %s&quot;, message, number, event);\n  }\n}\n</code></pre>\n<p>输出</p>\n<pre><code>序列化集合: [&quot;hello&quot;,5,{&quot;name&quot;:&quot;GREETINGS&quot;,&quot;source&quot;:&quot;guest&quot;}]\nUsing Gson.fromJson() to get: hello, 5, (name=GREETINGS, source=guest)\n</code></pre>\n<h1 id=\"内置序列化器和反序列化器\">内置序列化器和反序列化器</h1>\n<ul>\n<li>java.net.URL以将其与“ <a href=\"https://github.com/google/gson/”之类的字符串进行匹配\">https://github.com/google/gson/”之类的字符串进行匹配</a></li>\n<li>java.net.URI以将其与“ / google / gson /”之类的字符串进行匹配有关\n更多信息，请参见内部类<a href=\"https://github.com/google/gson/blob/master/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\">TypeAdapters</a>。您也可以在此页面上找到一些常用类的源代码，例如<a href=\"https://sites.google.com/site/gson/gson-type-adapters-for-common-classes-1\">JodaTime</a>。</li>\n</ul>\n<h1 id=\"自定义序列化和反序列化\">自定义序列化和反序列化</h1>\n<p>有的时候默认的不是你想要的，例如<code>DateTime</code>等，Gson允许自定义。分为两部分：</p>\n<ol>\n<li>Json序列化器：需要为对象定义自定义序列化器。</li>\n<li>Json 反序列化器：需要为类型自定义反序列化器。</li>\n<li>实例创建者：如果有无参构造器或注册了反序列化器，则不需要。</li>\n</ol>\n<pre><code>GsonBuilder gson = new GsonBuilder();\ngson.registerTypeAdapter(MyType2.class, new MyTypeAdapter());\ngson.registerTypeAdapter(MyType.class, new MySerializer());\ngson.registerTypeAdapter(MyType.class, new MyDeserializer());\ngson.registerTypeAdapter(MyType.class, new MyInstanceCreator());\n</code></pre>\n<p>registerTypeAdapter调用检查类型适配器是否实现了多个这些接口之一，并为所有这些接口注册它。</p>\n<h2 id=\"创建一个datetime序列化器\">创建一个<code>DateTime</code>序列化器</h2>\n<pre><code>private class DateTimeSerializer implements JsonSerializer&lt;DateTime&gt; {\n  public JsonElement serialize(DateTime src, Type typeOfSrc, JsonSerializationContext context) {\n    return new JsonPrimitive(src.toString());\n  }\n}\n</code></pre>\n<h2 id=\"创建一个datetime反序列化器\">创建一个<code>DateTime</code>反序列化器</h2>\n<pre><code>private class DateTimeDeserializer implements JsonDeserializer&lt;DateTime&gt; {\n  public DateTime deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context)\n      throws JsonParseException {\n    return new DateTime(json.getAsJsonPrimitive().getAsString());\n  }\n}\n</code></pre>\n<h2 id=\"实例创建\">实例创建</h2>\n<p>反序列化对象时，Gson需要创建该类的默认实例。用于序列化和反序列化的行为良好的类应具有无参数的构造函数,如果没得的话，就需要创建下面的实例。</p>\n<pre><code>private class MoneyInstanceCreator implements InstanceCreator&lt;Money&gt; {\n  public Money createInstance(Type type) {\n    return new Money(&quot;1000000&quot;, CurrencyCode.USD);\n  }\n}\n</code></pre>\n<h1 id=\"json输出格式\">Json输出格式</h1>\n<p>Gson默认的是紧凑型的格式（意思就是没得缩进这些，为null的字段不会输出），如果您想使用有格式的输出功能，则必须使用GsonBuilder配置Gson实例。JsonFormatter不会通过我们的公共API公开，因此客户端无法为JSON输出配置默认的打印设置/边距。目前，我们仅提供默认的JsonPrintFormatter，其默认行长为80个字符，2个字符的缩进和4个字符的右边距。</p>\n<p>以下示例显示了如何配置Gson实例以使用默认的<code>JsonPrintFormatter</code>（有格式的输出）而不是<code>JsonCompactFormatter</code>(紧凑的输出)：</p>\n<pre><code>Gson gson = new GsonBuilder().setPrettyPrinting().create();\nString jsonOutput = gson.toJson(someObject);\n</code></pre>\n<h1 id=\"空对象的支持\">空对象的支持</h1>\n<p>Gson中实现的默认行为是忽略空对象字段。这允许更紧凑的输出格式。但是，当JSON格式转换回其Java形式时，客户端必须为这些字段定义默认值。上面对象的时候提过。\n这是配置Gson实例以输出null的方法：</p>\n<pre><code>Gson gson = new GsonBuilder().serializeNulls().create();\n</code></pre>\n<p>注意：使用Gson序列化null时，它将在JsonElement结构中添加一个JsonNull元素。因此，可以在自定义序列化/反序列化中使用此对象。\n例如</p>\n<pre><code>public class Foo {\n  private final String s;\n  private final int i;\n\n  public Foo() {\n    this(null, 5);\n  }\n\n  public Foo(String s, int i) {\n    this.s = s;\n    this.i = i;\n  }\n}\n\nGson gson = new GsonBuilder().serializeNulls().create();\nFoo foo = new Foo();\nString json = gson.toJson(foo);\nSystem.out.println(json);\n\njson = gson.toJson(null);\nSystem.out.println(json);\n</code></pre>\n<p>输出</p>\n<pre><code>{&quot;s&quot;:null,&quot;i&quot;:5}\nnull\n</code></pre>\n<h1 id=\"版本支持\">版本支持</h1>\n<p>可以使用<code>@Since</code>批注维护同一对象的多个版本。可以在类，字段以及将来的方法中使用此注释。为了利用此功能，您必须将Gson实例配置为忽略大于某个版本号的任何字段/对象。如果在Gson实例上未设置任何版本，则它将对所有字段和类进行序列化和反序列化，而与版本无关。\n例如：</p>\n<pre><code>public class VersionedClass {\n  @Since(1.1) private final String newerField;\n  @Since(1.0) private final String newField;\n  private final String field;\n\n  public VersionedClass() {\n    this.newerField = &quot;newer&quot;;\n    this.newField = &quot;new&quot;;\n    this.field = &quot;old&quot;;\n  }\n}\n\nVersionedClass versionedObject = new VersionedClass();\nGson gson = new GsonBuilder().setVersion(1.0).create();\nString jsonOutput = gson.toJson(versionedObject);\nSystem.out.println(jsonOutput);\nSystem.out.println();\n\ngson = new Gson();\njsonOutput = gson.toJson(versionedObject);\nSystem.out.println(jsonOutput);\n</code></pre>\n<p>输出</p>\n<pre><code>{&quot;newField&quot;:&quot;new&quot;,&quot;field&quot;:&quot;old&quot;}\n\n{&quot;newerField&quot;:&quot;newer&quot;,&quot;newField&quot;:&quot;new&quot;,&quot;field&quot;:&quot;old&quot;}\n</code></pre>\n<h1 id=\"排除序列化和反序列化的字段\">排除序列化和反序列化的字段</h1>\n<p>Gson可以排除顶级类，字段，字段类型，下面是几种方式</p>\n<ol>\n<li>Java编辑排除\n默认情况下，如果将字段标记为暂时的，则将其排除。同样，如果将字段标记为静态，则默认情况下将其排除。如果要包括一些临时字段，则可以执行以下操作：</li>\n</ol>\n<pre><code>import java.lang.reflect.Modifier;\nGson gson = new GsonBuilder()\n    .excludeFieldsWithModifiers(Modifier.STATIC)\n    .create();\n</code></pre>\n<p>注意：您可以将任意数量的Modifier常量提供给excludeFieldsWithModifiers方法。例如：</p>\n<pre><code>Gson gson = new GsonBuilder()\n    .excludeFieldsWithModifiers(Modifier.STATIC, Modifier.TRANSIENT, Modifier.VOLATILE)\n    .create();\n</code></pre>\n<ol start=\"2\">\n<li>使用注解<code>@Expose</code>排除\n可以在字段上使用注解<code>@Expose</code>,排除对应的字段，但注意的是，必须使用下面的创建gson实例才有效。</li>\n</ol>\n<pre><code>new GsonBuilder().excludeFieldsWithoutExposeAnnotation().create()\n</code></pre>\n<ol start=\"3\">\n<li>自定义排除策略\n可以使用自定义的排除策略，更多看<a href=\"https://www.javadoc.io/doc/com.google.code.gson/gson/2.8.5/com/google/gson/ExclusionStrategy.html\">ExclusionStrategy</a>\n下面的示例演示如何排除标记有特定@Foo注释的字段，以及如何排除String类的顶级类型（或声明的字段类型）。</li>\n</ol>\n<pre><code>@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.FIELD})\npublic @interface Foo {\n  // Field tag only annotation\n}\n\npublic class SampleObjectForTest {\n  @Foo private final int annotatedField;\n  private final String stringField;\n  private final long longField;\n  private final Class&lt;?&gt; clazzField;\n\n  public SampleObjectForTest() {\n    annotatedField = 5;\n    stringField = &quot;someDefaultValue&quot;;\n    longField = 1234;\n  }\n}\n\npublic class MyExclusionStrategy implements ExclusionStrategy {\n  private final Class&lt;?&gt; typeToSkip;\n\n  private MyExclusionStrategy(Class&lt;?&gt; typeToSkip) {\n    this.typeToSkip = typeToSkip;\n  }\n\n  public boolean shouldSkipClass(Class&lt;?&gt; clazz) {\n    return (clazz == typeToSkip);\n  }\n\n  public boolean shouldSkipField(FieldAttributes f) {\n    return f.getAnnotation(Foo.class) != null;\n  }\n}\n\npublic static void main(String[] args) {\n  Gson gson = new GsonBuilder()\n      .setExclusionStrategies(new MyExclusionStrategy(String.class))\n      .serializeNulls()\n      .create();\n  SampleObjectForTest src = new SampleObjectForTest();\n  String json = gson.toJson(src);\n  System.out.println(json);\n}\n</code></pre>\n<p>输出</p>\n<pre><code>{&quot;longField&quot;:1234}\n</code></pre>\n<h1 id=\"字段命名支持\">字段命名支持</h1>\n<p>可以通过<code>@SerializedName</code>注解重新命名字段</p>\n<pre><code>private class SomeObject {\n  @SerializedName(&quot;custom_naming&quot;) private final String someField;\n  private final String someOtherField;\n\n  public SomeObject(String a, String b) {\n    this.someField = a;\n    this.someOtherField = b;\n  }\n}\n\nSomeObject someObject = new SomeObject(&quot;first&quot;, &quot;second&quot;);\nGson gson = new GsonBuilder().setFieldNamingPolicy(FieldNamingPolicy.UPPER_CAMEL_CASE).create();\nString jsonRepresentation = gson.toJson(someObject);\nSystem.out.println(jsonRepresentation);\n</code></pre>\n<p>输出</p>\n<pre><code>{&quot;custom_naming&quot;:&quot;first&quot;,&quot;SomeOtherField&quot;:&quot;second&quot;}\n</code></pre>\n<p>参考<a href=\"https://www.javadoc.io/doc/com.google.code.gson/gson/2.8.5/com/google/gson/FieldNamingPolicy.html\">FieldNamingPolicy</a>里面的类型值。</p>\n<h1 id=\"总结\">总结</h1>\n<ol>\n<li>Gson的几个注解</li>\n</ol>\n<ul>\n<li><code>@Expose</code>\n字段的排除，序列化和反序列化对该字段不生效，必须配置下面的才生效。</li>\n</ul>\n<pre><code>Gson gson = new GsonBuilder()\n.excludeFieldsWithModifiers(Modifier.STATIC, Modifier.TRANSIENT, Modifier.VOLATILE)\n.create();\n</code></pre>\n<ul>\n<li><code>@SerializedName</code>\n重命名字段</li>\n<li><code>@Since</code>\n对版本的支持，用于指定版本,配合下面的使用</li>\n</ul>\n<pre><code>Gson gson = new GsonBuilder().setVersion(1.0).create();\n</code></pre>\n<ul>\n<li><code>@JsonAdapter</code>\n指示用于类或字段的Gson TypeAdapter的注释。</li>\n</ul>\n<p>更多东西看官方文档和分析源码。</p>\n', 0, '# 简介\n\n## Gson 特点\n- Gson是目前功能最全的Json解析神器，Gson当初是为因应Google公司内部需求而由Google自行研发而来，但自从在2008年五月公开发布第一版后已被许多公司或用户应用。\n- Gson的应用主要为toJson与fromJson两个转换函数，无依赖，不需要例外额外的jar，能够直接跑在JDK上。\n- 而在使用这种对象转换之前需先创建好对象的类型以及其成员才能成功的将JSON字符串成功转换成相对应的对象。\n- 类里面只要有get和set方法，Gson完全可以将复杂类型的json到bean或bean到json的转换，是JSON解析的神器。\n- Gson在功能上面无可挑剔，但是性能上面比FastJson有所差距。\n\n## Fastjson的特点\n- Fastjson是一个Java语言编写的高性能的JSON处理器,由阿里巴巴公司开发。\n- 无依赖，不需要例外额外的jar，能够直接跑在JDK上。\n- FastJson在复杂类型的Bean转换Json上会出现一些问题，可能会出现引用的类型，导致Json转换出错，需要制定引用。\n- FastJson采用独创的算法，将parse的速度提升到极致，超过所有json库。\n\n\n在项目选型的时候可以使用Google的Gson和阿里巴巴的FastJson两种并行使用，\n如果只是功能要求，没有性能要求，可以使用google的Gson，\n如果有性能上面的要求可以使用Gson将bean转换json确保数据的正确，使用FastJson将Json转换Bean\n\n\n# Gson的资料地址\n[api文档](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/module-summary.html)\n[github地址](https://github.com/google/gson)\n[用法指导](https://github.com/google/gson/blob/master/UserGuide.md)\n\n# Gson的几个核心库\nGson类：解析json的最基础的工具类\nGsonBuilder类：解析json的最基础的工具类\n\nJsonParser类：解析器来解析JSON字符串到JsonElements的解析树\n\nJsonElement类：一个类代表的JSON元素抽象类，下面4个类都继承了他\n- JsonObject类：JSON对象类型\n- JsonArray类：JsonObject数组\n- JsonNull类： null值\n- JsonPrimitive类：可以理解为基础类型\n\nTypeToken类：用于创建type，比如泛型List<?>\n\n# maven引入\n```\n<dependencies>\n    <!--  Gson: Java to Json conversion -->\n    <dependency>\n      <groupId>com.google.code.gson</groupId>\n      <artifactId>gson</artifactId>\n      <version>2.8.6</version>\n      <scope>compile</scope>\n    </dependency>\n</dependencies>\n```\n\n# 基本类型序列换和反序列化\n```\n//基本类型序列化\nGson gson = new Gson();\ngson.toJson(1); // 1       \ngson.toJson(\"abcd\"); //\"abcd\"      \ngson.toJson(new Long(10));// 10\ngson.toJson(new int[]{1,2,3,4});  //[1,2,3,4]\ngson.toJson(new String[] {\"aa\",\"bb\",\"cc\"}); //[\"aa\",\"bb\",\"cc\"]\n\n// 基本类型反序列化\nint one = gson.fromJson(\"1\", int.class);  //1\nInteger one1 = gson.fromJson(\"1\", Integer.class); //1\nLong one2 = gson.fromJson(\"1\", Long.class); //1\nBoolean b = gson.fromJson(\"false\", Boolean.class); //false\nString str = gson.fromJson(\"\\\"abc\\\"\", String.class); // abc\nString[] anotherStr = gson.fromJson(\"[\\\"abc\\\"]\", String[].class); //[\"abc\"]\n```\n\n# 对象的序列化和反序列化\n```\npublic class User{\n    private String name;\n    private Integer age;\n    private Boolean isBoy;\n    public User(String name,Integer age,Boolean isBoy) {\n        this.age = age;\n        this.name = name;\n        this.isBoy = isBoy;\n    }\n}\n```\n## 序列化和反序列化\n```\nUser user = new User(\"张三\", 25, true);\n//序列化对象\nGson gson = new Gson();\nString userStr = gson.toJson(user);\n//{\"name\":\"张三\",\"age\":25,\"isBoy\":true}\nSystem.out.println(userStr);\n\n//反序列化\nUser user2 = gson.fromJson(userStr, User.class);\n```\n** 说明 **\n- 对象推荐使用私有的。\n- 不需要任何注解来修饰需要序列化和反序列化的字段，默认全部进行序列化和反序列化，当然包含超类。\n- 如果字段被标记被暂时的，则会被忽略。\n- 序列化时，一个null字段将会被忽略。\n- 反序列化时，json缺少的条目将被赋予默认值：\n	- 对象  赋值为null\n	- 数字  赋值为0\n	- 布尔  赋值为false\n- 如果字段是组合类型，将不会被序列化和反序列化。\n- 与内部类，匿名类和局部类中的外部类相对应的字段将被忽略，并且不包含在序列化或反序列化中。 \n\n- Gson还可以反序列化静态嵌套类。但是，Gson无法自动反序列化纯内部类，因为它们的无参构造函数还需要引用包含对象，而该对象在反序列化时不可用。您可以通过使内部类静态化或为其提供自定义InstanceCreator来解决此问题。这是一个例子：\n```\npublic class A { \n  public String a; \n\n  class B { \n\n    public String b; \n\n    public B() {\n      // No args constructor for B\n    }\n  } \n}\n```\n** 注意 **\n上述B类（默认情况下）无法使用Gson进行序列化。\n由于类B是内部类，因此Gson不能将{“ b”：“ abc”}反序列化为B的实例。如果将其定义为静态B类，则Gson将能够反序列化该字符串。另一种解决方案是为B编写自定义实例创建者。\n```\npublic class InstanceCreatorForB implements InstanceCreator<A.B> {\n  private final A a;\n  public InstanceCreatorForB(A a)  {\n    this.a = a;\n  }\n  public A.B createInstance(Type type) {\n    return a.new B();\n  }\n}\n```\n这只是一种做法，但不推荐。\n\n# 集合的序列化和反序列化\n```\nGson gson = new Gson();\nCollection<Integer> ints = new ArrayList();\nints.add(1);\nints.add(2);\nints.add(3);\nints.add(4);\nints.add(5);\n\n//序列换\nString json = gson.toJson(ints);  // [1,2,3,4,5]\n\n// 反序列化\nType collectionType = new TypeToken<Collection<Integer>>(){}.getType();\nCollection<Integer> ints2 = gson.fromJson(json, collectionType);\n```\n** 注意 **\n通过`TypeToken`传递泛型\n```\nType type = new TypeToken<T>(){}.getType();\n```\n定义的泛型Y,就是JSON序列化和反序列化的Java类型，当然，里面可以是复杂的集合类型。\n\n- Gson可以序列化任意集合，但是不能进行反序列化他们，因为用户无法指示生成的对象类型。\n- 反序列化时，集合必须是特定的通用类型。\n\n# 泛型\n当您调用toJson（obj）时，Gson会调用obj.getClass（）以获取有关要序列化的字段的信息。同样，通常可以在fromJson（json，MyClass.class）方法中传递MyClass.class对象。如果对象是非泛型类型，则可以正常工作。但是，如果对象属于泛型，则由于Java Type Erasure，泛型信息会丢失。这是说明要点的示例：\n```\nclass Foo<T> {\n  T value;\n}\nGson gson = new Gson();\nFoo<Bar> foo = new Foo<Bar>();\ngson.toJson(foo); // 可能会失败  \n\ngson.fromJson(json, foo.getClass()); // 失败反序列化 foo.value 作为 Bar\n```\n** 分析 ** \n上面的代码无法将值解释为Bar类型，因为Gson调用foo.getClass（）来获取其类信息，但是此方法返回的是原始类Foo.class。这意味着Gson无法知道这是Foo <Bar>类型的对象，而不仅仅是纯Foo。\n可以通过为泛型类型指定正确的参数化类型来解决此问题。您可以通过使用TypeToken类来实现。\n\n```\nType fooType = new TypeToken<Foo<Bar>>() {}.getType();\ngson.toJson(foo, fooType);\n\ngson.fromJson(json, fooType);\n```\n用于获取fooType的习惯用法实际上定义了一个匿名的本地内部类，其中包含一个方法getType（），该方法返回完全参数化的类型。\n\n# 序列化和反序列化带有任意对象的集合\n\n如果要序列化和反序列化`[\"hello\",5,{\"name\":\"GREETINGS\",\"source\":\"guest\"}]`,\n您可以使用Gson序列化集合，而无需执行任何特定操作：toJson（collection）将写出所需的输出。但是，由于Gson无法知道如何将输入映射到类型，因此fromJson（json，Collection.class）的反序列化将不起作用。Gson要求您在fromJson（）中提供集合类型的通用版本。\n可以有下面的3种方法\n\n1. 为Collection.class注册一个类型适配器，该适配器查看每个数组成员并将它们映射到适当的对象。这种方法的缺点是它将破坏Gson中其他收集类型的反序列化。\n2. `为MyCollectionMemberType`注册类型适配器，并将`fromJson（）`与`Collection <MyCollectionMemberType>`一起使用。\n```\n仅当数组显示为顶级元素或可以将保存集合的字段类型更改为Collection 	<MyCollectionMemberType>类型时，此方法才实用。\n```\n3. 使用Gson的解析器API（低级流解析器或DOM解析器JsonParser）解析数组元素，然后对每个数组元素使用Gson.fromJson（），这是首选方法。下面是案列。\n```\npublic class RawCollectionsExample {\n  static class Event {\n    private String name;\n    private String source;\n    private Event(String name, String source) {\n      this.name = name;\n      this.source = source;\n    }\n    @Override\n    public String toString() {\n      return String.format(\"(name=%s, source=%s)\", name, source);\n    }\n  }\n\n  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n  public static void main(String[] args) {\n    Gson gson = new Gson();\n    Collection collection = new ArrayList();\n    collection.add(\"hello\");\n    collection.add(5);\n    collection.add(new Event(\"GREETINGS\", \"guest\"));\n    String json = gson.toJson(collection);\n    \n    System.out.println(\"序列化后的字符串: \" + json);\n    \n    JsonParser parser = new JsonParser();\n    JsonArray array = parser.parse(json).getAsJsonArray();\n    \n    String message = gson.fromJson(array.get(0), String.class);\n    int number = gson.fromJson(array.get(1), int.class);\n    Event event = gson.fromJson(array.get(2), Event.class);\n    System.out.printf(\"反序列化后得到的信息: %s, %d, %s\", message, number, event);\n  }\n}\n```\n输出\n```\n序列化集合: [\"hello\",5,{\"name\":\"GREETINGS\",\"source\":\"guest\"}]\nUsing Gson.fromJson() to get: hello, 5, (name=GREETINGS, source=guest)\n```\n# 内置序列化器和反序列化器\n- java.net.URL以将其与“ https://github.com/google/gson/”之类的字符串进行匹配\n- java.net.URI以将其与“ / google / gson /”之类的字符串进行匹配有关\n更多信息，请参见内部类[TypeAdapters](https://github.com/google/gson/blob/master/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java)。您也可以在此页面上找到一些常用类的源代码，例如[JodaTime](https://sites.google.com/site/gson/gson-type-adapters-for-common-classes-1)。\n\n# 自定义序列化和反序列化\n有的时候默认的不是你想要的，例如`DateTime`等，Gson允许自定义。分为两部分：\n1. Json序列化器：需要为对象定义自定义序列化器。\n2. Json 反序列化器：需要为类型自定义反序列化器。\n3. 实例创建者：如果有无参构造器或注册了反序列化器，则不需要。\n```\nGsonBuilder gson = new GsonBuilder();\ngson.registerTypeAdapter(MyType2.class, new MyTypeAdapter());\ngson.registerTypeAdapter(MyType.class, new MySerializer());\ngson.registerTypeAdapter(MyType.class, new MyDeserializer());\ngson.registerTypeAdapter(MyType.class, new MyInstanceCreator());\n```\nregisterTypeAdapter调用检查类型适配器是否实现了多个这些接口之一，并为所有这些接口注册它。\n\n## 创建一个`DateTime`序列化器\n```\nprivate class DateTimeSerializer implements JsonSerializer<DateTime> {\n  public JsonElement serialize(DateTime src, Type typeOfSrc, JsonSerializationContext context) {\n    return new JsonPrimitive(src.toString());\n  }\n}\n```\n\n## 创建一个`DateTime`反序列化器\n```\nprivate class DateTimeDeserializer implements JsonDeserializer<DateTime> {\n  public DateTime deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context)\n      throws JsonParseException {\n    return new DateTime(json.getAsJsonPrimitive().getAsString());\n  }\n}\n```\n\n## 实例创建\n反序列化对象时，Gson需要创建该类的默认实例。用于序列化和反序列化的行为良好的类应具有无参数的构造函数,如果没得的话，就需要创建下面的实例。\n```\nprivate class MoneyInstanceCreator implements InstanceCreator<Money> {\n  public Money createInstance(Type type) {\n    return new Money(\"1000000\", CurrencyCode.USD);\n  }\n}\n```\n\n# Json输出格式\nGson默认的是紧凑型的格式（意思就是没得缩进这些，为null的字段不会输出），如果您想使用有格式的输出功能，则必须使用GsonBuilder配置Gson实例。JsonFormatter不会通过我们的公共API公开，因此客户端无法为JSON输出配置默认的打印设置/边距。目前，我们仅提供默认的JsonPrintFormatter，其默认行长为80个字符，2个字符的缩进和4个字符的右边距。\n\n以下示例显示了如何配置Gson实例以使用默认的`JsonPrintFormatter`（有格式的输出）而不是`JsonCompactFormatter`(紧凑的输出)：\n```\nGson gson = new GsonBuilder().setPrettyPrinting().create();\nString jsonOutput = gson.toJson(someObject);\n```\n\n# 空对象的支持\nGson中实现的默认行为是忽略空对象字段。这允许更紧凑的输出格式。但是，当JSON格式转换回其Java形式时，客户端必须为这些字段定义默认值。上面对象的时候提过。\n这是配置Gson实例以输出null的方法：\n```\nGson gson = new GsonBuilder().serializeNulls().create();\n```\n注意：使用Gson序列化null时，它将在JsonElement结构中添加一个JsonNull元素。因此，可以在自定义序列化/反序列化中使用此对象。\n例如\n```\npublic class Foo {\n  private final String s;\n  private final int i;\n\n  public Foo() {\n    this(null, 5);\n  }\n\n  public Foo(String s, int i) {\n    this.s = s;\n    this.i = i;\n  }\n}\n\nGson gson = new GsonBuilder().serializeNulls().create();\nFoo foo = new Foo();\nString json = gson.toJson(foo);\nSystem.out.println(json);\n\njson = gson.toJson(null);\nSystem.out.println(json);\n```\n输出\n```\n{\"s\":null,\"i\":5}\nnull\n```\n\n# 版本支持\n可以使用`@Since`批注维护同一对象的多个版本。可以在类，字段以及将来的方法中使用此注释。为了利用此功能，您必须将Gson实例配置为忽略大于某个版本号的任何字段/对象。如果在Gson实例上未设置任何版本，则它将对所有字段和类进行序列化和反序列化，而与版本无关。\n例如：\n```\npublic class VersionedClass {\n  @Since(1.1) private final String newerField;\n  @Since(1.0) private final String newField;\n  private final String field;\n\n  public VersionedClass() {\n    this.newerField = \"newer\";\n    this.newField = \"new\";\n    this.field = \"old\";\n  }\n}\n\nVersionedClass versionedObject = new VersionedClass();\nGson gson = new GsonBuilder().setVersion(1.0).create();\nString jsonOutput = gson.toJson(versionedObject);\nSystem.out.println(jsonOutput);\nSystem.out.println();\n\ngson = new Gson();\njsonOutput = gson.toJson(versionedObject);\nSystem.out.println(jsonOutput);\n```\n输出\n```\n{\"newField\":\"new\",\"field\":\"old\"}\n\n{\"newerField\":\"newer\",\"newField\":\"new\",\"field\":\"old\"}\n```\n\n# 排除序列化和反序列化的字段\nGson可以排除顶级类，字段，字段类型，下面是几种方式\n1. Java编辑排除\n默认情况下，如果将字段标记为暂时的，则将其排除。同样，如果将字段标记为静态，则默认情况下将其排除。如果要包括一些临时字段，则可以执行以下操作：\n```\nimport java.lang.reflect.Modifier;\nGson gson = new GsonBuilder()\n    .excludeFieldsWithModifiers(Modifier.STATIC)\n    .create();\n```\n注意：您可以将任意数量的Modifier常量提供给excludeFieldsWithModifiers方法。例如：\n```\nGson gson = new GsonBuilder()\n    .excludeFieldsWithModifiers(Modifier.STATIC, Modifier.TRANSIENT, Modifier.VOLATILE)\n    .create();\n```\n\n2. 使用注解`@Expose`排除\n可以在字段上使用注解`@Expose`,排除对应的字段，但注意的是，必须使用下面的创建gson实例才有效。\n```\nnew GsonBuilder().excludeFieldsWithoutExposeAnnotation().create()\n```\n\n3. 自定义排除策略\n可以使用自定义的排除策略，更多看[ExclusionStrategy](https://www.javadoc.io/doc/com.google.code.gson/gson/2.8.5/com/google/gson/ExclusionStrategy.html)\n下面的示例演示如何排除标记有特定@Foo注释的字段，以及如何排除String类的顶级类型（或声明的字段类型）。\n```\n@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.FIELD})\npublic @interface Foo {\n  // Field tag only annotation\n}\n\npublic class SampleObjectForTest {\n  @Foo private final int annotatedField;\n  private final String stringField;\n  private final long longField;\n  private final Class<?> clazzField;\n\n  public SampleObjectForTest() {\n    annotatedField = 5;\n    stringField = \"someDefaultValue\";\n    longField = 1234;\n  }\n}\n\npublic class MyExclusionStrategy implements ExclusionStrategy {\n  private final Class<?> typeToSkip;\n\n  private MyExclusionStrategy(Class<?> typeToSkip) {\n    this.typeToSkip = typeToSkip;\n  }\n\n  public boolean shouldSkipClass(Class<?> clazz) {\n    return (clazz == typeToSkip);\n  }\n\n  public boolean shouldSkipField(FieldAttributes f) {\n    return f.getAnnotation(Foo.class) != null;\n  }\n}\n\npublic static void main(String[] args) {\n  Gson gson = new GsonBuilder()\n      .setExclusionStrategies(new MyExclusionStrategy(String.class))\n      .serializeNulls()\n      .create();\n  SampleObjectForTest src = new SampleObjectForTest();\n  String json = gson.toJson(src);\n  System.out.println(json);\n}\n```\n\n输出\n```\n{\"longField\":1234}\n```\n\n# 字段命名支持\n可以通过` @SerializedName`注解重新命名字段\n```\nprivate class SomeObject {\n  @SerializedName(\"custom_naming\") private final String someField;\n  private final String someOtherField;\n\n  public SomeObject(String a, String b) {\n    this.someField = a;\n    this.someOtherField = b;\n  }\n}\n\nSomeObject someObject = new SomeObject(\"first\", \"second\");\nGson gson = new GsonBuilder().setFieldNamingPolicy(FieldNamingPolicy.UPPER_CAMEL_CASE).create();\nString jsonRepresentation = gson.toJson(someObject);\nSystem.out.println(jsonRepresentation);\n```\n输出\n```\n{\"custom_naming\":\"first\",\"SomeOtherField\":\"second\"}\n```\n参考[FieldNamingPolicy](https://www.javadoc.io/doc/com.google.code.gson/gson/2.8.5/com/google/gson/FieldNamingPolicy.html)里面的类型值。\n\n# 总结 \n\n1. Gson的几个注解\n - `@Expose`\n 字段的排除，序列化和反序列化对该字段不生效，必须配置下面的才生效。\n ```\n Gson gson = new GsonBuilder()\n .excludeFieldsWithModifiers(Modifier.STATIC, Modifier.TRANSIENT, Modifier.VOLATILE)\n .create();\n ```\n - `@SerializedName`\n重命名字段\n- `@Since`\n对版本的支持，用于指定版本,配合下面的使用\n```\nGson gson = new GsonBuilder().setVersion(1.0).create();\n```\n- `@JsonAdapter`\n指示用于类或字段的Gson TypeAdapter的注释。\n\n更多东西看官方文档和分析源码。', '', 0, '', '', '', 'GSON简单使用', 0, 'GSON简单使用', 6, 0, NULL, NULL, 'GSON简单使用');
INSERT INTO `posts` VALUES (0, 12, '2020-06-03 17:16:34', 0, '2020-06-03 17:18:30', 0, 0, '2020-06-03 17:18:30', '<h1 id=\"简介\">简介</h1>\n<p>简单介绍Gson对枚举的序列化和反序列化，顺便自定义的序列化器和反序列化器的一个说明。</p>\n<h1 id=\"例子\">例子</h1>\n<h2 id=\"创建一个性别枚举\">创建一个性别枚举</h2>\n<pre><code>public enum Gender{\n    @SerializedName(&quot;男孩&quot;)\n    BOY,\n\n    GIRL,\n\n    UNKNOWN\n}\n</code></pre>\n<h2 id=\"对name进行序列化和反序列化\">对name()进行序列化和反序列化</h2>\n<pre><code>Gson gson = new Gson();\n//序列化\nString sexGirl = gson.toJson(Gender.GIRL);\nSystem.out.println(sexGirl); //&quot;GIRL&quot;\n\n//反序列化\nGender gril = gson.fromJson(sexGirl, Gender.class); //GIRL\n</code></pre>\n<h2 id=\"通过serializedname指定枚举的含义\">通过<code>@SerializedName</code>指定枚举的含义</h2>\n<pre><code>Gson gson = new Gson();\n//序列化\nString sexBoy = gson.toJson(Gender.BOY);\nSystem.out.println(sexBoy); //&quot;男孩&quot;\n//反序列化\nGender boy = gson.fromJson(sexBoy, Gender.class); //BOY\n</code></pre>\n<p>我们可以通过<code>@SerializedName</code>注解来指定枚举的含义</p>\n<h2 id=\"序列化为ordinal\">序列化为<code>ordinal()</code></h2>\n<p>要序列化为枚举的ordinal值 这需要自定义序列化器和反序列化器</p>\n<h3 id=\"创建序列化器\">创建序列化器</h3>\n<pre><code>	public  class EnumSerializer implements JsonSerializer&lt;Enum&lt;?&gt;&gt;{\n		@Override\n		public JsonElement serialize(Enum&lt;?&gt; src, Type typeOfSrc, JsonSerializationContext context) {\n			//使用ordinal 来序列化成基本数据值\n			return new JsonPrimitive(src.ordinal());\n		}\n	}\n</code></pre>\n<h3 id=\"创建反序列化器\">创建反序列化器</h3>\n<pre><code>public static class EnumDeserialize implements JsonDeserializer&lt;Enum&lt;?&gt;&gt;{\n\n		@Override\n		public Enum&lt;?&gt; deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context)\n				throws JsonParseException {\n			//判断是否基本类型\n			if(json.isJsonPrimitive()) {\n				try {\n					JsonPrimitive jsonPrimitive = json.getAsJsonPrimitive();\n					//获取枚举类对象\n					Class classEnum = Class.forName(typeOfT.getTypeName());\n					//获取枚举内容\n					Enum&lt;?&gt;[] enums = (Enum&lt;?&gt;[]) classEnum.getEnumConstants();\n					if(jsonPrimitive.isNumber()) {\n						return enums[jsonPrimitive.getAsInt()];\n					}else if(jsonPrimitive.isString()){\n						for(Enum&lt;?&gt; constant : enums) {\n							if(constant.name().equalsIgnoreCase(jsonPrimitive.getAsString())) {\n								return constant;\n							}\n						}\n					}\n					\n				} catch (ClassNotFoundException e) {\n					// TODO Auto-generated catch block\n					e.printStackTrace();\n				}\n			}\n			return null;\n		}\n		\n	}\n</code></pre>\n<h3 id=\"调用方式\">调用方式</h3>\n<pre><code>//对ordinal()的，就要自定义序列化和反序列化器了\nGsonBuilder gsonBuilder = new GsonBuilder();\ngsonBuilder.registerTypeHierarchyAdapter(Enum.class, new EnumSerializer());\ngsonBuilder.registerTypeHierarchyAdapter(Enum.class, new EnumDeserialize());\n\n//序列化\nGson gsonB = gsonBuilder.create();\nString boyB = gsonB.toJson(Gender.BOY);\nSystem.out.println(&quot;boyB:&quot;+boyB); //boyB:0\n\n//反序列化\nGender boyB1 = gsonB.fromJson(boyB, Gender.class);\nSystem.out.println(boyB1); //BOY\n</code></pre>\n<p>当然，序列化器和反序列化器可以通过内内部类实现</p>\n<pre><code>gsonBuilder.registerTypeHierarchyAdapter(Enum.class, new JsonSerializer&lt;Enum&lt;?&gt;&gt;() {\n    @Override\n    public JsonElement serialize(Enum&lt;?&gt; src, Type typeOfSrc, JsonSerializationContext context) {\n    	return new JsonPrimitive(src.ordinal());\n    }\n});\n</code></pre>\n<h1 id=\"总结\">总结</h1>\n<p>这里简单的列举了Gson对枚举的支持，同时也简单的的指明了自定义序列化器和反序列化器的写法。</p>\n', 0, '# 简介\n简单介绍Gson对枚举的序列化和反序列化，顺便自定义的序列化器和反序列化器的一个说明。\n\n# 例子\n## 创建一个性别枚举\n```\npublic enum Gender{\n    @SerializedName(\"男孩\")\n    BOY,\n\n    GIRL,\n\n    UNKNOWN\n}\n```\n\n## 对name()进行序列化和反序列化\n```\nGson gson = new Gson();\n//序列化\nString sexGirl = gson.toJson(Gender.GIRL);\nSystem.out.println(sexGirl); //\"GIRL\"\n\n//反序列化\nGender gril = gson.fromJson(sexGirl, Gender.class); //GIRL\n```\n\n## 通过`@SerializedName`指定枚举的含义\n```\nGson gson = new Gson();\n//序列化\nString sexBoy = gson.toJson(Gender.BOY);\nSystem.out.println(sexBoy); //\"男孩\"\n//反序列化\nGender boy = gson.fromJson(sexBoy, Gender.class); //BOY\n```\n我们可以通过`@SerializedName`注解来指定枚举的含义\n\n## 序列化为`ordinal()`\n要序列化为枚举的ordinal值 这需要自定义序列化器和反序列化器\n\n### 创建序列化器\n```\n	public  class EnumSerializer implements JsonSerializer<Enum<?>>{\n		@Override\n		public JsonElement serialize(Enum<?> src, Type typeOfSrc, JsonSerializationContext context) {\n			//使用ordinal 来序列化成基本数据值\n			return new JsonPrimitive(src.ordinal());\n		}\n	}\n```\n\n### 创建反序列化器\n```\npublic static class EnumDeserialize implements JsonDeserializer<Enum<?>>{\n\n		@Override\n		public Enum<?> deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context)\n				throws JsonParseException {\n			//判断是否基本类型\n			if(json.isJsonPrimitive()) {\n				try {\n					JsonPrimitive jsonPrimitive = json.getAsJsonPrimitive();\n					//获取枚举类对象\n					Class classEnum = Class.forName(typeOfT.getTypeName());\n					//获取枚举内容\n					Enum<?>[] enums = (Enum<?>[]) classEnum.getEnumConstants();\n					if(jsonPrimitive.isNumber()) {\n						return enums[jsonPrimitive.getAsInt()];\n					}else if(jsonPrimitive.isString()){\n						for(Enum<?> constant : enums) {\n							if(constant.name().equalsIgnoreCase(jsonPrimitive.getAsString())) {\n								return constant;\n							}\n						}\n					}\n					\n				} catch (ClassNotFoundException e) {\n					// TODO Auto-generated catch block\n					e.printStackTrace();\n				}\n			}\n			return null;\n		}\n		\n	}\n```\n\n### 调用方式\n```\n//对ordinal()的，就要自定义序列化和反序列化器了\nGsonBuilder gsonBuilder = new GsonBuilder();\ngsonBuilder.registerTypeHierarchyAdapter(Enum.class, new EnumSerializer());\ngsonBuilder.registerTypeHierarchyAdapter(Enum.class, new EnumDeserialize());\n\n//序列化\nGson gsonB = gsonBuilder.create();\nString boyB = gsonB.toJson(Gender.BOY);\nSystem.out.println(\"boyB:\"+boyB); //boyB:0\n\n//反序列化\nGender boyB1 = gsonB.fromJson(boyB, Gender.class);\nSystem.out.println(boyB1); //BOY\n```\n\n当然，序列化器和反序列化器可以通过内内部类实现\n```\ngsonBuilder.registerTypeHierarchyAdapter(Enum.class, new JsonSerializer<Enum<?>>() {\n    @Override\n    public JsonElement serialize(Enum<?> src, Type typeOfSrc, JsonSerializationContext context) {\n    	return new JsonPrimitive(src.ordinal());\n    }\n});\n```\n\n# 总结\n这里简单的列举了Gson对枚举的支持，同时也简单的的指明了自定义序列化器和反序列化器的写法。', '', 0, '', '', '', 'Gson对枚举的支持', 0, 'Gson对枚举的支持', 6, 0, NULL, NULL, 'Gson对枚举的支持');

-- ----------------------------
-- Table structure for tags
-- ----------------------------
DROP TABLE IF EXISTS `tags`;
CREATE TABLE `tags`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `slug_name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `slug` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `thumbnail` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `tags_name`(`name`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 18 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tags
-- ----------------------------
INSERT INTO `tags` VALUES (1, '2019-09-30 10:30:04', 0, '2019-09-30 10:30:04', 'jdk源码', 'jdk', 'jdk', NULL);
INSERT INTO `tags` VALUES (2, '2019-09-30 10:30:20', 0, '2019-09-30 10:30:20', 'Mysql', 'mysql', 'mysql', NULL);
INSERT INTO `tags` VALUES (3, '2019-09-30 10:30:45', 0, '2019-09-30 10:30:45', 'redis', 'redis', 'redis', NULL);
INSERT INTO `tags` VALUES (4, '2019-09-30 17:40:10', 0, '2019-09-30 17:40:10', '缓存', 'cache', 'cache', NULL);
INSERT INTO `tags` VALUES (5, '2019-09-30 17:49:24', 0, '2019-09-30 17:49:24', '任务', 'task', 'task', NULL);
INSERT INTO `tags` VALUES (6, '2019-10-24 17:30:02', 0, '2019-10-24 17:30:02', 'netty', 'netty', 'netty', NULL);
INSERT INTO `tags` VALUES (7, '2019-12-27 14:24:32', 0, '2019-12-27 14:24:32', '工具', '1577427872613', '1577427872613', NULL);
INSERT INTO `tags` VALUES (8, '2020-05-12 17:33:54', 0, '2020-05-12 17:33:54', 'jdk8', 'jdk8', 'jdk8', NULL);
INSERT INTO `tags` VALUES (9, '2020-05-12 17:33:54', 0, '2020-05-12 17:33:54', 'map', 'map', 'map', NULL);
INSERT INTO `tags` VALUES (10, '2020-05-12 17:33:54', 0, '2020-05-12 17:33:54', 'java', 'java', 'java', NULL);
INSERT INTO `tags` VALUES (11, '2020-06-03 17:04:13', 0, '2020-06-03 17:04:13', 'EffectiveJava', 'effectivejava', 'effectivejava', NULL);
INSERT INTO `tags` VALUES (12, '2020-06-03 17:04:13', 0, '2020-06-03 17:04:13', '代码设计', '1591175053767', '1591175053767', NULL);
INSERT INTO `tags` VALUES (13, '2020-06-03 17:04:24', 0, '2020-06-03 17:04:24', '创建对象', '1591175064707', '1591175064707', NULL);
INSERT INTO `tags` VALUES (14, '2020-06-03 17:09:57', 0, '2020-06-03 17:09:57', '单单例', '1591175397914', '1591175397914', NULL);
INSERT INTO `tags` VALUES (15, '2020-06-03 17:15:17', 0, '2020-06-03 17:15:17', 'gson', 'gson', 'gson', NULL);
INSERT INTO `tags` VALUES (16, '2020-06-03 17:15:17', 0, '2020-06-03 17:15:17', 'goole', 'goole', 'goole', NULL);
INSERT INTO `tags` VALUES (17, '2020-06-03 17:16:34', 0, '2020-06-03 17:16:34', '枚举', '1591175794188', '1591175794188', NULL);

-- ----------------------------
-- Table structure for theme_settings
-- ----------------------------
DROP TABLE IF EXISTS `theme_settings`;
CREATE TABLE `theme_settings`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `setting_key` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `theme_id` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `setting_value` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `theme_settings_setting_key`(`setting_key`) USING BTREE,
  INDEX `theme_settings_theme_id`(`theme_id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 16 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of theme_settings
-- ----------------------------
INSERT INTO `theme_settings` VALUES (1, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_profile', 'ppoffice_icarus', 'true');
INSERT INTO `theme_settings` VALUES (2, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_links', 'ppoffice_icarus', 'true');
INSERT INTO `theme_settings` VALUES (3, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'code_pretty', 'ppoffice_icarus', 'Default');
INSERT INTO `theme_settings` VALUES (4, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'profile_avatar_type', 'ppoffice_icarus', 'avatar_rounded');
INSERT INTO `theme_settings` VALUES (5, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'mathjax_enable', 'ppoffice_icarus', 'false');
INSERT INTO `theme_settings` VALUES (6, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_recentpost', 'ppoffice_icarus', 'true');
INSERT INTO `theme_settings` VALUES (7, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_tags', 'ppoffice_icarus', 'true');
INSERT INTO `theme_settings` VALUES (8, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'links_top', 'ppoffice_icarus', '<a class=\"navbar-item\" target=\"_blank\" title=\"Download on GitHub\" href=\"https://github.com/halo-dev/halo-theme-icarus\"> <i class=\"fab fa-github\"></i> </a>');
INSERT INTO `theme_settings` VALUES (9, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_categories', 'ppoffice_icarus', 'true');
INSERT INTO `theme_settings` VALUES (10, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_recentcomment', 'ppoffice_icarus', 'false');
INSERT INTO `theme_settings` VALUES (11, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'sidebar_tagcloud', 'ppoffice_icarus', 'true');
INSERT INTO `theme_settings` VALUES (12, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'links_footer', 'ppoffice_icarus', '<p class=\"control\"> <a class=\"button is-white is-large\" target=\"_blank\" title=\"Creative Commons\" href=\"https://creativecommons.org/\"> <i class=\"fab fa-creative-commons\"></i> </a> </p> <p class=\"control\"> <a class=\"button is-white is-large\" target=\"_blank\" title=\"Attribution 4.0 International\" href=\"https://creativecommons.org/licenses/by/4.0/\"> <i class=\"fab fa-creative-commons-by\"></i> </a> </p>');
INSERT INTO `theme_settings` VALUES (13, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'social_github', 'ppoffice_icarus', 'TBlackBox');
INSERT INTO `theme_settings` VALUES (14, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'social_qq', 'ppoffice_icarus', '325811402');
INSERT INTO `theme_settings` VALUES (15, '2019-09-30 10:38:13', 0, '2019-09-30 10:38:13', 'social_email', 'ppoffice_icarus', '1227900499@qq.com');

-- ----------------------------
-- Table structure for users
-- ----------------------------
DROP TABLE IF EXISTS `users`;
CREATE TABLE `users`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `create_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `deleted` tinyint(4) NULL DEFAULT 0,
  `update_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `avatar` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `description` varchar(1023) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `email` varchar(127) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '',
  `expire_time` timestamp(0) NOT NULL DEFAULT current_timestamp(0),
  `nickname` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `username` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `mfa_key` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `mfa_type` int(11) NOT NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of users
-- ----------------------------
INSERT INTO `users` VALUES (1, '2019-09-27 18:00:47', 0, '2019-09-30 10:27:00', 'https://blog.javafroum.cn/upload/2019/9/ba79a75b2f389dae444a2993f72093b-eef65da0eb124e83bf5625f550ed2443.jpg', '', '1227900499@qq.com', '2019-09-27 18:00:47', 'BlackBox', '$2a$10$ihdGqyEZAN8I9DIhD2EEHurFA3FMjIV9dcb6K5WVb1/qb8ODPxxMy', 'BlackBox', NULL, 0);

SET FOREIGN_KEY_CHECKS = 1;
